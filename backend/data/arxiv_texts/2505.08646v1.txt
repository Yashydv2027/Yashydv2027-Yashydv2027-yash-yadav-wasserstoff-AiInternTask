Modular Federated Learning: A Meta-Framework Perspective‚ãÜ
Frederico Vicentea, Cl√°udia Soaresa and Du≈°an Jakovetiƒáb
aNOVA School of Science and Technology, Portugal
bUniversity of Novi Sad, Faculty of Sciences, Serbia
A R T I C L E I N F O
Keywords:
Federated Learning
Distributed Learning
Decentralised Learning
Distributed Optimisation
Survey
A B S T R A C T
Federated Learning (FL) enables distributed machine learning training while preserving privacy,
representing a paradigm shift for data-sensitive and decentralized environments. Despite its
rapid advancements, FL remains a complex and multifaceted field, requiring a structured
understanding of its methodologies, challenges, and applications. In this survey, we introduce a
meta-framework perspective, conceptualising FL as a composition of modular components that
systematically address core aspects such as communication, optimisation, security, and privacy.
We provide a historical contextualisation of FL, tracing its evolution from distributed optimi-
sation to modern distributed learning paradigms. Additionally, we propose a novel taxonomy
distinguishing Aggregation from Alignment, introducing the concept of Alignment as a fun-
damental operator alongside aggregation. To bridge theory with practice, we explore available
FL frameworks in Python, facilitating real-world implementation. Finally, we systematise key
challenges across FL sub-fields, providing insights into open research questions throughout the
meta-framework modules. By structuring FL within a meta-framework of modular components
and emphasising the dual role of Aggregation and Alignment, this survey provides a holistic and
adaptable foundation for understanding and advancing FL research and deployment.
1. Introduction
At present, digital privacy has become a paramount concern, propelling the development of regulations such as the
EU AI Act, the EU General Data Protection Regulation (GDPR), and the California Consumer Privacy Act (CCPA).
These concerns and regulations profoundly influence how data science and Machine Learning are conducted (EU AI
Act, Birrell et al. [25]). Inter-continental organisations can no longer freely transfer data from the EU to the USA,
compelling them to seek alternative methods to derive insights or train models on the entirety of their data. Privacy,
however, is merely one reason for exploring solutions beyond centralised data learning schemes. Consider the vast
proliferation of Internet of Things (IoT) devices generating continuous streams of raw data. Leveraging these data
streams effectively can lead to the development of more sophisticated and resilient Machine Learning models. Without
employing distributed learning algorithms, this data would need to traverse digital networks, potentially leading to
network saturation with sensitive information. Avoiding such network congestion and the high latency associated with
centralised learning solutions is crucial. Additionally, mobile phones, being inherently personal devices, necessitate
personalisation features in such systems. However, effective Machine Learning systems typically require substantial
datasets to perform optimally. With increasing data protection requirements such as GDPR and CCPA, and in scenarios
where data is continuously generated by distributed IoT devices, centralised data aggregation is often impractical or
even unfeasible. In these contexts, Federated Learning offers a compelling alternative, enabling collaborative model
training without exposing raw data.
The term Federated Learning was coined by a Google research team [177, 137], introducing the concept of a server-
client distributed learning schema for solving non-convex problems. They proposed a distributed learning process over
edge devices (i.e. mobile phones), which, without compromising private data, could collaboratively engage in learning
tasks (see Fig. 1 for a visual abstraction of the entities involved in a standard server-client FL network topology).
‚ãÜThe authors would like to thank NOVA LINCS‚Äôs support through the project (UIDP/04516/ 2020/BIM/10), Portuguese funding institution
FCT - Funda√ß√£o para a Ci√™ncia e a Tecnologia through the project PIDDAC, TaRDIS and 2024.03913.BD. The work of D. Jakovetic was also
supported in part by the Ministry of Education, Science and Technological Development, Republic of Serbia, and by the European Union‚Äôs Horizon
Europe Research and Innovation program, grant agreement IDs 101135775 and 101093006. The work of D. Jakovetic was further supported by the
Science Fund of The Republic of Serbia, the LASCADO project, grant no. 7359. Special thanks are extended to the following colleagues for helping
with revisions: Filipa Valdeira, Francisco Caldas, Frederico Metelo and Stevo Rackoviƒá.
fm.vicente@campus.fct.unl.pt (F. Vicente); claudia.soares@fct.unl.pt (C. Soares); dusan.jakovetic@dmi.uns.ac.rs
(D. Jakovetiƒá)
ORCID(s): 0000-0002-6807-1644 (F. Vicente); 0000-0003-3071-6627 (C. Soares); 0000-0003-3497-5589 (D. Jakovetiƒá)
Frederico Vicente et al.
Page 1 of 70
arXiv:2505.08646v1  [cs.LG]  13 May 2025
Modular Federated Learning: A Meta-Framework Perspective
The paradigm of distributed learning, however, dates back several decades, originating with the concept of
distributed optimisation. Over the past forty years, numerous approaches have been developed, ranging from non-
cooperative [231] to cooperative distributed learning environments [72], and from server-client topologies [149] to de-
centralised ones [189, 268]. Various algorithmic families embody the principles of distributed optimisation, including
methods such as the Alternating Direction Method of Multipliers (ADMM: Boyd et al. [32]), Block Coordinate Descent
(BCD), and distributed subgradient methods. These methods share similarities with the optimisation techniques
employed in Federated Learning. Moreover, in the same spirit as the Federated Learning genesis paper, many prior
works had already addressed the distributed solving of non-convex problems (e.g., neural networks). For example,
the 1-bit quantisation of Deep Neural Networks using distributed SGD [237] in 2014 explored many challenges still
relevant in today‚Äôs Federated Learning field, such as communication-efficient methods and quantisation mechanisms.
Both distributed optimisation and computer science distributed systems have a rich history [142].
In summary, Federated Learning is particularly beneficial in specific scenarios:
‚Ä¢ It excels in distributed systems where the number of devices far exceeds the number of data centre nodes [104].
‚Ä¢ It is well-suited for situations where data privacy is paramount [265].
‚Ä¢ FL is advantageous when dealing with numerous small datasets distributed across individual devices [177].
‚Ä¢ Data from edge devices is often unlabeled, but on-device pseudo-labeling techniques can be utilised to
personalise user experiences through Federated Learning [242].
‚Ä¢ Resource-limited devices may find data transmission prohibitive in terms of energy, assuming that Federated
Learning communication algorithms are less demanding than sharing raw data [276].
Server
C0
C1
CN
Global Model
(Aggregation of
Local Models)
Noisy Local Data
Local Learning
Local Data
Global Model sharing
Local Model 
sharing
Figure 1: Standard centralised Federated Learning Setting. Each client ùëêlearns a local model and shares it with a central
server, aggregating the individual model parameters and then sending this new global model back to the clients. This
process is repeated for several rounds until a certain criterion is met.
However, alongside its promising applications, Federated Learning faces several critical challenges that must be
addressed to ensure optimal performance. These include the need for communication-efficient methods to reduce
bandwidth usage, the difficulty of dealing with hardware and data heterogeneity across clients, and the challenge
of maintaining strong privacy guarantees while ensuring robustness against adversarial attacks. Moreover, aligning
distributed knowledge effectively without significant performance loss remains an open problem, as does the absence
of standardized frameworks for FL system design. Finally, the environmental impact, particularly the carbon footprint
associated with large-scale decentralized training, also raises concerns about sustainability.
For a comprehensive understanding of the Federated Learning landscape, we encourage readers to consult
contemporary surveys addressing various aspects of FL. Liu et al. [161] analyses heterogeneous FL, fairness
considerations, and aggregation methodologies. Li et al. [145], take a distinct approach, focusing on the development
of interpretable FL pipelines. The integration of Bayesian methods within the FL framework is thoroughly examined in
another significant survey [37]. Furthermore, the survey [126] offers an extensive discussion on security and privacy
Frederico Vicente et al.
Page 2 of 70
Modular Federated Learning: A Meta-Framework Perspective
issues, fairness in FL solutions, the challenges posed by non-independent and identically distributed (non-iid) data,
and strategies for effective and efficient handling of heterogeneous learning environments. In alignment with the
aforementioned surveys, particularly Kairouz et al. [126], and Liu et al. [161], our survey aims to provide an accessible
introduction to Federated Learning while presenting a comprehensive overview of the research and developments in
the field. However, our contribution diverges by proposing a novel perspective on FL as a Meta-Framework composed
of modules. Additionally, we find it relevant to discuss FL in the context of distributed optimisation and to address
trustworthy Machine Learning within FL contexts, as highlighted by Mucs√°nyi et al. [186].
We include a representative table that summarizes key directions in current survey literature, outlining their core
focus areas and contributions (see Table 1).
Table 1: Representative overview of Federated Learning Survey Litera-
ture by Focus Area and Contributions
Survey
Focus
Key Contributions
Foundational and General
Kairouz et al. [126]
FL
overview
and
open challenges
Provides a comprehensive and in-depth overview of the
federated learning field, along with a well-founded set of
research challenges that guide future work.
Ours (2025)
FL overview from a
Meta-Framework
Perspective
Systematises FL as a modular Meta-Framework with
modular components; proposes Alignment operator tax-
onomy to guide knowledge aggregation; traces histori-
cal evolution from distributed learning; surveys current
Python frameworks.
Privacy & Security
Hallaji et al. [100]
Privacy methods
Surveys security and privacy threats in decentralized
federated learning, examining adversary models, defense
mechanisms, and the role of trust and verifiability in the
absence of a central server.
Lyu et al. [170]
Robustness
Presents a comprehensive survey of privacy and robust-
ness in FL, offering a structured taxonomy of threat mod-
els, attacks, and defenses, while highlighting key tech-
niques, assumptions, and future directions toward secure
and resilient FL systems.
Bai et al. [16]
Membership
inference attacks
Provides a comprehensive survey on membership infer-
ence attacks in FL, introducing a structured taxonomy of
attack types and defense strategies, along with a critical
evaluation of their effectiveness, limitations, and open
research challenges.
Liu et al. [162]
Blockchain
Comprehensive survey of Blockchain-based FL, pre-
senting taxonomy architectures, analysing their integra-
tion across privacy-sensitive domains, and highlighting
blockchain‚Äôs role in enhancing FL security and decentral-
ization.
Trustworthiness
Continued on next page
Frederico Vicente et al.
Page 3 of 70
Modular Federated Learning: A Meta-Framework Perspective
Survey
Focus
Key Contributions
Qi et al. [212]
Aggregation
Strategies
Conducts a systematic review of model aggregation tech-
niques in federated learning, highlighting their impact
on global model accuracy and reliability, and analyzing
methods designed to handle low-quality or malicious
client updates.
Li et al. [145]
Interpretability
Proposes a novel taxonomy for interpretable federated
learning, covering methods that enhance prediction ex-
plainability, enable model debugging, and attribute con-
tributions to data owners, crucial for fair reward alloca-
tion. Includes a comprehensive analysis of current ap-
proaches, evaluation metrics, and future research direc-
tions.
Cao et al. [37]
Probabilistic
approaches
Addresses challenges such as data scarcity, heterogene-
ity, uncertainty, and limited explainability by covering
Bayesian frameworks designed for robust learning in real-
world federated settings.
Personalisation
Tan et al. [256]
Personalisation
methods
Presents a structured taxonomy of personalisation strate-
gies, grounded in key challenges and motivations, and
offers a comprehensive analysis of existing techniques.
Outlines future directions in architectural design, bench-
marking, and trustworthy personalised FL.
Applications
Nguyen et al. [191]
IoT and application
domains
Covers how FL can be applied across various IoT ser-
vices and applications. It also offers a taxonomy and key
takeaways to guide future FL-IoT integration efforts and
addresses ongoing challenges in the field.
Pinto Neto et al. [207]
Reinforcement
Learning
Comprehensive review of Federated Reinforcement
Learning in IoT applications, analysing current solutions
across domains such as security, efficiency, and vehicular
systems, while identifying research gaps and future chal-
lenges.
To provide a comprehensive overview, we now outline our core contributions:
‚Ä¢ Systematisation of Federated Learning as a Meta-Framework. We propose a Meta-Framework perspective
of Federated Learning, structuring it as a modular and composable system rather than a monolithic methodology.
This approach provides a unifying blueprint, organizing key FL dimensions, such as communication, aggrega-
tion, security, into interoperable modules. It enhances systematic design, and adaptation to diverse real-world
scenarios. Beyond its structural benefits, this taxonomy also simplifies the understanding of FL by breaking it
into core components, offering a clearer pedagogical framework. Ultimately, we hope this perspective facilitates
both theoretical analysis and practical implementation, making FL more accessible, adaptable, and intuitive for
newcomers.
‚Ä¢ Novel Alignment Operator. We propose a novel operator Alignment to explicitly capture and formalize
knowledge alignment between clients, distinguishing our approach from prior formulations. We argue that this
alignment operator is as fundamental as aggregation in Federated Learning. Aggregation refers to the process of
combining model updates from distributed clients to form a global model, ensuring knowledge is shared across
the system.
Frederico Vicente et al.
Page 4 of 70
Modular Federated Learning: A Meta-Framework Perspective
Alignment, on the other hand, constrains the aggregation process to meet specific objectives, such as fairness,
convergence, or robustness. This perspective highlights the dual importance of aggregation and alignment in
driving effective learning across distributed systems.
‚Ä¢ Historical contextualisation. We trace the evolution of Federated Learning, highlighting its foundational ties
to distributed optimisation.
‚Ä¢ Entry-level understanding. We provide a comprehensive yet accessible introduction to Federated Learning,
catering to newcomers and facilitating their engagement with the topic.
‚Ä¢ Federated Learning Python Frameworks Systematisation. We conduct a comprehensive exploration of
existing Python-based Federated Learning frameworks, systematically analysing their features, capabilities, and
suitability for different use cases.
‚Ä¢ Challenges in Sub-Fields. We identify and systematise the key challenges faced within various sub-fields of
Federated Learning.
Given the extensive scope of this survey, we provide a detailed roadmap to ease navigation through the various
sections:
‚Ä¢ Section 2: Preliminaries. This section provides foundational knowledge to understand the FL framework,
starting with key mathematical notation. It then formulates the distributed optimization problem, outlines core
FL family of algorithms, and presents various architectural paradigms. Finally, it presents an innovative modular
Meta-Framework approach, conceptualising FL as a structured blueprint of interconnected modules.
‚Ä¢ Section 3: Distributed Optimisation - A Historical Perspective. This section examines the evolution of
distributed optimisation and its relationship with Federated Learning.
‚Ä¢ Section 4: Dissecting the FL Modular Meta-Framework. This section systematically deconstructs Federated
Learning through the lens of a modular meta-framework, organizing existing literature across key FL domains.
By structuring FL as a composable set of interoperable modules, this taxonomy provides a coherent and intuitive
perspective, making it easier to grasp the fundamental principles and interconnections within FL.
‚Ä¢ Section 5: Python FL Frameworks. This section provides a practical perspective on FL, with an in-depth
discussion of the available Python frameworks for implementing distributed learning. We examine their features,
capabilities, and limitations.
‚Ä¢ Section 6 : Alternatives and Comparisons. Here, we clarify the distinctions between Federated Learning and
other techniques that involve distributed systems and Machine Learning but diverge from the FL paradigm.
‚Ä¢ Section 7: Real-World Applications and Challenges. We present real-world examples of FL frameworks in
use and propose potential future directions for use cases. We emphasise the significance of open platforms
for collaborative training and sharing FL models. Given the complexity of FL frameworks, which integrate
distributed systems, mathematical optimisation, and software engineering, we highlight the necessity of
advanced methods for monitoring, debugging, and profiling in practical FL systems. The section concludes
with insights into FL‚Äôs challenges, including environmental impact and hardware constraints.
‚Ä¢ Section 8: Future Research Directions. This section motivates and explores potential avenues for future
research in the FL domain, considering emerging trends and unresolved issues.
‚Ä¢ Section 9: Conclusion. We conclude by summarising the journey through the Federated Learning landscape and
remarking on the importance of a privacy-aware distributed design to tackle critical domain use cases. We further
remind that FL is a multidisciplinary field encompassing knowledge from distributed systems, optimisation
algorithms, and software engineering.
Frederico Vicente et al.
Page 5 of 70
Modular Federated Learning: A Meta-Framework Perspective
2. Preliminaries for Federated Learning
2.1. Notation, Terminology and Key Concepts
In Federated Learning (FL), a federation consists of a set of clients or nodes, denoted as ùê∂‚âî{ùëê1, ..., ùëêùëÅ}. Each
client is represented as ùëê, where ùëê‚ààùê∂. Generally, the core mechanism of FL involves a global optimisation algorithm
and local optimisation algorithms operating on locally available data. Typically, only a subset of federation nodes
participates in training during each global communication round; this subset is referred to as a cohort of size ùëÜ.
2.1.1. Data & Client Partitioning
In a distributed Machine Learning paradigm, data is obtained from multiple computational nodes, such as Internet
of Things (IoT) devices (e.g., CCTV cameras, sensors, smartphones) and organizational servers. The global data of
a distributed task is denoted as ùê∑, while the local data of a client ùëêis represented by ùê∑ùëê, containing ùëÄùëêsamples.
Formally, this can be expressed as:
ùê∑‚âî
ùëÅ
‚ãÉ
ùëê=1
ùê∑ùëê,
ùê∑ùëê‚âî{(ùë•ùëñ, ùë¶ùëñ
)}ùëÄùëê
ùëñ=1 .
(1)
where ùë•ùëñand ùë¶ùëñdenote the features and target samples, respectively, from each client. We denote |ùê∑| ‚âîùëÄand
|ùê∑ùëê| ‚âîùëÄùëêas the total number of samples across all clients and the total number of samples for a single client,
respectively.
In distributed systems, data exhibits certain properties that influence ùê∑ùëê. Unlike the centralized setting, where data
is typically homogeneous and independently and identically distributed (IID), FL often deals with heterogeneous (non-
IID) data. Each local dataset ùê∑ùëêconsists of data points (ùë•, ùë¶) sampled from a client-specific probability distribution ùëÉùëê.
These distributions vary across clients, meaning that for any two clients ùëêùëé, ùëêùëè‚ààùê∂with ùëêùëé‚â†ùëêùëè, we have ùëÉùëêùëé‚â†ùëÉùëêùëè. This
distributional shift across clients is a defining characteristic of FL, reflecting the realistic non-IID nature of distributed
data.
2.1.2. Distributed Communication
Following the literature on distributed systems and Federated Learning, several terminologies are commonly used
to describe client nodes. One such term is stragglers, referring to clients that are significantly slower than others in
completing their local training during a communication round, often becoming a bottleneck in the aggregation process.
Another important concept is staleness, which describes the situation where clients perform local training based on
outdated global models, leading to the submission of updates that may no longer be relevant or optimal for the current
state of the global model.
Communication Rounds and Epochs. In FL, the learning process is organized into discrete communication
rounds, where clients update their local models and send them to the central server (or other clients in decentralized
settings) for aggregation. Each communication round typically involves:
1. Downlink: Broadcasting the latest global model from the server to a subset of clients (a cohort).
2. Local training on client-specific data for a fixed number of epochs.
3. Uplink: Uploading the locally updated models from clients to the server for aggregation, where client models
are merged into a global model.
Convergence. Convergence refers to the process by which the global model reaches a stable state, where further
communication rounds lead to negligible performance gains. This process is influenced by several key factors. Data
heterogeneity, where clients possess non-iid data distributions, can significantly slow down convergence or lead to
suboptimal global models. Communication constraints, such as limited bandwidth or unreliable network conditions,
may delay the exchange of updates, thus extending the time required to converge. Additionally, client participation
plays a crucial role, as not all clients are available in every training round, introducing variability that can disrupt or
delay convergence.
2.1.3. Model Parameters and Optimisation
Model Representation. The learnable parameters of a Machine Learning model (e.g., a neural network) are denoted
by ùúÉ. The parameters of a global model in a centralized setting are represented as ùúÉ, while client-specific models are
Frederico Vicente et al.
Page 6 of 70
Modular Federated Learning: A Meta-Framework Perspective
denoted by ùúÉùëê1, ùúÉùëê, and ùúÉùëÅ, representing the first, any general, and the last client, respectively. A neural network is
defined as ùëì, a universal approximating function parametrised by input data and parameters ùúÉ. For a specific client
ùëê, the neural network is represented as ùëìùëê(ùë•; ùúÉùëê), which, given a data point (ùë•, ùë¶) ‚ààùê∑ùëê, predicts ÃÇùë¶‚âîùëìùëê(ùë•; ùúÉùëê).
Differentiating ùëìùëêfrom ùëìacknowledges that clients may learn different models, a scenario termed as heterogeneous
model learning [146].
Optimisation and Loss Functions. In Machine Learning, parameters are optimized to minimise a loss error
function ùìÅ(ùë¶, ùëì(ùë•; ùúÉ)), which evaluates the model‚Äôs performance. Gradient descent algorithms are typically employed
to update the parameters iteratively using gradient information ‚àáùúÉùëô(gradient of the loss with respect to the model
parameters ùúÉ) and a learning rate ùúÇ> 0, which determines the step size of each update. The learning rate controls how
much the parameters are adjusted in response to the gradient, balancing the trade-off between convergence speed and
stability. Optimisation can be subject to constraints, denoted as Œò, specific to a given task. To express numerical values
that control the enforcement of specific mathematical constraints throughout this survey we use ùúåand ùúÜ.
Probability and Logits. The probability of a random variable ùëçtaking the value ùëßis denoted as ùëÉ(ùëç= ùëß). In
classification models, the term logits refers to the log probabilities output by a classifier model.
2.1.4. Aggregation
A fundamental operation in Federated Learning is aggregation, which combines information from multiple client
nodes to update a global representation. This step is most commonly performed by aggregating model parameters,
such as in Federated Averaging, where client updates are averaged, typically weighted by local dataset size. However,
depending on the problem formulation, aggregation can also be applied to other learning artefacts like gradients,
embeddings, enabling flexible strategies that account for data heterogeneity, communication efficiency, or robustness
to outliers.
2.2. Distributed Objective
A Federated Learning problem can usually be considered an optimisation problem. The problem formulation
reflects on each client‚Äôs objectives and describes how the local clients‚Äô objectives are orchestrated together. Examples of
how the client‚Äôs objectives can be mutually related include consensus optimisation (similar clients‚Äô objectives) McMa-
han et al. [177], and competitive optimisation (competitive clients‚Äô objectives) Tang and Yu [258], Wu and Yu [294]. In
consensus optimisation, cooperation can occur individually or group-wise (as in distributed clustering learning Zeng
et al. [324]). Generally, a distributed learning problem is minimising a global loss/objective function of the form
Óà≥(Óà∏1(ùúÉ1), ..., Óà∏ùëÅ(ùúÉùëÅ)). We further formalise the process of constraining parameters or knowledge artifacts during
aggregation using an Alignment operator, denoted as Óà≠. We formalise this taxonomy of alignment operators due to
its importance in federated learning, where it appears in various forms across numerous studies (e.g. [103, 11, 19]).
The objective is to minimize the expected loss across clients while ensuring that the alignment measure Óà≠stays within
a predefined threshold ùúñ. Additional constraints may affect the parameters (ùúÉ, ùúÉùëê) being modelled, as
minimise
ùúÉ,{ùúÉùëê}ùëÅ
ùëê=1
Óà≥(Óà∏1(ùúÉ1), ..., Óà∏ùëÅ(ùúÉùëÅ), Óà∏(ùúÉ)))
s.t.
Óà≠(ùúÉ, {ùúÉùëê}ùëÅ
ùëê‚âî1
) ‚â§ùúñ, (ùúÉ, {ùúÉùëê}ùëÅ
ùëê‚âî1
) ‚ààŒò.
(2)
Here, Óà∏ùëê(ùúÉùëê) denotes the expected loss of client ùëêwhere the expectation is taken for the client ùëêdata distribution;
and Óà∏(ùúÉ) represents an optional term that corresponds to the expected loss concerning the joint clients‚Äô data distribution.
Also, ùúÉmay be interpreted either as a full global model of interest to all clients or as a part of the model (e.g. a subset
of Neural Network parameters) that is of interest to all clients. Next, Óà≥represents an aggregation function that specifies
how the different local losses are mutually combined, and Óà≠represents an alignment function that specifies how the
models ùúÉ1, ..., ùúÉùëÅand ùúÉare mutually related. Óà≠returns a vector (multi-dimensional) output, then the inequality Óà≠‚â§ùúñis
interpreted component-wise. Finally, Œò represents an a priori constraint on the space of admissible models/parameters.
Typically, Óà∏(ùúÉùëê) ‚âîùîº(ùë•,ùë¶)‚àºÓà∞ùëê
[ùìÅ(ùë¶, ùëìùëê(ùë•ùëê; ùúÉùëê))] is the expected loss with respect to each client ùëê‚Äôs data distribution.
Examples of the aggregation function Óà≥include the average and the maximum functions. That is, many formulations
consider
Frederico Vicente et al.
Page 7 of 70
Modular Federated Learning: A Meta-Framework Perspective
Óà≥(Óà∏1(ùúÉ1), ..., Óà∏ùëÅ(ùúÉùëÅ)) ‚âî1
ùëÅ
ùëÅ
‚àë
ùëê=1
Óà∏ùëê(ùúÉùëê),
(3)
or
Óà≥(Óà∏1(ùúÉ1), ..., Óà∏ùëÅ(ùúÉùëÅ)) ‚âîmax(Óà∏ùëê(ùúÉùëê), ùëê‚âî1, ..., ùëÅ).
(4)
The alignment operator Óà≠can also take many forms, for example:
Óà≠(ùúÉ, {ùúÉùëê}ùëÅ
ùëê‚âî1) ‚âî‚ÄñùúÉ‚àíùúÉùëê‚Äñ ‚â§ùúñ, ùëê‚âî1, ..., ùëÅ,
(5)
or
Óà≠(ùúÉ, {ùúÉùëê}ùëÅ
ùëê‚âî1) ‚âî‚ÄñùúÉùëñ‚àíùúÉùëó‚Äñ ‚â§ùúñ, ùëñ, ùëó‚âî1, ..., ùëÅ,
(6)
hence enforcing clients‚Äô mutually similar models. Note that here ùúñmay also be taken to be zero, thus enforcing full
consensus across clients‚Äô models.
It can also take the form of
Óà≠(ùúÉ, {ùúÉùëê}ùëÅ
ùëê‚âî1) ‚âî‚àí‚ÄñùúÉùëñ‚àíùúÉùëó‚Äñ ‚â•ùúñ, ùëñ, ùëó‚âî1, ..., ùëÅ,
(7)
thus enforcing mutually different models across clients.
Additionally, a combination of the similarity-enforcing and difference-enforcing constraints as above is possible,
for distinct sets of client pairs.
Among the many possible formulations of the form (2), we list some common examples:
minimise
{ùúÉùëê}ùëÅ
ùëê‚âî1
1
ùëÅ
ùëÅ
‚àë
ùëê‚âî1
Óà∏ùëê(ùúÉùëê)
s.t.
ùúÉùëñ= ùúÉùëó, ùëñ, ùëó‚âî1, ..., ùëÅ,
(8)
minimise
{ùúÉùëê}ùëÅ
ùëê‚âî1
max(Óà∏ùëê(ùúÉùëê), ùëê‚âî1, ..., ùëÅ)
s.t.
ùúÉùëñ= ùúÉùëó, ùëñ, ùëó‚âî1, ..., ùëÅ,
(9)
minimise
ùúÉ,{ùúÉùëê}ùëÅ
ùëê‚âî1
1
ùëÅ
ùëÅ
‚àë
ùëê‚âî1
Óà∏ùëê(ùúÉùëê) + ùúå
2
ùëÅ
‚àë
ùëê‚âî1
‚ÄñùúÉùëê‚àíùúÉ‚Äñ2,
(10)
minimise
ùúÉ,{ùúÉùëê}ùëÅ
ùëê‚âî1
1
ùëÅ
ùëÅ
‚àë
ùëê‚âî1
Óà∏ùëê(ùúÉùëê) + ùúå
2
ùëÅ
‚àë
ùëê‚âî1
‚ÄñùúÉùëê‚àíùúÉ‚Äñ,
(11)
minimise
{ùúÉùëê}ùëÅ
ùëê=1
1
ùëÅ
ùëÅ
‚àë
ùëê‚âî1
Óà∏ùëê(ùúÉùëê)
s.t.
‚ÄñùúÉùëñ‚àíùúÉùëó‚Äñ ‚â§ùúñ,
(12)
Formulation (8) appears in many references and is perhaps most widely used currently [177]. Formulation (9)
appears in distributed robust (model agnostic) Federated Learning [181]. Formulations (10), (11), (12) are examples
that arise in Personalised Federated Learning [103, 11, 19].
Equation (2) can also be reformulated as an unconstrained problem, for example, as observed in Eq. (10), e.g. using
a quadratic penalty method as
minimise
ùúÉ,{ùúÉùëê}ùëÅ
ùëê=1
1
ùëÅ
ùëÅ
‚àë
ùëê‚âî1
Óà∏ùëê(ùúÉùëê) + ùúå
ùëÅ
‚àë
ùëê‚âî1
ùëî(Óà≠(ùúÉ, ùúÉùëê
))
where
ùëî(Óà≠(ùúÉ, ùúÉùëê
)) ‚âîmax(‚àí(Óà≠(ùúÉ, ùúÉùëê
) ‚àíùúñ), 0)2.
(13)
Frederico Vicente et al.
Page 8 of 70
Modular Federated Learning: A Meta-Framework Perspective
The solutions (13) and Eq. (10) can be related; Typically they are mutually close or equal when ùëîis large enough.
Locally, at each client, the population loss Óà∏ùëê(ùúÉùëê) is unknown. Therefore, it is replaced by an approximation based
on the available training data ùê∑ùëêusing pairs (ùë•, ùë¶), through a sample average:
minimise
ùúÉùëê
Óà∏ùëê
(ùúÉùëê
) ,
Óà∏ùëê(ùúÉùëê) ‚âî
1
|ùê∑ùëê|
‚àë
(ùë•ùëñ,ùë¶ùëñ)‚ààùê∑ùëê
ùìÅ(ùë¶ùëñ
ùëê, ùëìùëê(ùë•ùëñ
ùëê; ùúÉùëê)) .
(14)
In heterogeneous Federated Learning environments, clients may exhibit diverse data distributions, leading to
challenges in global model convergence. To address this, clustering similar clients can ease optimisation by enabling
separate global models for distinct client groups. This motivates the Clustered Federated Learning (CFL) problem,
which involves optimising multiple global models corresponding to client clusters.
The CFL problem naturally leads to a dual optimisation task involving:
1. Determining the optimal cluster memberships {ÓàØùëò}ùêæ
ùëò‚âî1, where ÓàØùëòdenotes the set of clients in the ùëò-th cluster;
2. Optimising the global model parameters {ùúΩùëò}ùêæ
ùëò‚âî1 for each cluster.
These two components can be optimised jointly or in an alternating fashion.
We define the model parameter optimisation objective as:
min
{ùúΩùëò}ùêæ
ùëò=1
ùêæ
‚àë
ùëò=1
‚àë
ùëê‚ààÓàØùëò
1
|ùê∑ùëê|
‚àë
(ùë•ùëñ,ùë¶ùëñ)‚ààùê∑ùëê
ùìÅ(ùë¶ùëñ
ùëê, ùëìùëê(ùë•ùëñ
ùëê; ùúÉùëê))
(15)
In this formulation, ùêædenotes the number of clusters, and ùúΩùëòrepresents the global model parameters associated
with the ùëò-th cluster. The function ùìÅ(‚ãÖ, ‚ó¶) corresponds to the local loss evaluated over each client‚Äôs data.
The cluster membership assignment objective, given current global models, can be formulated as:
min
{ÓàØùëò}ùêæ
ùëò‚âî1
ùêæ
‚àë
ùëò‚âî1
‚àë
ùëê‚ààÓàØùëò
ùëë(ùúΩùëê, ùúΩùëò
)
(16)
Here, ùúΩùëêdenotes the local model update of client ùëê, and ùúΩùëòis the global model representing cluster ùëò. The distance
metric ùëë(‚ãÖ, ‚ó¶) can reflect dissimilarity in parameter space, gradient updates, or model outputs, and is often instantiated
as the Euclidean distance, cosine similarity, or KL divergence.
Clustering is typically performed using distance-based algorithms such as k-means or spectral clustering. By
integrating cluster structure into the federated setting, CFL captures non-IID distributions more effectively, leading
to improved personalisation and convergence in practice.
2.2.1. From Problem Formulation to Algorithmic Solution
Building on problem formulations from the Federated Learning (FL) literature, we formalize how these optimisa-
tion problems are practically addressed through algorithmic solutions.
The foundational algorithm of FL is FedAvg [177], an iterative algorithm within a server-client centralised schema
(See Fig. 1). In this framework, the server aggregates optimal parameters from the local client models ùúÉùëêafter each
communication round, by averaging them, as shown in the following update rule:
ùúÉ‚Üê
ùëÅ
‚àë
ùëê‚âî1
|ùê∑ùëê|
|ùê∑| ùúÉùëê,
ùúÉùë†+1
ùëê
‚ÜêùúÉùë†
ùëê‚àíùúÇ‚àáùúÉùë†ùëêùëô(ùúÉùë†
ùëê
) .
(17)
Eq. (17) represents both the aggregation on the server and the local optimisation on the clients using Stochastic Gradient
Descent, which updates parameters based on their gradient information at each local step ùë†.
The server-client Federated Learning algorithm FedAvg can be outlined as follows:
1. Initialisation: Initialisation of the global model following standard practices or task-related heuristics;
Frederico Vicente et al.
Page 9 of 70
Modular Federated Learning: A Meta-Framework Perspective
2. Client Selection: Based on predefined heuristics, such as computational resources and communication quality,
certain client nodes, referred to as a cohort, are selected to participate in more robust training rounds;
3. Server Broadcast: The global model‚Äôs parameters, along with relevant statistical data and other forms of
knowledge such as pre-trained features or model insights, are shared with selected client nodes to support their
local training;
4. Client Training: Local nodes perform ùëçoptimisation steps until convergence or a specific stop criterion;
5. Clients‚Äô Broadcast: Local models parameters ùúÉùëê, along with any other client-specific knowledge, are shared
with the server to enable parameter aggregation;
6. Aggregation: The server collects the local client updates and averages them to create an updated version of the
global model;
7. Repeat steps 2-6 for ùëårounds or until a specific stop criterion.
To illustrate a more complex scenario, consider the Clustered Federated Learning (CFL) algorithm, which proceeds
in iterative communication rounds:
1. Initialisation: Initialise the global model for each cluster. Initially, clients may be randomly assigned to clusters.
2. Cluster Broadcast: Each cluster broadcasts its global model parameters, along with any relevant statistics or
shared knowledge (e.g. pre-trained features), to its assigned clients.
3. Local Training: Each client performs local training on its private data and computes an updated model ùúΩùëê.
4. Client Upload: Clients send their local model updates ùúΩùëê, and optionally any client-specific statistics or
metadata, back to the server.
5. Cluster Reassignment: Clients are reassigned to clusters based on a distance metric ùëë(‚ãÖ, ‚ó¶), typically comparing
local updates to cluster centres.
6. Cluster Aggregation: For each cluster, the server aggregates the local model updates from its assigned clients
to update the cluster-specific model ùúΩùëò.
7. Global Synchronisation: Cluster centres ùúΩùëòare iteratively refined to minimise the overall CFL objective.
The FedAvg straightforward training process becomes more complex when incorporating local model alignment
penalties, modifying the alignment algorithm, or enforcing stronger privacy and security guarantees. While FedAvg,
as defined in Eq. 17, is designed to solve Eq. 8, adapting it to solve other relevant formulations, such as Eqs. (9)-(12),
requires non-trivial modifications to the algorithm.
2.2.2. Convergence
Convergence in optimisation refers to the process by which an algorithm iteratively refines its solution, ideally
approaching a local or global optimum. In classical optimisation, convergence analysis is centered on factors such as
the loss landscape, step size (learning rate), and initialization. The speed and accuracy of convergence determine the
efficiency of an algorithm, particularly in large-scale, non-convex settings where slow or premature convergence can
hinder optimal solutions.
In Federated Learning (FL), convergence is even more intricate due to distributed optimisation, data heterogeneity,
and communication constraints. FL aims to optimize a global objective function Óà≥through local updates on distributed
clients, and its convergence properties are affected by assumptions on Óà≥, client data distributions, aggregation and
alignment strategies. Notably, the distinction between independent and identically distributed (IID) vs. non-IID
data profoundly impacts convergence behavior, often necessitating algorithmic adaptations to maintain stability and
efficiency.
An overview of convergence in Federated Learning is examined in [152]. In this work, we highlight the key aspects
of FL algorithms and their convergence properties.
Function Classes and Their Convergence Properties. The convergence properties of FL algorithms depend
significantly on the formulation choices, such as Eqs. (9)‚Äì(12), and on the function class of the global objective. If the
objective function ùëìis convex, standard gradient-based methods generally ensure convergence, with sublinear rates
depending on smoothness and strong convexity assumptions. When ùëìis strongly convex, convergence guarantees
are stronger, often achieving linear rates under appropriate learning rate schedules. Most modern FL applications
involve non-convex objectives, such as those arising in deep neural networks. In this setting, convergence analysis
Frederico Vicente et al.
Page 10 of 70
Modular Federated Learning: A Meta-Framework Perspective
typically focuses on reaching stationary points rather than global optima [338]. Nevertheless, if ùëìsatisfies the Polyak-
≈Åojasiewicz (PL) condition1, convergence to a global minimum can still be achieved at a linear rate, despite non-
convexity, thereby mimicking the behavior of strongly convex functions.
Impact of Data Heterogeneity on Convergence. A fundamental challenge in FL is data heterogeneity, which
significantly influences convergence rates. When data is independently and identically distributed (IID) across clients,
FL methods tend to achieve convergence rates similar to centralised settings, as the problem is homogeneous and
gradient updates from different clients align well [177]. In contrast, practical FL settings often involve non-IID data,
which leads to optimisation difficulties. To address this, some works assume bounded local loss minimisers imposing
an upper bound on the divergence of local optima across clients to facilitate convergence guarantees [112]. Other
approaches model clustered heterogeneity, assuming structured variability where clients belong to underlying clusters,
thereby improving optimisation strategies [90].
Optimisation Techniques for Improved Convergence. To address the challenges posed by data heterogeneity
and improve convergence in FL, various optimisation approaches have been proposed. Federated Averaging (Fe-
dAvg) remains the standard baseline method in which clients perform local updates before aggregation. However,
FedAvg lacks convergence guarantees under non-IID data [336]. To mitigate this, optimisation-based methods have
been developed that leverage historical information to improve client updates. These include momentum-based FL
approaches [303, 275, 62], and proximal methods such as FedProx [151] and SCAFFOLD [130]. Operator splitting
methods (e.g. FedSplit [205]) has also been suggested to address the issue of incorrect fixed points in earlier
optimization methods, ensuring that the iterates converge to the true minimizer in convex federated settings. Client
selection techniques have also emerged, strategically choosing well-behaved clients to enhance global model training
and reduce divergence issues [54, 12]. Additionally, employing pre-trained models and transfer learning has proven
effective in providing better initialisation, thereby improving convergence efficiency.
Linear Speedup and Scalability. An ideal FL algorithm should exhibit linear speedup, where the loss error
scales as ùëÇ(1‚àïùëÅ) with the number of clients ùëÅ. This is typically achievable when data is IID, as gradient noise
diminishes symmetrically across clients, enabling near-optimal speedup. However, in heterogeneous data settings,
convergence degrades due to inconsistent updates across clients. To overcome this, several techniques such as
adaptive weighting, variance reduction, and personalised FL have been proposed [324]. Furthermore, even when
theoretical speedup is achievable, practical performance may be limited by communication overhead. This has led
to the development of strategies such as local updates, adaptive aggregation, and communication-efficient methods
like compression [120, 71].
Stochastic Gradient Noise Assumptions. FL convergence is also influenced by assumptions regarding stochastic
gradient noise. A common assumption is that of zero-mean noise, ensuring unbiased convergence [286]. Techniques
like Differential Privacy, which introduce randomly generated zero-mean noise, are used to enhance privacy in FL [74].
Another assumption is that of uniformly bounded variance, which guarantees controlled convergence rates under
certain conditions [320]. More recent work has explored FL under heavy-tailed noise distributions, prompting the
use of robust estimation techniques such as gradient clipping and adaptive learning rates [148].
For further details, we refer the reader to the optimisation Algorithms subsection in the survey [126] and to an
overview of Federated Learning convergence in [152].
2.3. Taxonomy of Federated Learning Systems
The structure and capabilities of participating clients define the type of Federated Learning architecture. Federated
Learning can be broadly categorized into Cross-Silo, Cross-Device, and Hierarchical Federated Learning, each tailored
to distinct use cases. In a Cross-Silo federation, multiple organisations such as hospitals collaborate, each represented
by a robust client with reliable communication.
1A mathematical property that helps ensure that an optimisation algorithm converges efficiently. It states that if a function satisfies this condition,
the gap between its current value and the optimal value can be used to bound the gradient norm.
Frederico Vicente et al.
Page 11 of 70
Modular Federated Learning: A Meta-Framework Perspective
Server
Cross-Device
Cross-Silo
Hierarchical FL
Server
Server
Server
Server
Server
‚àë
‚àë
‚àë
Figure 2:
Contrasting different infrastructure meta-types of Federated Learning architectures. Cross-Device FL utilises
low-resource devices with uncontrollable training availability (e.g. smartphones, microcontrollers). Cross-Silo is based on a
reliable infrastructure such as a collection of servers. Hierarchical FL mixes Cross-Device and Cross-Silo FL infrastructure.
Client 0
Feat 0
Feat 1
Feat n
...
Client c
Feat 0
Feat 1
Feat n
...
Client N
Feat 0
Feat 1
Feat n
...
Horizontal FL
...
...
Feat 0
Feat 3
Feat 2
Feat 3
Feat 5
Client 0
Client c
Client N
Feat 1
Feat 3
Feat 4
Feat 5
Vertical FL
...
...
Figure 3:
Abstract overview of the main differences between Horizontal and Vertical Federated Learning. Horizontal
Federated Learning (left) expects the same features across clients, while Vertical Federated Learning (right) involves
clients with different features.
Conversely, in a Cross-Device federation, a central server orchestrates learning with less powerful clients (e.g. IoT
or phone devices), which may be intermittently available or compromised. Training occurs when the device is idle,
charging, and connected to a robust network.
Hierarchical Federated Learning (H-FL), also known as Hybrid Federated Learning or Fog Learning, combines
Cross-Device and Cross-Silo FL. Individual silos perform internal aggregations across low-power nodes, with further
inter-silo aggregation, avoiding raw data sharing. Fig. 2 illustrates the differences between Cross-Device, Cross-Silo,
and Hierarchical FL.
The organization of data across clients determines the type of Federated Learning framework, broadly classified
into Vertical (Heterogeneous) and Horizontal (Homogeneous) Federated Learning. In Vertical (Heterogeneous) FL,
data is distributed such that different clients hold different features for the same users. For example, in a hospital group,
each clinic may provide different clinical features for the same patient.
Horizontal (Homogeneous) FL, on the other hand, involves clients with the same set of features for different users.
For instance, different clinics in the same hospital group may produce identical types of features for patients. Fig. 3
contrasts horizontal and vertical FL.
2.4. Meta-Framework Perspective
In this survey, we propose viewing Federated Learning (FL) from a Meta-Framework perspective, comprising
eight key modules (Fig. 4).
A meta-framework is a higher-order conceptual structure that defines a flexible, modular, and composable system
rather than prescribing a rigid methodology. Unlike the traditional framework term, which defines a predefined
pipeline or architecture, a meta-framework allows for the systematic composition of multiple interoperable components,
enabling customization and adaptation to different requirements and constraints. By defining a structured set of modules
that can be configured and extended, a meta-framework serves as both a unifying theory and a practical design guide.
FL aligns with this meta-framework paradigm. Rather than being a singular, fixed approach, FL is an umbrella
term encompassing a diverse set of strategies for enabling distributed learning across dispersed data sources. Different
FL applications require distinct solutions depending on constraints related to infrastructure, communication, data
characteristics, aggregation, security, privacy, and trustworthiness. Viewing FL as a meta-framework allows us to
decompose it into a set of fundamental modules, each addressing a specific dimension of FL. These modules can mostly
be independently designed, improved, and recombined, making FL more adaptable to various deployment scenarios,
from cross-device learning in edge computing to cross-silo collaboration among enterprises.
Frederico Vicente et al.
Page 12 of 70
Modular Federated Learning: A Meta-Framework Perspective
d
Communication
Strategy
c
Aggregation
Strategy
Infrastructure 
and Network 
Design
Distributed
Data Handling
a
c
e
Model Agnostic Design &
Specialized Learning Paradigms
Security
Strategy
f
Privacy
Strategy
g
Trustworthy
Strategy
h
Infrastructure
Threat
Protection
Distributed
Optimization
Data
Model
Design
Meta-Framework Modules
Figure 4:
Meta-Framework overview of the Federated Learning paradigm as a fusion of key modules categorised into
Infrastructure, Data, Threat Protection, Distributed Optimisation, and Model Design.
By embracing this perspective, we shift the understanding of FL from a monolithic paradigm to a structured,
modular ecosystem, where different FL techniques and methodologies can be composed like building blocks. This
enables scalability, cross-domain applicability, and a systematic approach to analyzing, designing, and implementing
FL systems, ultimately leading to more robust federated learning solutions.
We briefly introduce each module:
a) Infrastructure and Network Design: This module focuses on the distributed nature of FL systems, addressing
network resources, communication fidelity, and the physical topology of the distributed network. Applications
with inherently distributed data, such as healthcare, smart agriculture, or energy routing, necessitate custom
infrastructure designs. The network architecture can be modularly adjusted based on FL system types, device
constraints and multiplicity, and organisational participation.
b) Communication Strategy: This module examines the communication protocols underpinning Federated Learning
networks, focusing on both centralised (star-schema) and decentralised (peer-to-peer) architectures. In centralised
networks, a server orchestrates the coordination and aggregation of updates, while decentralised networks distribute
responsibilities among clients, enabling fully collaborative learning without a central authority. Communication
artefacts, such as neural network weights, statistics, gradients, and logits, are key to facilitating efficient knowledge
exchange and collaboration. Furthermore, the synchronicity of communication is explored, addressing the trade-offs
between synchronous and asynchronous approaches in terms of efficiency, scalability, and convergence.
c) Aggregation Strategy: This module addresses the central role of aggregation in combining the learning of multiple
client nodes. Aggregation strategies are critical for balancing contributions from diverse clients, managing data
heterogeneity, and ensuring convergence in distributed learning systems. Furthermore, by integrating an alignment
operator into the optimisation process, this module introduces a richer and more constrained optimisation
landscape, enabling better coordination and knowledge sharing across client models.
d) Distributed Data Handling: This module addresses the challenges of managing distributed data in Federated
Learning. We have categorised datasets and benchmarks commonly used to evaluate FL systems to ease FL
evaluation. While real-world distributed datasets are naturally partitioned across clients, benchmark datasets
require synthetic partitioning to simulate FL settings. Techniques such as Sharding and Dirichlet Distribution-
based partitioning are commonly used to distribute data among clients meaningfully. Additionally, this module
incorporates noisy learning considerations, highlighting the importance of benchmarks that account for label
corruption and adversarial perturbations to evaluate FL systems under realistic conditions.
Frederico Vicente et al.
Page 13 of 70
Modular Federated Learning: A Meta-Framework Perspective
e) Model Agnostic Design & Specialized Learning Paradigms: This module highlights the flexibility of Federated
Learning (FL) as both a distributed optimisation framework and a distributed systems paradigm, enabling it to
adapt to diverse models and tasks. FL‚Äôs model-agnostic nature allows for various optimisation strategies tailored to
local client models, including probabilistic initialisations, global parameter sharing, and transfer learning. Beyond
traditional supervised learning, FL supports specialised paradigms like Reinforcement Learning, which facilitates
collaborative policy optimisation in dynamic environments such as autonomous driving, energy management,
and robotics. By integrating domain-specific requirements while maintaining privacy and scalability, this module
underscores FL‚Äôs adaptability and modularity in addressing real-world challenges.
f) Security Strategy: This module focuses on safeguarding FL systems against a wide range of security threats. These
threats include:
‚Ä¢ Data Poisoning: Altering training data to manipulate the global model.
‚Ä¢ Adversarial Attacks: Modifying inputs to affect system behaviour during inference.
‚Ä¢ Model Theft: Hijacking local or global models.
‚Ä¢ Physical Attacks: Tampering with FL physical nodes to disrupt learning.
Mitigation strategies include Blockchain, Trusted Execution Environments, input validation, and Secure Multi-
Party Computation, ensuring the robustness of FL systems.
g) Privacy Strategy: This module emphasises privacy preservation in Federated Learning (FL) systems. While
FL inherently offers intrinsic privacy by avoiding raw data transmission, advanced techniques further enhance
protection against potential exploitation of communication artefacts.
Privacy threats include:
‚Ä¢ Model Inversion Attacks: Attempts to reconstruct raw data used for training.
‚Ä¢ Membership Inference Attacks: Attack designed to check whether some given data was used for training.
Notable privacy defensive methods include Differential Privacy, which introduces carefully calibrated noise to
shared data to prevent individual information leakage, and Homomorphic Encryption, enabling computations
to be performed directly on encrypted data without decryption. Additionally, Zero-Knowledge Proofs provide a
robust mechanism for verifying the correctness of computations without revealing the underlying data, ensuring
privacy and trustworthiness in sensitive applications. Together, these techniques form a comprehensive framework
for safeguarding data privacy in FL systems, even in adversarial settings.
h) Trustworthy Methodologies: This module addresses the need for trustworthiness [187] in real-world Feder-
ated Learning (FL) deployments. Ensuring fairness, robustness to noisy labels, uncertainty estimation and
explainability in predictions are critical to fostering confidence in FL systems and making them viable for
practical applications. For example, domain-knowledge injection or informed machine learning techniques can
be employed in FL to incorporate expert knowledge or contextual insights into the learning process, improving both
interpretability and performance, particularly in specialised fields such as healthcare or finance.
3. Distributed Optimisation - A Historical Perspective
In this section, we establish a connection between Federated Learning and distributed optimisation/learning
techniques, requiring a time travel to the past for historical contextualisation.
The distributed optimisation problem consists of
minimise
ùë§‚àà‚Ñùùëö
1
ùëÅ
ùëÅ
‚àë
ùëõ‚âî1
ùëìùëõ(ùë§)
(18)
where ùëÅis the number of agents or data and computing centres, and for each ùëõ‚âî1, ‚Ä¶ , ùëÅ, function ùëìùëõis a local
function internal to the agent ùëõand determined by data private to the agent [47, 190].
The Consensus problem and (sub-)gradient optimisation methods. The consensus problem can be found in
many areas of computation, like control and game theory or computer systems [190]. In a peer-to-peer network, a
common task is to compute aggregate measurements, say average file size or CPU usage. In a network consisting
Frederico Vicente et al.
Page 14 of 70
Modular Federated Learning: A Meta-Framework Perspective
of ùëÅnodes, each computing node ùëõcan easily estimate its average file size ùë§ùëõ, and it is connected to other peers
over a network without a central coordinator node [40]. These nodes have to compute the global file size ùë§‚âî
1
ùëÅ
‚àëùëÅ
ùëõ‚âî1 ùë§ùëõ[64, 30, 267, 266, 118, 131].This problem can be generalised to the distributed optimisation problem (18),
by considering a consensus objective functions of ùë§, such as ùëìùëõ(ùë§) ‚âî1
2(ùë§‚àíùë§ùëõ)2, instead of simply computing the
mean ùë§. Minimizing this function encourages ùúîto be close to ùúîùëõ, which aligns with the idea of reaching a consensus
among multiple agents in a system.
Several (sub-)gradient methods were proposed for problems of the form (18) where ùëìùëõare convex functions, with
convergence relying on diminishing learning rates [189]. In Jakovetiƒá et al. [119], two distributed gradient algorithms
were proposed, inspired by the centralised Nesterov gradient descent, well-known for its accelerated convergence
properties. The first method introduced was the Distributed Nesterov Gradient, which significantly enhanced the
efficiency of communications and computations across the network. The second method, Distributed Nesterov Gradient
with Consensus Iterations, added another layer of sophistication but required strongly convex functions, knowledge of
the Lipschitz constant of the gradient of the loss, and knowledge about communication graph connectivity.
Vogels et al. [273] concentrates on studying how sparse averaging in decentralised learning speeds up training, by
enabling larger learning rates in situations where clients share the same data distribution.
Decentralised Exact First-Order Algorithm (EXTRA, Shi et al. [243]) achieves exact convergence to the solution
of the consensus problem. EXTRA is designed to operate with a fixed large step size, which remarkably does not
depend on the network size, and it ensures synchronised iteration across all nodes. Each local variable at agent ùëõ
uniformly converges to the precise minimiser of the global function. Distributed gradient descent (DGD) methods
require diminishing step sizes to converge to an exact minimiser. Both EXTRA and DGD utilise similar mixing matrices
and share comparable complexities per iteration. However, EXTRA leverages the gradients from the last two iterations,
unlike DGD, which uses only the gradient from the last iteration. This modification in EXTRA not only enhances
stability but also improves convergence rates.
Parallel to developments in decentralised optimisation strategies like Jakovetiƒá et al. [119] and EXTRA, from
Shi et al. [243], significant advancements were also made in the field of incremental gradient methods. One notable
contribution was the introduction of SAGA [63], an optimisation algorithm that refines the concepts of earlier methods
like SAG [235], SDCA [238], and SVRG [124]. These algorithms are known for their efficient incremental gradient
updates and fast linear convergence rates. SAGA stands out due to its comprehensive theoretical framework, which not
only improves upon the convergence rates of SAG and SVRG but also extends the applicability of these methods to
more complex optimisation scenarios. One of the key features of SAGA is its support for composite objectives, where
a proximal operator can be applied to the regulariser part of the objective function. This makes SAGA particularly
useful for problems involving regularisation. Further, SAGA can directly handle non-strongly convex problems. It
is also adaptive to any inherent strong convexity in the problem, optimising its performance based on the specific
characteristics of the objective function. This adaptability makes SAGA a versatile tool in both theoretical and practical
settings.
The robust framework introduced by Komodakis et al. [136] for optimising discrete Markov Random Fields (MRFs)
through dual decomposition provided a powerful basis for handling complex optimisation problems in computer
vision. This method effectively decomposed large optimisation problems into smaller subproblems, which were then
solved individually and combined to achieve a comprehensive solution [227]. The strength of this approach lies in its
ability to tailor subproblem selection and use efficient inference techniques, such as graph-cut methods, to enhance
overall algorithm performance and applicability. Building upon this foundation, the 2022 paper by Su et al. [252]
explored the nuances of implementing dual decomposition in more dynamic and less controlled environments typical
of real-world distributed systems. Their research addressed the critical aspects of asynchrony and computational
inexactness‚Äîelements that are often inevitable due to communication delays, packet drops, and the inherent limitations
of computational accuracy within agent-based systems.
Primal-dual algorithms are a class of optimisation methods used to solve problems that can be formulated as saddle-
point problems. The goal is to find a point that simultaneously minimises a primal objective function and maximises
a dual objective function. These algorithms have become essential tools in various fields, such as convex optimisation
and Machine Learning. Primal-dual methods are particularly well-suited for Federated Learning due to their ability
to naturally handle decomposable structures and constraints. In many cases, primal-dual algorithms can decompose
the global optimisation problem into smaller, more manageable subproblems. Each node can independently solve its
subproblem, typically involving only its local data, while dual variables are used to enforce consistency across the
Frederico Vicente et al.
Page 15 of 70
Modular Federated Learning: A Meta-Framework Perspective
nodes. Specifically, consider the problem
minimise
ùê∞‚àà‚Ñùùëö
ùëÅ
‚àë
ùëõ‚âî1
ùëìùëõ(ùê∞),
s.t.
ùëî(ùê∞) = ùëè
(19)
where ùëìis a possibly non-convex function, ùëîis a function from ‚Ñùùëöto ‚Ñùùëë, and ùëè‚àà‚Ñùùëë. To handle the constraints, we
introduce the Lagrangian function ùêø(ùê∞, ùúÜ) ‚âî‚àëùëÅ
ùëõ‚âî1 ùëìùëõ(ùê∞)+‚ü®ùúÜ, ùëî(ùë•)‚àíùëè‚ü©, where ùúÜ‚àà‚Ñùùëëare the Lagrange multipliers,
also called dual variables. In primal-dual methods, we want to find saddle points, i.e., a pair (ùë•‚ãÜ, ùúÜ‚ãÜ) satisfying the
inequalities
ùêø(ùë•‚ãÜ, ùúÜ) ‚â§ùêø(ùë•‚ãÜ, ùúÜ‚ãÜ) ‚â§ùêø(ùë•, ùúÜ‚ãÜ),
for all ùë•and ùúÜ. The inequalities entail that the ùë•‚ãÜmaximises the Lagrangian with respect to the primal variable
ùë•and ùúÜ‚ãÜminimises it with respect to the dual variable ùúÜ. Chambolle and Pock introduced the Primal-Dual Hybrid
Gradient method [45]. It combines primal and dual updates with additional extrapolation steps to improve convergence
properties. The stochastic version of the Primal-Dual Hybrid Gradient algorithm [44] introduces randomness in
the update steps, either by selecting random subsets of data or variables to update, which can significantly reduce
computation time for large-scale problems. A method covering second-order stationary solutions for non-convex
distributed optimisation was presented by Hong et al. [110]. This paper investigates two primal-dual-based algorithms
to solve linearly constrained non-convex optimisation problems. These algorithms utilise first-order information and
are shown to compute second-order stationary solutions (ss2) with probability one. This is significant as it extends
existing results beyond first-order primal-only algorithms, achieving global convergence to ss2 for unconstrained
distributed non-convex learning problems over multi-agent networks. A family of randomized primal-dual block
coordinate algorithms named DSCOVR (Doubly Stochastic Coordinate Optimisation with Variance Reduction, Xiao
et al. [297]) was presented for asynchronous distributed optimisation of large-scale linear models with convex loss
functions. The primary goal is to enhance computational and communication efficiency in distributed Machine
Learning environments. RandProx [56] uses randomized proximal updates. It introduces randomness in updating dual
variables or calling the proximity operator, which reduces computational load while maintaining accuracy.
Alternating Direction Method of Multipliers (ADMM). The ADMM consists of a distributed optimisation
method that tries to solve both a primal and dual problem. The primal problem consists of many local sub-
problems characterised by local variables that condition the solution of the local problem. The dual problem involves
regularisation variables (constraints) distributed across multiple local sub-problems, which are optimised in parallel
by each local optimisation step.
Historically, the ADMM method evolved through some convoluted mutations, sparkling into existence as a result
of an inexact implementation of the Augmented Lagrangian method (ALM), which is further known as the method of
multipliers [91].
Roughly speaking, ADMM is an approximation method to the ALM method, which instead of jointly optimising
the primal and dual variables, takes the block coordinate variation and alternately optimises in blocks respectively the
primal and dual variables. Mathematically speaking, the classical ADMM optimisation problem can be described as:
minimise
ùê∞‚àà‚Ñùùëõ,ùê≥‚àà‚Ñùùëé{Óà∏(ùê∞, ùê≥, ùùÖ) ‚à∂= ùëì(ùê∞) + ùëî(ùê≥) + ‚ü®ùê¥ùê∞+ ùêµùê≥‚àíùêõ, ùùÖ‚ü©
+ ùúé
2 ‚Äñùê¥ùê∞+ ùêµùê≥‚àíùêõ‚Äñ2}
(20)
where ùúãrepresents a dual variable (Lagrange multiplier), to enforce the constraint suggested by the equation
ùê¥ùë§+ ùêµùëß= ùëè. The ùë§and ùëßrepresent the variables being optimised, subject to the ùëìand ùëîobjectives. The term
ùúé
2 ‚Äñùê¥ùê∞+ùêµùê≥‚àíùêõ‚Äñ2 penalises deviations from the constraint defined, where ùúéconsists of an hyper-parameter controlling
the penalty level.
Throughout many decades, the ADMM method has been presented in many flavours: Symmetric ADMM; Fast
ADMM, Generalised ADMM, Linearised ADMM, and Stochastic ADMM.
Frederico Vicente et al.
Page 16 of 70
Modular Federated Learning: A Meta-Framework Perspective
Regarding convex problems over distributed optimisation problems ADMM, has also been proven to have some
well-behaved properties (e.g. linear convergence: Shi et al. [244]).
If we eliminate the dual constraints in the ADMM formulation, the resulting optimisation problem closely
resembles a standard FL setting. Specifically, the global model in FL can be viewed as a regulariser that guides the local
models toward consensus. This perspective highlights how ADMM provides a principled way to enforce agreement
between local models while allowing for personalization, a key characteristic of many FL approaches.
In particular, consider the following formulation Eq. (21), where ùê∞represents the global model and ùêñcontains
the local models across clients:
minimise
ùê∞‚àà‚Ñùùëõ,ùêñ‚àà‚Ñùùëõ√óùê∂
{
Óà∏(ùê∞, ùêñ, Œ†) ‚à∂=
ùê∂
‚àë
ùëñ=1
ùìÅ(ùê∞, ùêñùëñ,

ùùÖùëñ
)
}
ùìÅ(ùê∞, ùêñùëñ,

ùùÖùëñ
) ‚à∂= ùëìùëñ
(ùêñùëñ
) +((((((
‚ü®ùêñùëñ‚àíùê∞, ùùÖùëñ‚ü©+ ùúéùëñ
2
‚Äñ‚Äñùêñùëñ‚àíùê∞‚Äñ‚Äñ
2 .
(21)
By removing the dual variables (denoted by the cancellations), the optimisation objective retains a structure similar
to FL, where each client optimises its local objective ùëìùëñ(ùêñùëñ), and the global model ùê∞acts as a soft constraint via the
quadratic regularization term. This term encourages local models to remain close to the global model but still allows
deviation based on local data heterogeneity.
Consequently, ADMM can be seen as a generalized framework that unifies FL with constrained optimisation
principles. By introducing or removing dual constraints, one can transition between explicit enforcement of consensus
(via Lagrange multipliers) and a more flexible regularization-based approach, as commonly used in FL. This connection
provides a valuable perspective through which FL methods can be analyzed and extended using optimisation techniques
from ADMM.
For further exploration of ADMM, we invite the reader to read [311].
Block Coordinate Descent. Classic Block Coordinate Descent (BCD) scheme, introduced by Bertsekas and
Tsitsiklis [22], explores an optimisation algorithm where the variables get dispersed in different nodes, and the iterative
progression of its solving can be described as an alternate optimisation step on each individual or block of variables,
each block at a time, while the others are locked. In a sense, Federated Learning follows this pattern if we encapsulate
the several varieties and flavours it builds upon. In FL, each client is solving a subset of variables (a block) of variables
and later on, in the aggregation step, a consensus is obtained.
Token/random-walk Optimisation. The Distributed Token/random-walk optimisation method is historically
described as an iterative process which permits the optimisation of a set of variables which hop between a graph
of distributed nodes and is solved locally using each node‚Äôs data (Ram et al. [216] uses the iterate term instead of the
token term: Johansson et al. [123]). The simplest and classical version of the distributed token optimisation method
utilises only one token per federation network, meaning that no parallel global model learning is performed. Having
this in mind, multiple token approaches to increase learning convergence have been tried using semi-decentralised
communication topology [270] and using the augmented lagrangian method [48].
Clustering. Before Federated Learning was introduced, numerous research had focused on the study of clustering
techniques within distributed networks. These studies cover from optimised distributed communication to distributed
learning. HEED [315] dives into the conceptualisation of a hierarchical clustering technique to reduce energy
consumption, whilst producing well-distributed cluster heads.
Distributed Optimisation techniques often resort to a collaboration between all clients/agents, since it is assumed
all agents are interested in an equal objective. However, this is not always the case [163] and this cooperation might
even damage the optimisation process (consider non-iid data for instance). Clustering can help mitigate this issue by
allowing agents to be grouped according to a similar objective, hence helping the convergence [335].
Federated Learning. The FedAvg [177] algorithm, marked a significant step in distributed machine learning.
However, its design prioritized simplicity and scalability for real-world deployment, overlooking foundational
Frederico Vicente et al.
Page 17 of 70
Modular Federated Learning: A Meta-Framework Perspective
principles from mathematical distributed optimisation. This pragmatic focus led the field to naturally diverge into two
complementary directions: one emphasizing the rigorous mathematical underpinnings of distributed optimisation, and
the other centering on privacy-aware distributed learning, addressing concerns like user data security and regulatory
compliance.
This divergence reflects the dual demands of Federated Learning: the need for efficient solutions to real-world
constraints and the importance of theoretical guarantees for optimisation. Over time, subsequent works have increas-
ingly bridged these perspectives, enriching Federated Learning with both practical innovations and mathematical rigor.
Notable contributions include FedBCD [167], which adapts block coordinate descent methods to federated settings;
Inexact Federated ADMM [339], which integrates Alternating Direction Method of Multipliers (ADMM) into FL;
Multi-Token Federated Learning [270], which enhances communication efficiency; and Stochastic Clustering FL [324],
which introduces clustering techniques to improve training dynamics.
4. Dissecting the Federated Learning Meta-Framework
In this chapter, we present the Meta-Framework modules that structure the Federated Learning (FL) paradigm
(Section 2.4). Consisting of eight key modules, this Meta-Framework taxonomy not only enhances conceptual
understanding but also serves as a foundational blueprint for designing FL systems and frameworks.
4.1. Infrastructure and Network Design
The design of a Federated Learning system is shaped by its underlying infrastructure and network architecture,
which influence its efficiency, scalability, and robustness. FL operates across diverse environments, from resource-
constrained edge devices to high-performance servers, requiring careful consideration of computational resources,
connectivity, and communication overhead.
Key challenges include accommodating heterogeneous devices with varying capabilities, managing resource
constraints in low-power systems, and mitigating communication bottlenecks that impact training efficiency. Optimised
system design must balance these trade-offs while ensuring seamless coordination and reliable model convergence.
This section examines the infrastructural foundations of FL, exploring strategies to enhance performance and
scalability in real-world deployments.
4.1.1. Heterogeneous Network Node Requirements
Resource Limitations of Edge Devices. Edge devices, such as microcontrollers, lack the powerful resources
available in cloud devices, personal computers, or mobile phones. These devices are typically composed of low-
capacity CPUs, limited memory, and low power, often lacking GPUs. RAM is often limited to kilobytes, and CPU
speeds are bound to megahertz.
Embedded systems, composed of hardware and specific embedded OSs, can be categorised into three types [340]:
1. Type I: Full-functional hardware with a general-purpose OS.
2. Type II: Hardware with a non-general-purpose OS and computational limitations.
3. Type III: Slave devices without an OS, such as USB storage devices.
Heterogeneity of Embedded Systems. FL solutions must account for the resource heterogeneity of embedded
processors, which range from ARM architectures to x86, FPGAs, and AI accelerators. Devices like Arduinos,
Raspberry Pis, Nvidia Jetsons, and Google Edge TPUs vary significantly in resource capabilities. Standardised
frameworks, such as Edge Impulse [116] and ONNX Runtime [70], help bridge this gap by enabling model deployment
across diverse devices.
4.1.2. Memory and Resource Constraints
Low-Memory Devices. Training deep learning models on devices with stringent memory limitations requires
innovative solutions. For instance, Lin et al. [160] demonstrates techniques for training models within 256 KB of
memory. Traditional frameworks like PyTorch or TensorFlow are unsuitable for such environments due to their
significant memory overhead.
Bare-Metal Frameworks. Bare-metal frameworks, such as LiteRT [95], enable low-memory neural network
inference but lack support for continuous learning. These frameworks are optimised for pre-trained model deployment
rather than iterative training, which is essential for FL.
Frederico Vicente et al.
Page 18 of 70
Modular Federated Learning: A Meta-Framework Perspective
Strategies for Resource Efficiency. To address these constraints, several methods are employed:
‚Ä¢ Model Quantisation: Reduces precision levels (e.g., from 32-bit to 8-bit) to minimise memory consumption,
enabling efficient model deployment on resource-constrained devices. Quantisation is particularly effective for
reducing communication overhead in FL scenarios [98].
‚Ä¢ Model Pruning: Removes non-essential parameters while preserving performance, focusing on simplifying
the model structure without significantly impacting accuracy [274]. Pruning can dynamically adjust model
complexity to match the capabilities of edge devices [113].
‚Ä¢ Sparse Representations: Utilises sparsification to retain only critical features, reducing the density of model
weights and gradients. This approach decreases transmission size during communication rounds and improves
scalability in FL settings [285].
‚Ä¢ Early-Exit Training: Allows intermediate layers to produce predictions, reducing computational costs and
enabling inference to terminate earlier when confidence thresholds are met [259]. This technique is well-suited
for time-sensitive applications on low-power devices.
‚Ä¢ Split Learning: Distributes the training process between devices and servers, lowering resource requirements
on edge devices by offloading computationally intensive tasks [99].
Split Learning [272] is a paradigm to train and infer over Machine Learning models, whilst computing entry and
end points of neural network layers on the client side and further moving the intermediate heavy computation
to the server side (See Fig 5). SplitNet [134] extended the neural network splitting idea to a tree-like neural
network, where the model is layer-wise split concerning its classes/features to reduce the parameters usage and
computation overhead. Split Learning also enhances privacy by transmitting intermediate representations instead
of raw data and can also be combined with privacy-security mechanics, such as homomorphic encryption to
preserve client data better [132].
Client
Client
Server /
Cluster
Input
Output
Heavy
Computation
Figure 5: Abstract depiction of Split Learning, which shares a neural network model computational execution between
clients and more computational-powered servers.
Even though Split Learning and Federated Learning are different learning paradigms, they share some principles
(e.g. privacy-preserving, distributed computing) and can be composed. SplitFed [262] presents a solution to deal
with the downside of the heavy computation of ML on the client side, by relieving the clients‚Äô heavy computation
to server computation nodes, but still relying on a Federated Learning network of nodes who collaborate their
learning.
On the health domain, Vepakomma et al. [272] utilises Split-NN to showcase the surprisingly better efficiency
and the accuracy possible to achieve when compared with default Federated Learning [177] and synchronously
distributed SGD [49] solutions.
‚Ä¢ Knowledge Distillation: Facilitates the transfer of knowledge from a larger, more complex model (teacher) to
a smaller, simpler model (student) [127]. This technique is particularly effective for addressing data and model
heterogeneity in FL, enabling lightweight models to benefit from collaboratively learned knowledge without
directly accessing raw data.
Frederico Vicente et al.
Page 19 of 70
Modular Federated Learning: A Meta-Framework Perspective
4.1.3. Communication Challenges and Protocols
Heterogeneous Communication Networks. Devices in FL often connect through diverse networks, including
fibre optic, 3G, 4G, 5G, and Wi-Fi [196].In some cases, the complexity is further increased by the use of analogue
over-the-air communication [309]. This heterogeneity impacts communication cost and complexity, introducing delays
and potential failures in client-server artefact exchanges.
Communication Protocols. FL frameworks employ various communication protocols to address these challenges:
‚Ä¢ gRPC: Designed for real-time streaming and large data loads, supporting synchronous and asynchronous
communication [23, 250, 224].
‚Ä¢ AMQP: Message-oriented middleware enabling features like queues and publish-subscribe mechanisms,
suitable for distributed computing [169].
‚Ä¢ MPI: A parallel computing protocol ideal for large-scale, CPU-oriented tasks in homogeneous infrastruc-
tures [107].
4.1.4. Learning Scheduling
FL can employ either offline or online learning schedules:
‚Ä¢ Offline Learning: Infrequent training sessions with potential model architecture updates between sessions.
‚Ä¢ Online Learning: Continuous updates to adapt to real-time data changes and counteract data drift, ensuring
robustness in production environments [180].
4.2. Aggregation Strategy
Aggregation lies at the core of FL, serving as the mechanism to combine knowledge from multiple clients into a
global model. This process determines how local updates are merged and plays a pivotal role in ensuring the efficiency,
robustness, and fairness of the FL system. Various aggregation methods have been developed to address challenges
such as data heterogeneity, communication constraints, and model convergence. Popular strategies, like FedAvg [177],
rely on simple averaging, but more sophisticated techniques introduce client weighting, regularization, or feature-based
aggregation to enhance performance and adapt to diverse client environments.
To further refine the aggregation process, additional constraints or guiding principles may be applied. We explore
this concept in a dedicated subsection, introducing the alignment operator Óà≠as a complementary tool to constrain and
guide aggregation for specific objectives.
The original and most popular algorithm in Federated Learning is the FedAvg algorithm [177], which can be
depicted as an optimisation problem solved by minimising the average aggregation function:
minimise
ùúÉ,{ùúÉùëê}ùëÅ
ùëê=1
Óà≥(Óà∏(ùúÉ1), ‚Ä¶ , Óà∏(ùúÉùëÅ)) .
(22)
FedAvg averages the local optimised parameters, obtained from each client at round ùë°of the global learning proce-
dure. The method‚Äôs popularity, despite good results, disregards client data heterogeneous distributions. Consequently,
in non-homogeneous data scenarios, standard FedAvg works poorly [336].
Relying primarily on the aggregation function Óà≥to optimise a Federated Learning problem is suboptimal, as there is
no basis to assume that the average of local client solutions will yield a better model for all clients [336]. Consequently,
the field has begun to explore various aggregation techniques and the communication of diverse knowledge artefacts,
beyond local losses and model weights, initially investigated by FedAvg McMahan et al. [177].
FedProx [151] is a generalisation of the FedAvg algorithm to address the heterogeneity of the distributed data. It
adds a proximal term to the local client loss to regularise the learning model, encouraging the local model to remain
close to the global model.
SCAFFOLD [130] stands as an extension to the FedAvg algorithm with a better convergence rate, especially on
heterogeneous data and it is invariant to sampling techniques. SCAFFOLD work shows that training for many epochs
without communication rounds can deteriorate the global model performance by losing the sensibility to the client‚Äôs
data, also known as client drift. In its essence, SCAFFOLD battles the same issues as FedProx and can be seen as
Frederico Vicente et al.
Page 20 of 70
Modular Federated Learning: A Meta-Framework Perspective
an upgrade to the distributed optimisation algorithm DANE [240], using stochastic control variables. SCAFFOLD
experiments with the idea that commonly clients are disjoint in their distributions, but there can be similarities in some
of them, therefore different step sizes should be accountable for better global and local optimum convergence.
Power-of-Choice [54] studied how biasing the selection of clients through their learning loss can improve error
convergence.
Inexact Federated ADMM [339] explores a practical federated implementation of the Alternating Direction Method
of Multipliers (ADMM) algorithm considering the small distributed sub-problems as the local models being optimised
by clients in a federation and overcomes inefficient computations by utilising a cohort of clients instead of the full
federation.
Concerned with the client drift phenomenon, FedFish [71] focuses on aggregating local approximations to the
functions learnt by the respective clients, using an estimate based on their Fisher Information, whilst defending the
idea that the model aggregation technique used in FL plays a major role in the client drift. They present a genuine
metric to evaluate the impact of their aggregation procedure: the Client-Server Barrier. Given a performance metric,
this metric measures on average the distance between the evaluation of the function over the parameter space of the
federation local models and the server global model.
All these previous methods mentioned resort to a single server for the aggregation phase, however, there is also an
aggregation type that distributes the aggregation phase into several servers (e.g. Prio [59], Prio+ [3]).
Studying the impact of different federated aggregation algorithms, FedDecorr [245] has shown that under
data heterogeneous scenarios FL aggregation schemes lead to greater dimensional collapse. Therefore, FedDecorr
introduced a loss regularisation term, which encourages different dimensions of representations to be uncorrelated.
4.2.1. Personalised Aggregation
In a Federated Learning setting, each client learns a local independent model, which can be seen as a personified
compression of local client data. Personalised Federated Learning harnesses the intrinsic nature of individual data
while exploring methods for a model to gain a comprehensive understanding of clients‚Äô data on a global scale through
model sharing. At the local level, however, the approach involves incorporating insights from other clients, ensuring a
balance between leveraging collaborative knowledge and prioritizing the integrity of the local data and the local model.
FedFish [71] demonstrates promising post-personalisation results when data is majorly heterogeneous and locally
fine-tuned for a few steps after the Federated Learning procedure finishes. They also suggest a way to evaluate
personalisation performance: Client Personalisation Performance. Client Personalisation Performance consists of a
metric for assessing personalisation quality, defined by taking the global model previously trained using an FL
procedure followed by a fine-tuning and evaluation process over a set of clients over local unseen data. The metric
then calculates the average performance of the federated fine-tuning evaluation.
pFedMe [255], similar to FedProx [151] develops a regularisation method to soften the parameter sharing between
clients, by utilising a Moreau Envelope term in the loss function, which controls the weight of the influence of the
global model over the local models.
Sharma et al. [242] leverages user feedback (pseudo-labels) to customise local models for individual users while
maintaining robustness against noisy feedback.
FedPac [302], uses a feature-alignment procedure to align the local models, where a weighting of local versus a
global model is learnt for each client to better adjust locally to the heterogeneous data distribution.
kNN-Per [176] proposes a personalisation mechanism based on local memorisation, which uses a standard FedAvg
algorithm for federated aggregation, but after each local training procedure stores in a local store database the (key:
value) pairs of the data samples with the corresponding local model learning representations. Finally, in inference mode,
it queries a specific client with an input and based on it, the client computes the k-nearest neighbours over the local
dataset and interpolates between the global model and these local intermediate results to obtain the final prediction.
Through their experiments, they state that the memorisation technique‚Äôs usefulness lies greater when distribution shifts
coexist between clients.
Parameter Decoupling. One technique found in the penalisation take of Federated Learning separates a model into
two parts: the knowledge encoding representation sub-model (the body) and the classifier (head). Some research papers
suggest training locally the body whilst maintaining the classifier head globally for all clients, others do the opposite.
FedRep [55], for instance, shares an authentic view of heterogeneous data settings. They transmit the idea, that
labels may have different distributions over clients, but the underlying features which encode those labels share similar
Frederico Vicente et al.
Page 21 of 70
Modular Federated Learning: A Meta-Framework Perspective
patterns, a common representation. Consequently, they deeply explore the low-dimensional space understanding as the
bare bones of the features, to learn a global learning representation structure, which is personalised at the local/client
level. The clients and the server focus on learning a global representation together, while each client learns their final
layer locally conserving the personal properties of the local client data.
Federated Averaging with Body Aggregation and Body Update (FedBABU, Oh et al. [197]) explores the parameter
decoupling method where the head is locally personalised (finetuned) and the body (representation learning part) is
aggregated from the multiple clients.
4.2.2. Feature-Based Aggregation
Heterogeneous environments, where clients in a federation have non-iid data distributions hinder some aggregation
methods (e.g. FedAvg). Furthermore, deep learning applications have proven that network bottlenecks are great for
encoding meaningful feature representations. Therefore, instead of blindly aggregating network parameters, which not
only showcases limitations to non-iid data but also limits models to homogeneous architectures, what if we could map
weights meaningfully when aligning client models?
This question sparked several works to try the collaboration of clients‚Äô models in between feature representations.
FedPac [302], builds upon the FedAvg algorithm but adds a regularisation term penalising the distance between the
global feature centroid of a class ùë¶ùëñand the client local feature embedding of the respective data point ùë•ùëñ.
Differently, ùëìùëíùëë2 [318] presented a feature-aligned method, where the parameters are combined considering the
semantic alignment between them. Each model‚Äôs weights are grouped by their similar features and are consequently
combined through an average operation. In a general sense, ùëìùëíùëë2 minimises the total feature-level parameter variance
among the federation collaborative nodes.
4.2.3. Knowledge Distillation Aggregation
Knowledge Distillation (KD) is a kind of meta-learning algorithm, which assumes the existence of two model
types (the teacher, and the student). The teacher normally corresponds to a larger model trained on a task and the
student corresponds to a weaker model, which is trained by absorbing the wisdom of the larger model using fewer
parameters (model compression, Wang et al. [278]). Even though knowledge distillation was initially designed as
a model compression mechanism, the notion of cooperatively sharing knowledge between homogeneous models to
improve performance has gained track (Codistillation, Anil et al. [9]).
Applied to FL, the cooperation of teacher-student learning can be thought of as an assembled distillation, in which
a global model is a student and several clients are teachers passing on their knowledge to the global model.
The model aggregation operation, typically encountered in the distillation process is the Kullback‚ÄìLeibler
Divergence (KLD), which makes use of the models‚Äô prediction logits to approximate the learnt distribution of one
model (local model) and the other (global model). This conceptualisation is important since it means that the model
predictions must be present in the aggregation server during the models alignment procedure. Furthermore, as the local
data is heterogeneous and private (non-present in the aggregation server) most works use a public dataset to ensure the
alignment is possible in heterogeneous systems [146, 79].
Since the availability of public datasets, in the FL domain, is scarce, some works have tried to use KD without
them [120, 257].
FedRad [257] introduces relational knowledge [204] and single-sample knowledge into the loss function of
cooperative distillation optimisation. During the local distillation alignment, it weights each homogeneous model,
through predicted entropy to control the penalty of each model loss. The global aggregation can be described as the
standard FedAvg, averaging an updated version of each client‚Äôs global models.
Considering heterogeneous models, proxy model sharing work [127] follows a different paradigm, first by being
a decentralised FL solution, secondly by utilising a special homogeneous proxy model (global model: all the clients
share the same proxy architecture, but each one has a unique version of it), which is shared directly between clients.
Hence, in every training iteration, the local model of each client utilises KD to incorporate knowledge from the proxy
model of the other client. In parallel, as the proxy model assimilates knowledge from the local model before returning
to its original client, the local model also absorbs the knowledge from the proxy model. This establishes a reciprocal
exchange of knowledge between the two models.
Frederico Vicente et al.
Page 22 of 70
Modular Federated Learning: A Meta-Framework Perspective
4.2.4. Token-Based Aggregation
We have explored techniques to align the shared federation knowledge into one global understanding of the localised
data/task. The Token aggregation method is a method where the global model (the token) periodically hops between the
federation network, according to some heuristic (e.g. random walk: Hendrikx [109]) and either aggregates the node‚Äôs
local model with the global model or trains the global model directly over the client‚Äôs data. No server is required, as
the token communicated between the nodes acts as the global model; thus, this alignment technique can be categorised
as a decentralised method [270].
4.2.5. Attentive Aggregation
In many real-world FL scenarios, clients exhibit heterogeneous data distributions, varying reliability, or differing
contributions to model performance.
Attentive Aggregation addresses this challenge by dynamically weighting client updates based on their relevance,
or reliability to the global model. Inspired by attention mechanisms commonly used in deep learning, these techniques
enable FL systems to focus more on valuable updates, leading to improved model convergence and robustness.
FedAtt [121] builds on the FedAvg algorithm but enhances it with an attentive aggregation algorithm, allowing the
global model to prioritize updates from more informative or reliable clients. Further enhancements and variations are
proposed in [122] and [263], integrating transformer-based attention models to refine the aggregation process.
4.2.6. Concatenation Aggregation
In Vertical Federated Learning, where clients hold complementary features for the same set of users, a common
approach to combining knowledge is Concatenation Aggregation. This method capitalizes on the distributed nature
of feature sets by computing embeddings independently on each client. These embeddings are then transmitted to a
central server, where they are concatenated to form a unified latent representation for downstream processing [271].
This concept builds on the principles of split neural networks, where model layers are distributed across different
network nodes [99].
Concatenating the clients‚Äô latent transformations of their data is particularly effective in scenarios where clients
contribute distinct and non-overlapping features. By integrating these embeddings at the server, the system achieves a
holistic representation of the data without requiring direct data sharing, thereby ensuring privacy. The server processes
the concatenated embeddings to perform tasks such as prediction or classification, leveraging the collective knowledge
embedded in the distributed features.
Split Neural Networks [41, 99] also follow a concatenation aggregation operation. They are designed as a distributed
model learning framework, consisting of a local client feature embedding process and a server-side end-tail of the
model. The server-side leverages the several sub-model embeddings being produced at the client level and combines
them as sub-representations for the tail heads of the server model. After this distributed feedforward process ends,
back-propagation is performed on the server and the server returns the jacobians to the client so they can perform
their respective local back-propagation (See Fig. 6 for an abstract depiction of a Split-NN architecture). Split Neural
Networks also slightly distance themselves from the split learning framework, since only the initial feature mapping is
computed on the client side when using Split Neural Networks.
However, while Concatenation Aggregation enables collaboration within Vertical Federated Learning, it poses
challenges related to communication overhead and client synchronization. Efficiently optimising embedding dimen-
sions and minimising redundancy in the concatenated representation are crucial to enhancing both the scalability and
performance of this approach.
4.2.7. Alignment Operator as a Complement to Aggregation
In this section, we have explored aggregation as a family of operators for combining local updates in Federated
Learning. Building on this, we introduce the notion of an alignment operator, Óà≠, as a complementary mechanism
to the aggregation operator, a generalised taxonomy inspired by numerous works [103, 11, 19]. While aggregation
focuses on merging knowledge across clients, alignment provides a framework to constrain and guide this process to
meet specific objectives, such as fairness, convergence, or robustness.
As discussed in Section 2, the alignment operator Óà≠imposes constraints on how knowledge is shared and
aggregated within the federation (see Eq. 23). This additional layer of control enables FL systems to better handle
challenges arising from data heterogeneity, diverse client capabilities, and varying optimisation goals.
We recall the problem formulation, introducing the alignment constraining operator:
Frederico Vicente et al.
Page 23 of 70
Modular Federated Learning: A Meta-Framework Perspective
X1
ùû±1
h1(ùû±1)
Xn
ùû±n
hn(ùû±n)
A(‚Ä¢)
‚Ä¢‚Ä¢‚Ä¢
h0
ùû±0
f(ùû±0 )
Figure 6: Split-NN architecture overview. Distributed Learning network where each client trains an intermediate
representation and shares it with a server, which then fuses them, applies backpropagation, and defuses the update
with the clients.
minimise
ùúÉ,{ùúÉùëê}ùëÅ
ùëê=1
Óà≥(Óà∏1(ùúÉ1), ‚Ä¶ , Óà∏ùëÅ(ùúÉùëÅ), Óà∏(ùúÉ))
s.t.
Óà≠(ùúÉ, {ùúÉùëê}ùëÅ
ùëê=1
) ‚â§ùúñ,
(ùúÉ, {ùúÉùëê}ùëÅ
ùëê=1
) ‚ààŒò.
(23)
The alignment operator plays a pivotal role in refining the aggregation process by introducing targeted constraints
and objectives. For example:
‚Ä¢ Client Prioritisation: Alignment can prioritise updates from specific clients based on their data quality,
importance, or relevance to the global objective.
‚Ä¢ Balancing Data Heterogeneity: By guiding aggregation to account for non-iid data distributions, alignment
can mitigate biases and ensure fair contributions across clients.
‚Ä¢ Feature Representation Alignment: Alignment can synchronise feature representations across models, pro-
moting consistency and enhancing collaborative learning outcomes.
By complementing the aggregation operator, alignment strategies allow Federated Learning systems to achieve
more targeted and efficient outcomes. This synergy between aggregation and alignment expands the optimisation
landscape, providing additional flexibility to address the complex demands of real-world FL scenarios.
For a comprehensive review of Model Aggregation Strategies, refer to the survey by [212].
4.3. Communication Strategy
The strategy to communicate different content between federation clients can be segregated into 5 main categories:
1. Communication Topology; 2. Learning Periodicity; 3. Content; 4. Compression. 5. Client Selection.
4.3.1. Communication Topology
The design of different topology solutions for a distributed system is driven by multiple factors:
‚Ä¢ Simplicity and ease of deployment/debugging: A well-structured topology simplifies implementation and
maintenance.
‚Ä¢ Robustness to single points of failure: Decentralised or redundant structures prevent system-wide disruptions.
‚Ä¢ Faster convergence: Optimised topologies can accelerate model synchronization and training efficiency.
‚Ä¢ Mitigating trust issues between entities: Certain topologies help address concerns related to data privacy and
inter-organizational collaboration.
Frederico Vicente et al.
Page 24 of 70
Modular Federated Learning: A Meta-Framework Perspective
The most popular architecture topologies for Federated Learning are centralised (star schema) networks, decen-
tralised networks and semi-decentralised networks, which represent a hierarchical mixture of both server-dependent
(centralised) network and peer-to-peer (decentralised) communication (See Fig. 7).
Server
C0
C1
CN
Server-Client ('centralised')
Decentralised
C1
CN
C0
Semi-Decentralised
C1
CN
C0
C3
CN
C2
C5
CN
C4
Server
Figure 7: Comparison of distributed network topologies: (Left) Centralised server-client star schema with a single control
point. (Middle) Decentralised peer-to-peer system with direct client communication. (Right) Semi-decentralised topology
combining peer-to-peer and server communication.
Decentralised Learning. Cross-silo Federated Learning (FL) combines resources from different organisations,
which can raise trust concerns on centralised FL since the organisations must cooperate on central server behaviour.
Decentralised FL can diminish these concerns, by utilising Peer-2-Peer (p2p) communication, removing the need
for a central server. This is beneficial since it reduces bandwidth communication and makes the system more reliable
to infrastructure failures.
The work of FL Proxy Model Sharing [127], for example, proposes a mesh of nodes, which learn both a private
model and a proxy one which is shared and aggregated each round with a peer node. They control the distillation of
knowledge by adjusting a weight between the knowledge transfer of the private to the proxy, and the inverse.
Sharing model parameters faces the risk of saturating a network, (the Large Language Model, Llama-2, for instance,
accounts for 70 Billion of parameters [264]), therefore being able to exchange a distillation of knowledge instead of the
actual model parameters is communication-wise beneficial. Not only does this approach lighten the communication
bottleneck, but it also better protects the privacy of the raw data used for training.
BrainTorrent [225] proposed a simple p2p Federated Learning setup. In this setting, each client maintains a local
model and a data structure that records the model versions of other network clients. At each communication step, a
client requests model updates and local dataset size from other clients with a more advanced model version to perform
a standard weighted aggregation locally.
Gossip-based protocols are also widely explored in p2p federated networks [108, 50]. FedDual [50] explores the
use of a pair-wise gossip protocol to extract knowledge from neighbouring nodes. Additionally, it addresses privacy
and security concerns commonly associated with distributed communication by introducing a Gaussian mechanism to
perturb each weighted local gradient.
Additionally, token-based methods are frequently used in decentralised learning to optimise communication
bandwidth. A token model circulates between nodes, progressively aggregating knowledge before periodically
synchronizing with other nodes to enhance global learning [109].
Peer-to-peer networks also play a fundamental role in blockchain technology, serving as the underlying infrastruc-
ture that enables decentralization. In a blockchain system, nodes communicate and validate transactions directly with
one another in a distributed p2p network. This architecture enhances fault tolerance, security, and censorship resistance,
making it a crucial component of blockchain-based applications, including FL [162].
Regarding privacy and security concerns in decentralised federated learning, Hallaji et al. [100] provides a
comprehensive summary in a survey format.
Semi-decentralised Learning. Straggler nodes deteriorate the convergence of FL as the computed local updates
become stale/delayed. Therefore, fully trusting client nodes to deliver their learning progress hinders the progress
of the global learning process. Semi-decentralised FL is designed to be a hybrid approach between centralised and
decentralised communication systems. More precisely, as a whole the system is distributively centralised (relies on
a server), but in extreme edge cases, it uses peer-to-peer communication to encompass network issues fairly [313].
Frederico Vicente et al.
Page 25 of 70
Modular Federated Learning: A Meta-Framework Perspective
As expressed by Yemini et al. [313], there are two types of stragglers: Computation-limited stragglers (type I) and
communication stragglers (type II). They suggest and develop a method to utilise neighbour clients to surpass straggler
(type II) issues, where local updates are conveyed to the central server with the help of neighbouring nodes, when the
direct connection with the central server is not optimal.
4.3.2. Synchronous and Asynchronous Coordination
Standard Federated Learning methods (e.g. FedAvg [177], FedProx [151]), can be described as Synchronous
Federated Learning since they follow an iterative and incremental recipe, where the server waits for a client
agglomeration Cohort to finish local training and consequently, the clients wait for the server to aggregate the global
model and share with the clients again. This synchronous behaviour makes the system agnostic to client/server
resources, being dependent on Stragglers, which are the slowest clients to perform training on a communication round.
Synchronous Federated Learning. Synchronous Federated Learning is designed for low-concurrency use cases
and is preferred due to ease of analysis/debugging and privacy guarantees. However, in high-concurrent cases, where
the system follows a cross-device FL architecture, characterised by the clients having different compute power and
intermittent availability, an Asynchronous approach can help with training speed (See Fig. 8).
Server Update
Server Update
Time (s)
Number of
Federation
Clients
Training
100
50
Waiting for
Straggler
Waiting for
Cohort to be
formed
Synchronous FL
Asynchronous FL
Maximum 
Concurrent
Clients
Figure 8: Impact of stragglers on Synchronous vs Asynchronous Federated Learning. Initially, both approaches behave
similarly, but after cohort formation, asynchronous servers/clients progress faster by not waiting for stragglers, leading to
quicker convergence in fewer training rounds.
Asynchronous Federated Learning. Asynchronous Federated Learning deviates from the synchronous process in
an attempt to accelerate the convergence of the learning procedure, by reducing the effect of Stragglers.
FedBuf [192] assumes the existence of Stragglers in the learning communication process and attempts to mitigate
this effect by utilising buffered asynchronous aggregation. The server contains a buffer that awaits ùêæclients to send
their local updates and aggregates these model parameters. The learning process and communication are performed
asynchronously between the clients and server and utilising privacy-aware and secure techniques like Differential
Privacy and Secure Aggregation.
Papaya [115] extends FedBuf‚Äôs work using a Trusted Execution Environment for secure aggregation and demon-
strates that AsyncFL can achieve more fair models than SyncFL with over-selection. Over-selection is a technique used
in SyncFL, corresponding to dropping slow clients‚Äô train results. Ultimately, this behaviour can develop a bias towards
faster-performant clients.
It is worth pointing out that Asynchronous FL, inevitably, introduces a phenomenon named staleness. Since clients
independently start training new models without global convergence, some clients continue training over previous
server model versions. One solution to this staleness factor is establishing a timeout limit, after which a pre-defined
amount of time a straggler model is removed from an update phase [115].
Semi-Synchronous Federated Learning. To mitigate the stillness of fast learners in Synchronous policies, the
Semi-Synchronous FL policy was introduced [251] allowing every learner to stop, not in terms of convergence metrics
but according to pre-defined synchronisation time point. The selection of this time threshold is based on the maximum
Frederico Vicente et al.
Page 26 of 70
Modular Federated Learning: A Meta-Framework Perspective
Table 2
Learning Scheduling Policies comparison. Adapted from Stripelis et al. [251].
Protocol
Processing
Cost
Communication
Cost
Energy
Cost
Iddle-free
Stale-free
Synchronous
High
Low
High
√ó
‚úì
Asynchronous
Low
High
Medium
‚úì
√ó
Semi-Synchronous
Low
Low
Low
‚úì
‚úì
time it takes for the federated straggler to finish training. Semi-synchronous FL, is therefore dependent on network
statistics, requiring an initial training round to collect the respective cohort statistics.
Examine Table. 2 for a comparison summary of different policies for scheduling training sessions.
4.3.3. Communication Content
Since the inception of Federated Learning, numerous approaches have been developed to enable effective
communication between clients and servers. Within this scope, a variety of communication content alternatives have
emerged, each tailored to address specific challenges like privacy, efficiency, and scalability.
Early Approaches. The foundational methods, FedAvg and FedSGD [177], introduced the concept of learning a
global model by sharing:
‚Ä¢ Neural Network Parameters (FedAvg): Clients share their locally trained model parameters for aggregation
into a global model [177].
‚Ä¢ Loss Gradients (FedSGD): Clients transmit gradient updates computed from their local data [177].
Advanced Communication Content. To improve privacy, or communication efficiency, or communication het-
erogeneity, several alternative communication payloads have been proposed:
‚Ä¢ Proxy Models: Proposed in Kalra et al. [127], these act as knowledge compression mechanisms, enabling
efficient transmission of compressed model knowledge between clients and servers.
‚Ä¢ Model Parameters with Noise Masks: Introduced in Bonawitz et al. [29], this approach mitigates model
inversion attacks by adding noise masks to shared parameters, ensuring privacy while maintaining accurate
model aggregation.
‚Ä¢ Token Models: In this client-to-client sharing mechanism [270], global model parameters are transmitted across
clients to either train on local data or extract knowledge from pre-trained local models.
‚Ä¢ Model Predictions: Instead of sharing model parameters, clients share the outputs (predictions) of their local
models [79]. These predictions can be used by other nodes to improve learning without exposing raw data.
‚Ä¢ Embeddings: As seen in Gupta and Raskar [99], clients focus on learning and sharing sub-representations
(embeddings) instead of performing end-to-end training. This reduces communication overhead while preserving
task-specific learning.
‚Ä¢ Statistics: Clients transmit metadata such as data distribution hints, performance metrics, and the number of
local data points.
4.3.4. Compression
One of the key challenges in distributed learning is the communication bottleneck caused by bandwidth-heavy
transmission and inefficient communication rounds. This issue is exacerbated by several factors, including large model
sizes, limited network resources, data heterogeneity among clients, and high federation participation.
To address these challenges, various model compression techniques are employed, such as pruning, quantisation,
sparsification, and knowledge distillation. These methods aim to reduce the size of transmitted updates, improve
communication efficiency, and minimise resource usage while maintaining model performance.
Frederico Vicente et al.
Page 27 of 70
Modular Federated Learning: A Meta-Framework Perspective
Model Pruning. As Neural Networks are universal approximators of non-trivial functions, they are flexible to
specific structural manipulations without significant performance degradation. For instance, studies on Transformer
networks have shown that some attention heads contribute minimally to final predictions [274]. This insight suggests
that pruning unimportant components can reduce model size and computation time while maintaining comparable
performance. In Federated Learning (FL), FedTiny [113] dynamically prunes network components during training
based on their relevance to final predictions, making it suitable for scenarios with intensive computational and memory
constraints.
Model Quantisation. Model Quantisation involves reducing the number of bits used to represent the numerical
values encoding model weights, thereby decreasing the size of transmitted updates. Gupta et al. [98] introduced
a federated quantisation technique using Kurtosis Regularisation (KURE) and Additive Pseudo-Quantisation Noise
(APQN) to create robust quantised models. Their approach ensures that the model remains tolerant to varying bit
widths while retaining full-precision accuracy. Additionally, Lazily Aggregated Quantisation (LAQ) [253] compresses
gradient updates and skips non-informative communication rounds, reducing communication overhead. By sharing
gradients with inherent noise, this method also enhances privacy by mitigating potential exploitation of communication
artefacts.
Sparsification. Sparsification is another effective compression strategy that reduces the size of updates by trans-
mitting only the most significant components of the model parameters or gradients. For example, sparse gradient
updates focus on retaining only a small fraction of the most informative elements, discarding less significant values.
This approach significantly reduces communication overhead while maintaining learning efficacy. Furthermore,
sparsification inherently enhances privacy, as fewer model details are shared during communication rounds [285].
Knowledge Distillation. Knowledge Distillation is a popular method for transferring knowledge from a large and
complex model (teacher) to a smaller and simpler model (student). In the context of FL, this technique is particularly
useful for addressing challenges such as data and model heterogeneity. For instance, works like Kalra et al. [127]
and Fang and Ye [79] employ knowledge distillation to harmonise learning across diverse client models while ensuring
robust global performance.
4.3.5. Client Selection
Distributed Learning systems face both physical and digital constraints. During federated training, devices may be
turned off unexpectedly or the network connectivity might drop during the parameters-sharing phase. Furthermore,
the training and communication speeds might differ due to the internet physical components of the federated client,
creating progress bottlenecks in the system. Such situations make it necessary to design FL frameworks robust to these
learning inconsistencies. One way to mitigate it is by instituting the notion of Client Selection in such a way that the
learning procedure is mildly affected and such that it can be enhanced based on some heuristics (e.g. segregating clients
into clusters to align clients in groups in terms of data homogeneous characteristics).
The simplest client selection technique is based on the Cohort mechanism, where a subset of available clients is
chosen to be part of the Federated Learning process. One further customisation step is to weigh the client selection
based on heuristics (e.g. client number of samples, noise rate, speed performance).
FedRN [135] assumes clients have noisy data, and therefore consults K-reliable neighbour clients‚Äô models to
assess the health of its data and trains its local model using the not noisy filtered data. These noise-aware auxiliary
training models are bi-modal Gaussian Mixture Models, which express the probability distribution of noisy versus
clean examples.
TiFL [42] is an FL framework designed to mitigate the effect of stragglers by segregating clients into tiers depending
on their performance.
4.4. Distributed Data Handling
The simplistic assumption that distributed data behaves similarly to centralised, curated data is unrealistic.
Statistically speaking, most Machine Learning mechanisms rely upon the assumption that the data/evidence supporting
a specific task (e.g. regression, classification, generative modelling) is Independent and Identically Distributed (iid).
In reality, however, distributed data is either not identically distributed or not independent; thus, federated data is
generally non-iid. We present the four core types of non-iid data observed in real-world scenarios [324]:
Frederico Vicente et al.
Page 28 of 70
Modular Federated Learning: A Meta-Framework Perspective
‚Ä¢ Feature Distribution Skew. The marginal distribution of the data features ùëÉ(ùë•) varies across federated clients.
Example: Imagine two equal CCTV cameras pointing at the respective garden of a house. One of the gardens
has trees, the other has a tree and many gnomes over the grass. The distribution of items/objects and the features
are different.
‚Ä¢ Label Distribution Skew. The marginal distribution of label data ùëÉ(ùë¶) varies across federated clients. Example:
Imagine two equal CCTV cameras recording a garden. One CCTV camera is in Country X and the owner
populates it with cactuses, the other CCTV is recording a Country Y house filled with gnomes. The Country Y
house will probably never have a cactus so for the Country Y‚Äôs CCTV there is no label for cactus.
‚Ä¢ Feature Concept Skew. The features conditioned on the input labels ùëÉ(ùë•|ùë¶) vary across federated clients,
whereas ùëÉ(ùë¶) remains constant. Example: Imagine two CCTV cameras recording the same object from two
different perspectives. Even though the object ùë¶remains the same, the encoded understanding of each object
will vary deeply since the captured features are not the same.
‚Ä¢ Label Concept Skew. The labels conditioned on the input features ùëÉ(ùë¶|ùë•) vary across federated clients, whereas
ùëÉ(ùë•) remains constant. Example: Imagine two different CCTV cameras recording the same object. The raw input
is the same, but since the cameras are different, the perception of the object ùë¶can vary.
4.4.1. Heterogeneous Data
Distributed Learning systems by nature imply different data characteristics over the different nodes composing the
distributed network. This heterogeneous non-iid data behaviour hinders the learning mechanism (e.g. FedAvg: McMa-
han et al. [177]) and makes several standard/classical Machine Learning approaches not viable.
Clustering Federated Learning (CFL). One way to mitigate the non-iid factor is finding client nodes that share
similar data distributions and grouping them. Mathematically, we try to find ùëòclusters, optimising the best client-
cluster fit for each client data distribution. This process can be considered a meta-learning mechanism since it paves
the way for a more insightful model alignment protocol, by leveraging the information of likewise client nodes when
selecting clients to perform the distributed learning alignment [90, 324] (See Fig. 9 to view a federated clustering
abstract example, where clients are grouped so the learning is more robust to heterogeneous data distributions).
A
c1
c2
c4
c5
c3
C
B
Figure 9: Abstract overview over a federated clustering algorithm, which groups together clients in clusters (A: client 1,4; B:
client 2,5; C: client 3) according to how similar their data distributions are. The circles represent the class distributions when
considering a classifying problem (circle colour: the respective class; circle size: the amount of data points corresponding
to the class).
In a sense, CFL exploits the intrinsic geometric properties of FL by grouping clients through the usage of
measurement distances between client nodes. One first work in the CFL realm, Sattler et al. [234] recursively performs
Frederico Vicente et al.
Page 29 of 70
Modular Federated Learning: A Meta-Framework Perspective
a top-down FL bipartition over the training federation. Until convergence, an FL training round is executed, followed by
the server performing a bipartition over its clients to understand whether this new partition better separates congruent
from incongruent clients. If the new partition is worse (evaluation metric smaller than a threshold hyperparameter) the
system falls back to the previous clustering structure.
StoCFL [324] is a Bi-Level clustering approach to FL, agnostic to the total amount of clusters. It estimates the
similarity of any two clients to assign close clients to the same cluster and eases the data distribution divergences
during the model alignment phase. Models are aligned in the same cluster space and then further aligned globally
using each cluster model for regularisation purposes.
4.4.2. Unlabeled Data
Most Federated Learning Literature tackles supervised learning use cases, however, the presence of unlabeled data
over Internet of Things (IoT)/edge devices is more prevalent than explicitly labelled one.
Regarding cyber-attack vulnerabilities, some works (e.g. Cassavia et al. [39]) have proposed federated auto-encoder
architectures to detect anomalies in unlabelled data, which intrinsically learn a codification of the data to spot data
distribution shifts.
FedUL [168] studies how clients can effectively learn from situations where no data is labelled, but assuming prior
knowledge of the class distribution present at each client.
Federated Contrastive Averaging (FedCA: Zhang et al. [327]) undertakes an unsupervised representation learning
approach utilising contrasting learning techniques on the client side and server aggregation to align the local samples
logits database and the local models onto a global one. FedCA extends SimCLR [51] to a federated setting with two
key modules: a (local and global) database containing the logits of the client nodes, which is shared with the server
and a representation learning alignment model.
FedX [102], concerned with data sharing among federation clients (e.g. FedCA: Zhang et al. [327]), explores
a different take on unsupervised contrastive Federated Learning through the usage of local and global knowledge
distillation.
Feedback-based Implicit Annotated Data. Sharma et al. [242] provide a realistic take on utilising natural human
behaviour as pseudo labels (Feedback Noise Modeling) in the domain of smartphone usability, assuming no labelled
data is available on the device, rather they resort to intrinsic positive/negative feedback from behaviour cues. This is
an interesting take since it provides a platform for an active learning deployment. Furthermore user feedback signals
represent a robust source of knowledge to reduce the effect of concept and data drifts, especially in scenarios where
data is majorly unlabelled.
4.4.3. Streaming Data - Online Learning
Online Learning assumes that data instances we are interested in learning come in a streaming fashion and may not
be available after training/inference. In Online Learning no target label is known beforehand, therefore the learning
process is continuous, through an iterative process: 1. At time stamp ùë°, a new batch or data point ùëãùë°arrives; 2. A
model makes a prediction ÃÇùë¶= ùëÄùë°(ùëãùë°); 3. Ground truth ùë¶ùë°is revealed, with or without a time delay ùõøùë°; 4. The model
ùëÄùë°learns from data pair (ùëãùë°, ùë¶ùë°) and, thus, updates to ùëÄùë°+1; 5. This process repeats on the arrival of a new data
element. For neural networks, online stochastic gradient descent is normally used. If there are no imminent shifts in
data distributions, the online learning scheme can be conceived as an offline learning procedure by collecting and
storing the streaming data and only dispatching the learning process as needed.
Online FL is the expansion of Online Learning methods to a distributed setting, where each client continually
receives a stream of data (e.g. wearable monitoring devices). It is deeply explored in real-time use cases like Fraud
Detection, Online Services (Music/Movie streaming) Recommendations, etc.
FedOMD [180] recognises that data may not be available offline and designs a collaborative method to minimise
a regret metric over a convex problem.
Wu et al. [293] concerned with large-scale recommendation systems extends Online FL to personalisation and a
decentralised setting. They introduce a novel learning model aggregation scheme, which performs a learning step over
a given arriving data element and a learnt weighted combination of the local and peer models to update the local model.
Some works also consider the hyper-parameters tuning of Federated Learning within the optimisation problem
(e.g. learning rate, batch size). Kan [128], for instance, leverages an online procedure to update the hyper-parameters
dynamically.
Frederico Vicente et al.
Page 30 of 70
Modular Federated Learning: A Meta-Framework Perspective
4.4.4. Datasets and Benchmarks
Datasets and benchmarks play a pivotal role in Federated Learning (FL), enabling researchers to simulate realistic
scenarios, compare algorithms, and address key challenges such as non-iid data, noisy labels, and privacy preservation.
Below, we provide a consolidated overview of commonly used datasets and benchmarks in FL, categorised by domain
and task:
Table 3: Overview of datasets and benchmarks used in Federated Learn-
ing research.
Dataset/Benchmark
Key Features/Applications
Image Recognition and Classification
FASHION-MNIST [296]
Handwritten fashion item images for classification tasks.
CIFAR-10, CIFAR-100 [139]
Object classification datasets, extended in CIFAR-
N [284] to include noisy labels.
ImageNet [67]
Large-scale image classification dataset for deep learning
models.
CINIC-10 [61]
Combines CIFAR-10 and ImageNet to create a more
diverse dataset.
CLOTHING-1M [298]
Fashion image dataset with noisy labels.
Natural Language Processing (NLP)
LEAF [35]
General benchmark supporting sentiment analysis, lan-
guage modeling, and meta-learning.
FEDLEGAL [334]
Real-world FL benchmark for legal NLP tasks.
FedLLM-Bench [312]
Designed for evaluating FL methods on large language
models.
Speech and Audio Processing
LibriSpeech [202]
Large-scale automatic speech recognition dataset.
Common Voice v13.0 [10]
Diverse speaker dataset for evaluating FL systems in ASR
tasks.
Noisy Learning Datasets/Benchmarks
CIFAR-N [284]
An extension of CIFAR with corrupted target labels for
noisy data research.
FedNoisy [157]
Benchmark designed to evaluate FL techniques on non-
iid, noisy data.
CLOTHING-1M [298]
Fashion dataset with noisy labels.
Security and Adversarial Environments
TON_IoT [185]
IoT dataset for simulating network intrusion and attacks.
Kitsune [179]
Network attack dataset for adversarial FL research.
FLHetBench [328]
Benchmarks device and state heterogeneity in FL sys-
tems.
Edge Computing
Continued on next page
Frederico Vicente et al.
Page 31 of 70
Modular Federated Learning: A Meta-Framework Perspective
Table 3 ‚Äì continued from previous page
Dataset/Benchmark
Key Features/Applications
FLEdge [288]
Benchmarks FL workloads in edge computing, focusing
on hardware heterogeneity and energy efficiency.
Wearable and IoT Applications
FitRec [195]
Tracks physical activity attributes like heart rate and GPS.
ExtraSensory [269]
Smartphone-based activity recognition dataset.
Anguita et al. [8]
Human activity recognition dataset capturing six activity
types.
Multimodal Learning
FedMultimodal [82]
Benchmark for multimodal FL applications, covering five
representative tasks.
Vertical Federated Learning
PyVertical Framework [222]
Simulates User ID Alignment issues using modified
MNIST.
MedPerf [129]
Medical benchmark testing FL models on edge devices in
realistic scenarios.
hERG dataset [106]
Molecular biophysics dataset for FL systems focused on
cardiac toxicity prediction.
The table combines datasets and benchmarks, categorizing them by their primary domain or task. It highlights the
diversity of datasets used in FL, as well as specialised benchmarks designed to address FL-specific challenges like
non-iid data distributions, noisy labels, and privacy concerns.
4.4.5. Data Processing
Data Partitioning. In real-world Federated Learning (FL) applications, data is inherently partitioned across clients,
often reflecting their individual contexts (e.g., user devices or organizations). However, when evaluating FL algorithms
using benchmarks, data is often synthetically partitioned to either simulate a federated scenario or test the robustness
of algorithms under varying degrees of heterogeneity.
A common and simple partitioning technique, initially used by FedAvg [177], is data sharding. In this method,
training examples are sorted by class labels and divided into shards, with each client assigned a predefined number
of shards (e.g., two shards per client). While effective for basic simulations, this method is limited in its ability to
represent realistic non-iid scenarios.
To address this, a more probabilistic and systematic partitioning approach was introduced: the Dirichlet Distribution-
based partitioning [111]. This method allows for fine-grained control over the heterogeneity of client data. By tuning
the ùõºparameter of the Dirichlet distribution, one can control the level of non-iidness among clients: smaller ùõºvalues
produce greater heterogeneity, while larger ùõºvalues result in more homogeneous data distributions (see Fig. 10). This
flexibility makes the Dirichlet-based method widely used for benchmarking FL systems under diverse non-iid settings.
Dirichlet (ùõÇ ~ 1)
c1
c2
c3
c4
c1
c2
c3
c4
Dirichlet (ùõÇ ~ 1)
& Quantity Skew
Sharding
c1
c2
c3
c4
Figure 10: Popular data preparation techniques involve using Sharding (left), the Dirichlet distribution (middle), and a
combination of the Dirichlet distribution and manipulating the number of elements in the datasets (right). The different
colors represent distinct features, while the size of each feature indicates its distribution scale.
Regarding heterogeneous data scenarios (inconsistent class label distributions among clients), some researchers [79]
have proposed the use of a publicly available dataset shared among all clients, in addition to their private data. The
Frederico Vicente et al.
Page 32 of 70
Modular Federated Learning: A Meta-Framework Perspective
underlying rationale is that this common dataset serves as a shared foundation to align the models, mitigating the
effects of shifts in local data distributions.
However, the use of public datasets in a federated setting has been met with criticism, as such datasets are
often unrealistic in real-world scenarios. Public datasets‚Äîespecially large, well-annotated ones‚Äîare rarely available,
particularly for highly specialised or private domains. Nevertheless, we argue that the concept retains relevance in two
distinct forms:
1. Common Knowledge Sources: Even if the original data of interest is unavailable, there may exist a shared
set of non-confidential metadata or general information common to all parties. Such data, even if in a different
modality, can provide guidance for the learning process.
2. Open Public Datasets for Transfer Learning: In some cases, publicly available datasets similar to the task
at hand can be leveraged through techniques like transfer learning or knowledge distillation. These approaches
allow models to generalize better across clients by pretraining on public data and fine-tuning on private data.
Noisy Learning. While clean public datasets are often used in research, real-world data is frequently corrupted by
adversarial attacks, machine-generated errors, or human annotation mistakes. Unfortunately, most popular datasets
do not capture such imperfections. To address this gap, researchers typically simulate noisy annotations by injecting
artificial perturbations into datasets. This process allows for controlled evaluation of robustness against noisy labels,
but it falls short of fully replicating the complexities of real-world noisy data.
In the noisy learning realm, two widely used noise perturbation styles of injecting label noise are Symmetric Label
Flipping [223, 7] and Pair Label Flipping [101]. Symmetric Label Flipping involves altering the labels of a dataset so
that each label has an equal probability of being changed to any other class label. In contrast, Pair Label Flipping is
characterised by swapping labels between two specific predefined classes, rather than randomly changing to any class.
4.5. Model Agnostic Design & Specialised Learning Paradigms
Similar to traditional monolithic machine learning, Federated Learning enables the execution of numerous tasks,
expanding the possibilities of distributed processing. Locally, on the clients/devices, these tasks can be addressed using
various models, such as Convolutional Neural Networks (CNNs), Transformers, etc. This flexibility allows for tailored
solutions to specific challenges, leveraging the strengths of different model architectures to enhance performance and
efficiency across diverse applications.
To an extreme extent, the model on each client can be a black box concerning other clients on a federation [146].
4.5.1. Model Initialisation
In Federated Learning, model parameters can be tailored using global or local heuristics. Typically, global model
parameters are initialised using normal distributions, in line with standard machine learning practices. However, when
the task at hand shares similarities with a previously addressed task, Transfer Learning is often employed, leveraging
a pre-trained foundational model. In the context of client-side learning, initialization is generally based on the most
recent global model version, which in turn depends on the specific FL aggregation or alignment algorithm in use. For
instance, the FedAvg algorithm [177] produces a global model that represents the average of the local models, whereas
FedPSO [203] initializes local models based on the best-performing client model from the previous optimisation
iteration.
4.5.2. Neural Architecture Search (NAS)
Manually designing a neural network architecture to solve a task may be suboptimal, especially in a Federated
Learning setting where local data distributions differ and even the tasks/features may not be identical. NAS attempts
to dynamically find an optimal neural model architecture balancing a defined search space, search strategy and
performance estimation [345]. In the realm of FL, NAS was initially proposed by He et al. [105] and Yuan et al.
[321] tackling online Federated NAS. Online federated NAS optimises both the model and its architecture design
simultaneously, in contrast to offline approaches that optimise them sequentially. Two popular techniques for Online
Federated NAS are gradient-based methods [321] and Evolutionary Algorithm-based methods [341].
To further explore the topic of NAS in a Federated Learning setting we invite the reader to read the survey [342].
Frederico Vicente et al.
Page 33 of 70
Modular Federated Learning: A Meta-Framework Perspective
4.5.3. Federated Reinforcement Learning
Reinforcement Learning (RL) represents a distinctive Machine Learning paradigm that conceptualises the learning
journey as a Markov Decision Process. In simpler terms, RL adheres to a ‚Äúlearn by doing‚Äù doctrine, wherein the
learning system continually refines its environment understanding by striking a delicate balance between adapting
to errors based on the rewards received for actions taken in a given state and exploring uncharted territories within
the (state, action, reward) space. This iterative process, characterised by the dynamic interplay of exploitation and
exploration, forms the essence of Reinforcement Learning. It is a powerful approach for training intelligent systems to
make optimal decisions in complex, dynamic environments.
In physical real-world cases, however, the concept of learning from real experience is impractical as it would be
extremely costly and time-consuming. Therefore to combat this gap, software simulations are often used to substitute
real-world prior experiences to fasten RL applications in the real world.
In essence, applied to FL, reinforcement learning, like normal Federated Learning can be segregated into Horizontal
and Vertical FL (See Fig. 11 for a visual guide and brief overview of the differences).
Vertical
Local Model1 Training
Agentn
Reward
rt
Action
at
rt+1
st+1
State
st
Environmentn
Local Model2 Training
Agentn
Reward
rt
Action
at
rt+1
st+1
State
st
Environmentn
Local Modeln Training
Agentn
Reward
rt
Action
at
rt+1
st+1
State
st
Environmentn
Horizontal
Global Environment
Agentn
Reward
rt
Action
at
rt+1
st+1
State
st
Observed
Environmentn
Agentn
Reward
rt
Action
at
rt+1
st+1
State
st
Observed
Environment2
Agentn
Reward
rt
Action
at
rt+1
st+1
State
st
Observed
Environment1
Figure 11: Overview of Horizontal vs. Vertical Reinforcement Federated Learning. (Left) Horizontal FL, where each node
explores a different environment. (Right) Vertical FL, with multiple clients observing a shared environment. Adapted from
Qi et al. [211].
In the automotive industry, the usage of reinforcement learning is prominent, due to the intrinsic nature of the
dynamism of the environment that a vehicle encounters. In this sector, we often find a Horizontal FL, since each vehicle
drives in different locations, encountering different obstacles and weather factors. Vertical Federated Reinforcement
Learning is less commonly found in the literature, however, works such as Zhuo et al. [344] exist exploring agents
collaborating in a finite space.
Lee and Choi [144] proposed a Reinforcement Learning system, a Home Energy Management System (HEMS), to
estimate the energy consumption of multiple Smart Homes consisting of multiple energy devices (e.g. Air Conditioner).
Generally, in a Federated setting each local entity optimises a single local model, whereas, in this HEMS system, a set
of energy devices are independently optimised considering user preferences in their reward functions.
Federated Learning applied to Autonomous Driving has gathered interest as it can help speed up the gap between
the simulation performance and real-world scenarios, by transferring the knowledge of other vehicle agents when
acting on a given state [158]. More recent work on Connected Autonomous Driving (Federated Learning applied to
Autonomous driving methodologies) has emerged [84].
For further in-depth detail about the state of applications of reinforcement learning in a federation scheme,
visit the following surveys [211, 207].
4.6. Security Strategy
Federated Learning (FL) mitigates raw data exposure by transmitting, for instance, model weights or gradients,
instead of raw data across network nodes. However, this alone does not guarantee security, as FL remains vulnerable
to various attacks and adversarial threats. With an estimated 60 billion Internet of Things (IoT) devices expected by
2025 [219], FL is positioned to target low-resource applications due to these devices‚Äô interconnectivity, abundance
of local data, and advancements in embedded AI acceleration. However, this massive and diverse ecosystem presents
critical security challenges. A less favourable factor is that this myriad of machines does not always have the ideal
Frederico Vicente et al.
Page 34 of 70
Modular Federated Learning: A Meta-Framework Perspective
security design, possessing low-quality/cheap components facilitating adversarial attacks to devices and endangering
FL‚Äôs applicability [340]. Furthermore, a key characteristic concerning the dissemination of Machine Learning models
over embedded devices is the possible increase of interest in the theft or destruction of these devices carrying valuable
and powerful specialised ML models.
Federated Learning is susceptible to various security threats that can compromise model integrity and system
reliability [174, 100, 340]. This module focuses on safeguarding FL systems against a wide range of security threats,
including:
Data Poisoning Attacks. Data poisoning involves adversarial modification of training data to manipulate the global
model. Attackers may inject misleading samples to degrade model accuracy or introduce hidden backdoors [194].
Defense mechanisms such as robust aggregation methods [29] and anomaly detection [292] can mitigate such risks.
Adversarial Attacks. Adversarial attacks involve carefully crafted perturbations to input data, causing incorrect
model predictions [12]. Federated models are particularly vulnerable as attackers may exploit updates to generate
adversarial examples. Defense strategies, for instance, include adversarial training [153].
Model Theft and Inference Attacks. Model theft occurs when adversaries attempt to reconstruct or steal the
global model [331]. Inference attacks further exploit access to model outputs to infer sensitive training data [5].
Countermeasures include Differential Privacy [94] and Secure Multi-Party Computation [28].
Physical Attacks. FL relies on distributed nodes that can be physically compromised. Attackers may tamper with
hardware to extract sensitive model parameters or disrupt training. Secure enclave technology [69, 183] and hardware-
based attestation can reduce the impact of such attacks. Security strategies in FL require a holistic approach, combining
cryptographic techniques, anomaly detection, and robust optimisation methods to ensure trustworthiness in distributed
learning environments.
4.6.1. Distributed Byzantine Attacks
Malign attacks are prominent within Machine Learning systems, where the training data, training process, or
inference procedures are exploited. In distributed systems, assaults on the established behaviour of distributed
infrastructure are classified as Byzantine Attacks. They are a subset of Byzantine Failures, a broader class of
distributed issues (e.g. hardware failures, communication failures, adversarial attacks, protocol inconsistencies).
On a different line of attack, there is the Data Poisoning Attack. It is a kind of byzantine attack, where a third-party
entity tries to infect nodes in a learning network to either alter the local dataset, manipulate the labels, or impersonate
a benign node to infiltrate the central learning system at a later stage. One popular way to contaminate target labels
is using the Label-Flipping technique where according to some probability distribution, labels in a dataset get altered
with different ones. CONTRA [12], for instance, tries to combat label poisoning by ranking network nodes depending
on their suspected behaviour.
Apart from poisoning attacks, there are other styles of adversarial learning attacks: Inner Product Manipula-
tion [299]; Sign Flipping [241]; and A Little is Enough Baruch et al. [18]).
Focused on building robust distributed learning optimisation methods, some works (e.g. GeoMedian [52],
Krum [26]) have concentrated on gradients‚Äô Euclidean norm guarantees. However, the norm of a vector is arguably
less important than its direction. In this sense, Zeno [300] was proposed to enforce gradient direction constraints in
the learning process. Some clustering techniques [156] group similar clients based on their gradient updates, relying
on cosine similarity. In isolation, cosine similarity might not be ideal as it solely accounts for relative directions while
disregarding the magnitude of each vector. See Fig. 12 to visualise how a byzantine gradient can negatively affect an
FL algorithm‚Äôs learning process.
4.6.2. Trusted Execution Environment (TEE)
Secure and Privacy-preserving Federated Learning frameworks have been proposed using Trusted Execution
Environments to hide model/gradient updates from malign adversaries [182].
The core idea behind TEE is that along a computer system‚Äôs Trusted Computing Base (TCB), there is a hardware
and application/software enclave where specific computations and resources are protected. Systematically, TEE is
powerful because it provides a flexible and secure platform for processing Federated Learning computation (see
Fig. 13). Unfortunately, since they run over a TCB (the secure components of a system), which must be audited
Frederico Vicente et al.
Page 35 of 70
Modular Federated Learning: A Meta-Framework Perspective
Average 
Gradient
Well Behaved
Gradients
Byzantine
Gradient
Average Gradient 
without Byzantine
Figure 12: Byzantine Gradient Attack. Showcasing how a gradient attack can affect the update of the FedSGD algorithm.
and remain secure, the hardware enclave limits computational Machine Learning possibilities: 1. Secure Memory
Limitations. TEE‚Äôs TCB physical memory is typically constrained to a few megabytes. This limitation restricts
operational throughput and the number of parameters that can be accommodated; 2. Privileged Instructions. Some
TEEs, for security reasons, do not provide access to privileged instructions (e.g. filesystem access, multi-threading)
hindering some use cases; 3. Software Development Kits (SDKs). TEEs are often populated with simple low-level
SDKs.
Server/Client
Model
Untrusted Client
TEE
Data
ML Algorithms
ML Model
Training Procedure
Inference Procedure
Figure 13: We depict a general case where a TEE is used on federation clients to protect the contamination of ML models
and the execution of the learning inference procedures. Adapted from Mo et al. [183].
The TEE, as depicted in Fig. 13, assumes that its host might be compromised, however, assuring that the execution
of the procedures assigned to it is not affected. The TEE cannot, however, guarantee that the local data on the client
was not corrupted.
Melon [276], focusing on mobile devices, has developed a Secure Learning Framework using a TEE to train deep
neural networks distributively.
We invite the reader to explore further the Machine Learning possibilities and limitations of TEE [183].
4.6.3. Multi-party Computation
To extend privacy guarantees in Federated Learning, secret sharing between parties can be used, in what is called:
Secure Multi-Party Computation (SMPC).
SMPC techniques enable different entities to collaboratively compute a function while ensuring the confidentiality
of their respective inputs. In the context of Machine Learning, we can imagine this function being the loss during
model training.
While SMPC generally incurs notable communication overhead, its key advantage lies in preserving the privacy
of input data, as long as a significant portion of the parties involved are not maliciously coordinating. Using secret
Frederico Vicente et al.
Page 36 of 70
Modular Federated Learning: A Meta-Framework Perspective
sharing, both the parameters of models and the data used in training or inference can be safeguarded. This guardrails
that, even a malicious adversarial agent with unlimited time and resources, cannot crack the confidentiality within the
input data.
In comparison, Fully Homomorphic Encryption is more computationally expensive than SMPC, even though both
allow the execution of mathematical operations over encrypted data.
Google pioneered SMPC implementation over the FL framework [28]. They resort to t-out-of-n Secret Shar-
ing [239] to ensure that the masking of each client‚Äôs inputs does not reveal unwanted information. They also introduce a
notion of double masking to protect against cases where the server can reconstruct some specific client mask. They use
Diffie-Hellman public keys to reduce communication by having the parties agree on common seeds for a pseudorandom
generator.
4.6.4. Secure Aggregation (SE)
The notion of Secure Aggregation is based on the idea that malicious agents can try to corrupt a Federated Learning
process. The Secure Aggregation technique employs additive masking to ensure privacy protection of the model
updates shared by clients [29]. Each client adds a uniform random mask to their update, ensuring that each masked
update is statistically indistinguishable from the other clients‚Äô values. At the time of aggregation, the protocol cancels
out all the masks, ensuring that the final model update is an accurate representation of all the client updates while
maintaining their privacy (see Fig. 14).
C3
+
+
C2
+
+
C1
+
+
= 0
‚àë
Server
Local Model
Mask
Mask
Local Model
Mask
Mask
Local Model
Mask
Mask
Figure 14: Abstract example of how Secure Aggregation mechanism can be applied to Federated Learning. Each client
holds one or more masks which are added to the model weights, conditioned that the sum of all masks from the different
clients must add up to 0, so they cancel out.
SE can be applied through different techniques:
1. Software-based protocols (e.g. Multi-Party Computation [28]);
2. Hardware implementations of Trusted Execution Environments [182].
ELSA [217], for instance, introduces a Secure Aggregation protocol, which utilises two servers to maintain trust
(distributed trust) in the learning system. The system guarantees privacy properties as long as at least one server is
honest. Unlike RoFL [310], EIFFeL [226], and Prio [59], ELSA stays efficient when dealing with strict bandwidth
constraints.
Dropout clients during the training/model aggregation process make the algorithm design of Secure Aggregation
considerably more complex. Standard techniques face this problem when the number of dropout clients increases since
they rely on the secret sharing of random seeds to further reconstruct/cancel the masks belonging to the dropped clients.
To face this malicious issue, LightSecAgg [249] presents a protocol consisting of moving the masking responsibility to
the local clients, which is then followed by the respective mask encoding and its sharing with the other clients, whilst
making sure the server can recover the masks upon clients dropouts. It can be used in an asynchronous setting and
Frederico Vicente et al.
Page 37 of 70
Modular Federated Learning: A Meta-Framework Perspective
if the majority of clients persist active in the federation it can increase the resiliency to dropping out clients, whilst
reducing the aggregation time.
In Federated Learning settings, the model aggregation process may repeat several times, which may consist of
multiple communication overhead if the random-seed usage for masking is not well designed. LERNA [147], for
instance, established a particular initial round for setting up the needed Secure Aggregation configurations to reduce
communication costs. Upon a specific pre-defined period, this setup is reset to ensure private-secure guarantees. This
method is specially designed for a large-scale interconnected network (‚â•20K clients).
4.6.5. Blockchain
Traditional centralised FL systems suffer from inherent infrastructure vulnerabilities, as they rely on a single main
server controlling the learning process to remain operational and, thus, they are vulnerable to unauthorised tampering
or failures. Apart from classical peer-to-peer decentralised networks, Blockchain can provide properties like tamper-
proof, collective maintenance, and traceability in a decentralised setting.
In essence, a Blockchain consists of a chain of blocks, where each block contains a list of transactions, a timestamp,
and a reference to the previous block. These blocks are linked and secured using cryptographic hashes, creating an
immutable and tamper-resistant system. With the help of consensus mechanisms like proof-of-work or proof-of-stake,
participants in a blockchain network validate and agree on the state of the ledger, preventing fraudulent activities. The
ledger is the record-keeping system that stores a chronological and transparent transaction history, distributed between
multiple blocks.
In the context of FL, the blocks are often designed to have the local training rounds of each client, where each
transaction within the block represents each client model parameters. The edge devices assume the responsibility to
maintain the Blockchain as ‚Äúminers‚Äù, receive and store the model parameters, and finally authenticate the parameters
by a consensus protocol.
Chang et al. [46] suggests the combination of Blockchain technology with the use of differential privacy, along
with model gradients verification step as a move towards a more secure and reliable FL framework.
We encourage the reader to explore the research on Blockchain-based Federated Learning in depth [162].
4.6.6. Anomaly Detection
One effective approach for assessing the status of a FL pipeline involves leveraging anomaly detection techniques.
This approach proves invaluable in real-time monitoring, enabling swift identification of any deviations within specific
local deployments. Employing anomaly detection facilitates the detection of potential label-poisoning or adversarial
attacks.
A Cumulative Sum Control Chart (CUSUM: PAGE [201]), is a rather simple technique that establishes a threshold
of maximum acceptable change in specified weights/model parameters/data distributions.
In the domain of image-based tasks, PhotoDNA, originally developed to combat Child Sexual Abuse Material
(CSAM), is a tool that converts images into unique hashes, enabling the identification of similar images within a
database. This technology can also be leveraged to detect and track alterations in datasets.
FL-MGVN [292] presented an anomaly detection classification model that uses Mixed Gaussian Variational Self-
encoding Networks. It is designed to effectively handle network attacks and sample dissimilarity, addressing key
challenges in anomaly detection, including low detection accuracy, high false alarm rates, and the scarcity of labeled
data.
For a comparison of threshold-based anomaly detection algorithms, we invite the reader to refer to Table 4, where
we evaluate multiple approaches. These methods differ in the statistical measures used, data characteristics considered,
and techniques applied for threshold calculation.
4.6.7. Physical Unclonable Functions (PUFs)
PUFs [218, 87] is a physical/hardware device that can be used to obtain a cryptographic key, which uniquely
identifies a specific device. This is possible through the micro-scale physical discrepancies in the fabrication of
computer devices, which enables the obtainment of a fingerprint upon specific input stimuli.
Frederico Vicente et al.
Page 38 of 70
Modular Federated Learning: A Meta-Framework Perspective
Table 4
Anomaly Detection Federated Methods Comparison. Adapted from [143].
Thresholding Method
Anomalies in
Threshold Calculation
Statistics Used
Local Data Distribution
Consideration
Laridi et al. [143]
‚úì
Mean, Variance, etc.
‚úì
Fed-MinMax [208]
‚úì
Min/Max
√ó
Fed-MSE-StD [280]
√ó
Mean, StD
√ó
Fed-Filtered [232]
√ó
Mean, StD
√ó
A PUF key is intrinsically bound to an individual device excluding any possibility of cloning the key, reverse
engineering it or, provided access to it, extracting it. They provide means to watermark an ML model or a model
prediction preventing cases where an attacker tries to steal or proclaim ownership.
We invite the readers to review the work of Yaacoub et al. [305] and refer to the Privacy and Security chapter
of the Machine Learning Systems with TinyML book [218].
4.7. Privacy Strategy
The world is driving more concern in the ownership and control of one‚Äôs data. Examples of this are the development
of regulations and privacy principles like: EU AI Act, EU General Data Protection Regulation (GDPR), the California
Consumer Privacy Act (CCPA) and the Health Insurance Portability and Accountability Act (HIPAA).
Federated Learning, in its intrinsic form, guarantees a basic level of privacy since raw data is not openly shared
between network parties. Conversely, it has been shown that Neural Networks memorise training data [80, 184] and
consequently, this data can be exploited through adversarial attacks on models [88, 343, 193]. Furthermore, Sattler et al.
[234] reveals that information about client similarity can be inferred from their weight updates, upon model alignment.
Intellectual property is also at risk in Federated Learning, leading to increased interest in model watermarking as a
protective measure [260].
Next, we discuss common privacy-related attacks on Federated Learning systems:
Model Inversion Attacks. These attacks attempt to reconstruct the raw training data by exploiting access to the
model outputs or model parameters. By analysing gradients or model predictions, an adversary can approximate the
original input data, potentially revealing private information in the training set. One popular exploit vulnerability is
the gradient update vectors since they encode information about the learning function and data. For example, Yin et al.
[314] developed a method (GradInversion) to reconstruct the original batches of data from gradients shared from the
client to the server (see Fig. 15).
Original batch - ground truth
GradInversion
Figure 15: Showcasing the capabilities of the Gradient Inversion technique extracted from gradients obtained from a
Federated Learning setting. Adapted from GradInversion [314].
Frederico Vicente et al.
Page 39 of 70
Modular Federated Learning: A Meta-Framework Perspective
We can categorise the gradient inversion attack as a Data Reconstruction Attack. Typically, associated with
this attack, we can have ‚Äúhonest-but-curious‚Äù clients/servers, which will behave towards the goal established in the
federation, but have a third-party goal like collecting statistics or data theft.
Membership Inference Attacks. These attacks aim to determine whether a specific data sample was included in
the training set. By exploiting divergences in the model behaviour, such as confidence scores or gradient updates,
an adversary can infer the presence of individual data points, potentially compromising privacy. MemberShield [5],
for instance, mitigates Membership Inference Attacks risks by training local models with soft-encoded labels to
regulate overconfident predictions. It further enhances privacy by incorporating early stopping to prevent unintended
memorization.
We invite the reader to explore in more detail Membership Inference Attacks in the following survey [16].
As previously discussed, Federated Learning does not inherently guarantee data privacy, making it susceptible to
adversarial attacks. To address these vulnerabilities, a range of techniques has been developed to enhance privacy at
different stages of the learning process. Next, we explore these techniques and their role in fortifying privacy-preserving
FL systems.
4.7.1. Differential Privacy
Differential Privacy (DP) [74] helps obfuscate the danger of exposing raw data through a noise injection procedure
(See Def. 1) at the cost of forcing the Machine Learning practitioner to trade-off accuracy with data anonymity. The
injection of noise can be performed over many possible targets: 1. Model Parameters; 2. Loss Function; 3. Optimiser;
4. Input Data (See Fig. 16). The main types of differential privacy are ùúñ‚àíùê∑ùëÉand (ùúñ, ùõø) ‚àíùê∑ùëÉ, the latter being a
generalisation of the former. ùúñis a real number defining a threshold of privacy tolerance, whilst ùõøis an option to
control the probability of the extreme event of data breach occurring. A smaller ùúñwill yield better privacy constraints
but result in less accurate models.
Definition 1 (Differential Privacy). A noise injection randomised function M: D ‚ÜíD‚Äô with domain D (e.g. the space of
possible training datasets) and codomain D‚Äô (e.g. the space of the possible resulting datasets with noise transformation)
satisfies (ùúñ, ùõø)-differential privacy provided that for any two adjacent datasets ùëë1, ùëë2 ‚ààD and any subset of outputs S ‚äÇ
D‚Äô it holds that ùëÉ[ùëÄ(ùëë1) ‚ààùëÜ] ‚â§ùëíùúñùëÉ[ùëÄ(ùëë2) ‚ààùëÜ]+ùõø(P: probability; M: randomisation function (e.g. query(dataset)
+ noise, query(dataset + noise)); ùúñ: a positive real number representing the privacy budget; ùõø: Probability of data
accidentally having been leaked).
Client
Model Parameters
Loss Function
Input Data
Optimiser
M(d1)
M(d2)
Figure 16: Differential Privacy mechanism and its possible applications (e.g. Model Parameters, Loss Function, Optimiser,
Input Data).
The rise of speech-powered companions, such as Siri, Alexa, or Cortana has led to the interest in designing robust
Automatic Speech Recognition (ASR). The presence of these assistants on ubiquitous devices makes them a great
Frederico Vicente et al.
Page 40 of 70
Modular Federated Learning: A Meta-Framework Perspective
target for (cross-device) FL applicability. A team by Apple concerned with privacy guarantees proposed training a
Transformer with DP, in a Federated Learning setting, proving that a large-scale FL ASR take can have relatively good
results when compared with a standard ML approach [13]. It also discusses the positive correlation between the cohort
sizes and DP success, which suggests that to find a good utility for DP we need a rather big amount of federated clients
> 100ùëò. Zhang et al. [329] also explores a relevant analysis of the operation of clipping models and gradients, which
lies as a base operation to the usage of DP in FL. DP has also been shown to badly impact fairness when a model is
faulty already [15].
The concept of Local Differential Privacy [254] has also been introduced in decentralised FL domains to eliminate
the need for a central server to manage the privacy budget.
Some popular libraries with off-the-shelf implementations of Differential Privacy are Opacus [317] and Google‚Äôs
DP library [94].
For an in-depth exploration of the DP domain, we invite the reader to visit Ted‚Äôs compilation of articles related
to Differential Privacy [68].
4.7.2. Homomorphic Encryption
Homomorphic Encryption (HE) [1] has been proposed as a privacy-preserving technique in FL to safeguard local
raw data by encrypting it, allowing learning computations to be performed directly on encrypted inputs without
revealing the underlying data. This ensures that data remains confidential throughout the learning process, even during
transmission or aggregation.
Compared to other privacy-preserving approaches, HE introduces a trade-off between computational efficiency,
model accuracy, and privacy guarantees. One practical challenge is that most HE schemes operate over integer domains,
necessitating quantization of model artefacts (mapping floating point values to integer ones) to enable compatibility
with machine learning models.
Moreover, the use of HE in neural networks incurs significant computational overhead due to the sequential
nature of neural computations and the requirement for bootstrapping, a costly re-encryption process to manage noise
accumulation between operations.
Homomorphic Encryption can be categorised into the following types:
‚Ä¢ Partially Homomorphic Encryption (PHE): Allows only a single, predefined operation (either addition or
multiplication) to be performed on ciphertexts ‚Äî but without limits on how many times that operation can be
applied. One widely known example of a PHE scheme is the Paillier encryption system.
‚Ä¢ Somewhat Homomorphic Encryption (SHE): Extends PHE by supporting both addition and multiplication
operations on ciphertexts, but only for a limited number of consecutive operations. This limitation arises due to
noise accumulation, which eventually hinders correct decryption.
‚Ä¢ Leveled Homomorphic Encryption (LHE): Further extends SHE by allowing users to specify the maximum
number of sequential operations (circuit depth) at encryption time. While it removes the fixed limit of SHE, it
still does not support unlimited computations.
‚Ä¢ Fully Homomorphic Encryption (FHE): The most general and powerful form of HE, supporting arbitrary
computations (combinations of additions and multiplications) on ciphertexts. This is achieved using a technique
called bootstrapping, which "refreshes" ciphertexts to reduce accumulated noise, enabling unlimited operation
depth. Some FHE schemes may impose constraints such as quantization or specific circuit representations (see
Fig. 17).
Rahulamathavan et al. [215] suggests a new weighted aggregation scheme, which leverages Homomorphic
Encryption by encrypting the gradients, preventing the server from inferring private information, while still providing
comparable accuracy with reasonable computational costs. The algorithmic complexity in this methodology lies in a
single server, in contrast with previous works where 2 servers are often needed [165]. It also seems to assure better
security characteristics, while holding less communication overhead than previous works [175].
One popular and current standard implementation zoo for Fully Homomorphic Encryption is OpenFHE [14].
Concrete [323] is an FHE Compiler, which compiles operations to perform homomorphic evaluation over them.
Frederico Vicente et al.
Page 41 of 70
Modular Federated Learning: A Meta-Framework Perspective
x
Encryption
Decryption
Enc(   )
Chain of
Homomorphic
Operations
f:
Symmetric
Asymmetric
vs
Enc(   )
f(   )
{
f(   )
{
x
noise
fi(   )
Bootstrap
(reduce noise)
noise
Output after
bootstrap
Output of
each 
network
operation
input the next layer in network
Figure 17: We present a FHE framework applied to a neural network use case. Notice that after a homomorphic operation,
noise is additionally added to the encrypted input. Above a certain threshold of noise, FHE execution starts deteriorating
the correctness of the decryption process, since the input of the operations starts getting corrupted by the increasing
levels of noise. The bootstrap method mitigates this issue, by decrypting and encrypting again the input content after an
operation or a set of operations.
4.7.3. Zero-Knowledge Proofs
Zero-Knowledge Proofs (ZKPs) [92] are cryptographic protocols that allow a party (the prover) to convince another
party (the verifier) that a certain statement is true without revealing any additional information. In the context of FL,
ZKPs can be used to verify that a client has correctly trained a model or followed the agreed-upon protocol, without
requiring them to expose their local data or intermediate model updates. A ZKP must satisfy three fundamental
properties: completeness, soundness, and zero-knowledge. They can be interactive or non-interactive, with zk-
SNARKs and zk-STARKs being widely adopted non-interactive schemes that balance efficiency and scalability [77].
While ZKPs enhance FL privacy and security, they introduce computational overhead, particularly in proof generation
and verification. Efficient ZKP schemes such as zk-STARKs help address this, but scalability remains an issue,
particularly with large-scale FL models.
Privacy-Preserving Model Updates. Clients train local models and share updates (gradients or weights) with a
central aggregator. However, these updates may inadvertently leak sensitive data. ZKPs can be used to prove correctness
of updates without exposing the underlying gradients, mitigating gradient inversion attacks [282].
Decentralised Federated Learning. Traditional FL relies on a centralised aggregator, which may act dishonestly.
ZKPs can enable decentralised FL, where clients submit model updates along with zero-knowledge proofs. This
removes the need for a trusted server, making FL more robust to single points of failure [43].
Secure Aggregation with ZKPs. Secure aggregation ensures that individual model updates remain hidden while
allowing their aggregation to be used for training. ZKPs can be combined with secure aggregation protocols to:
‚Ä¢ Prove that an individual update was computed correctly before aggregation.
‚Ä¢ Ensure aggregation is performed honestly without exposing raw data.
This improves end-to-end privacy guarantees in FL [43].
Fair Model Contribution and Reward Mechanisms. In collaborative FL, different participants may contribute
varying levels of effort. ZKPs can be used to prove that each client has performed a minimum amount of computation
before receiving updates. This prevents free-riding and ensures fairness in incentive mechanisms [306].
We encourage the reader to explore the topic of federated learning privacy in the survey by [100]. Furthermore,
we direct the reader to Fig. 6, which provides a comprehensive overview of several widely used Federated
Learning algorithms, concerning privacy.
Frederico Vicente et al.
Page 42 of 70
Modular Federated Learning: A Meta-Framework Perspective
Table 5
Comparison of research works on privacy and security guarantees. Adapted from [172].
Representative Works
Model Privacy
Poisoning Resilience
Malicious Aggregator
Efficient Aggregation
Integrity Check
Inter-client Aggregation
Server Fault Tolerance
FedAvg [177]
√ó
√ó
√ó
‚úì
√ó
√ó
√ó
Krum [26]
√ó
‚úì
√ó
‚úì
√ó
‚úì
√ó
Median [52]
√ó
‚úì
√ó
‚úì
√ó
‚úì
√ó
SecAgg [28]
‚úì
√ó
√ó
‚úì
√ó
√ó
√ó
BREA [248]
‚úì
‚úì
√ó
√ó
√ó
‚úì
√ó
RoFL [310]
‚úì
‚úì
√ó
√ó
√ó
√ó
√ó
EIFFeL [226]
‚úì
‚úì
‚úì
‚úì
‚úì
√ó
√ó
zkFL [282]
‚úì
‚úì
√ó
‚úì
‚úì
√ó
√ó
ELSA [217]
‚úì
‚úì
‚úì
‚úì
‚úì
√ó
‚úì
ScionFL [21]
‚úì
‚úì
‚úì
‚úì
√ó
√ó
√ó
zProbe [89]
‚úì
‚úì
√ó
‚úì
√ó
‚úì
√ó
PPSFL [171]
‚úì
‚úì
‚úì
‚úì
‚úì
√ó
√ó
ZKFL [172]
‚úì
‚úì
‚úì
‚úì
‚úì
‚úì
‚úì
4.8. Trustworthy Federated Learning
Federated Learning (FL) is mostly considered in critical domains, with concerns about the privacy feasibility
characteristics. The bare consideration and usage of FL is a step towards Trustworthy Machine Learning (ML).
Trustworthy ML is a paradigm in the Machine Learning community to advance the field considering the real
applicability of the designed models. This means that Trustworthy ML normally considers: how the model behaves
with Out-Of-Distribution (OOD) data; Leverages simplicity and explainable models to help reasoning and support
decision-heavy use-cases; Explores the uncertainty distributions under model predictions; Meditate on the effect of
noisy contamination to the data and how we can build robust models to such adverse conditions; Are constructed
having in consideration they can have a real supportive impact on the decision making of a critical process. Real-world
applications need this thoughtful and accountable design. In the European Union, we already observe a direction
towards a regulation on trustworthy Machine Learning (Trustworthy AI EU Act).
4.8.1. Dynamic Learning
FL is often studied under the assumption of a homogeneous and static environment. However, in real-world
scenarios, FL systems must adapt to dynamic and evolving conditions, leading to the concept of Dynamic Federated
Learning (DFL). This paradigm addresses key challenges such as out-of-distribution (OOD) data, client data drift,
and operational shifts in client participation.
DFL research explores methods to improve model robustness against these variations. For instance, Rizk et al.
[220] proposes an adaptation of the FedAvg algorithm that dynamically adjusts local epoch sizing and normalization
while incorporating a random-walk parameter drifter, enhancing resilience to data distribution shifts.
The notion of client‚Äôs concept drift can be defined as a change in the client‚Äôs data distributions (e.g. new target
labels in a client appear and others oscillate in magnitude. See Fig. 18 for an illustrative evolution of four types of
client concept drift).
Consequently, drift detection mechanisms are important either to prompt the FL infrastructure to incrementally
learn the new data distribution and avoid decay in performance or to monitor and debug possible problems in the FL
infrastructure. Concerned with clients‚Äô data drifts, Jothimurugesan et al. [125] introduce FedDrift and FedDrift-Eager,
which are FL methods to train groups of models which share the same concepts distribution. In a sense, this work is
similar to clustered FL, since it combines similar clients and each group trains a global model.
Understandably, these client‚Äôs distribution shifts cause fluctuation in the overall behaviour of the Federated
Learning mechanism (see Fig. 19 to observe the effect on the global model, when clients start having distribution
shifts).
4.8.2. Bayesian Learning
Bayesian methods offer a principled approach to uncertainty estimation and model interpretability, making them
particularly relevant in multi-client cooperative learning settings. In the context of Federated Learning (FL), Bayesian
techniques have been explored to enhance robustness and address overfitting issues arising from data scarcity at client
nodes.
Bayesian Neural Networks (BNNs) have been integrated into FL frameworks by representing model parameters
as probability distributions rather than fixed values. While this approach helps mitigate overfitting, its effectiveness
Frederico Vicente et al.
Page 43 of 70
Modular Federated Learning: A Meta-Framework Perspective
Clients
Time
Clients
Time
Clients
Time
Clients
Time
Figure 18: We present four different time-evolving types of data distribution shifts occurring in a Federation, also known as
Clients Concept Drift. Each colour represents a different concept distribution. Adapted from Jothimurugesan et al. [125].
Global
Model
(round r - 1)
Global
Model
(round r )
Global
Model
(round r + 1)
Drifted
Client
Drifted
Clients
Global
Model
(round r + 1)
Global
Model
(round r)
Global
Model
(round r + 2)
Figure 19: Clients Models drifting when their intrinsic concept distribution changes.
diminishes in the presence of non-iid data, where parameter distributions struggle to generalize across heterogeneous
client datasets [322].
The pFedGP [2] was proposed as adapting Gaussian Processes (GPs) to multiple clients, where a shared deep
kernel function 2 is learnt globally through the clients and inducing point methods are introduced to reduce the
computational overhead. They implement multi-class classification GPs as a pipeline of binary decision trees, where
each tree represents a binary GP classifier. These GP models are locally built at every communication round and
averaged at the server. They prove this method has non-vacuous guarantees and that it is advantageous when clients
lack in data quantity and follow heterogeneous data distributions.
Instead of assuming priors to all model parameters, like in a standard BNN, pFedBayes [330] uses the global
distribution being learnt as a probabilistic prior for the local client models.
Liu et al. [164] presents a Bayesian FL framework, which models clients using Gaussian distributions and
showcases how aligning clients‚Äô knowledge with the FedAvg algorithm can move the global model to a non-optimal
parameter space (see Fig. 20).
We invite the reader to explore a comprehensive overview of Bayesian methodologies in Federated Learning
in [38].
4.8.3. Noisy Learning
Literature on FL, generally, assumes the data present at the local computation silos are already labelled and
additionally that they show no anomalies in their intrinsic distribution. However, in real scenarios, seldom is the data
labelled and even when it is, it is reasonable to assume that some noise artefacts may be affecting their quality.
Realistic data normally assumes the form:
2In Regression problems, features normally map well with common kernel functions, like RBF or Materne. However, when dealing with
unstructured data like images on Bayesian classification problems, Deep Kernel Learning [287] helps in creating a better compressed and pattern-
aware representation of an image, which is fundamental in the good behaviour of a GP.
Frederico Vicente et al.
Page 44 of 70
Modular Federated Learning: A Meta-Framework Perspective
Figure 20: Two heterogeneous clients being modelled with Gaussians, depicting how poorly the FedAvg algorithm can be
for aligning heterogeneous clients, in comparison with the FL Bayesian framework [164].
ùê∑ùëê= {(ùë•ùëñ, ÃÉùë¶ùëñ
)}ùëÄùëê
ùëñ=1 ,
(24)
where labelled annotations have suffered a transformation through a composed function over the original
labels/target outputs.
Noisy labels, the result of a composed function which is intrinsically applied to ùë¶noted as ÃÉùë¶, can normally be
characterised in three distinct ways:
1. Random process. An uncontrolled and unknown function inevitably alters the Labels, independently of the
corresponding data point;
2. Y-Dependent Noise ùëÉ( ÃÉùë¶‚à£ùë¶, ùë•) = ùëÉ( ÃÉùë¶‚à£ùë¶). There is the assumption that a perturbation function gets applied to
the data, where the new label is conditioned on the previous ùë¶label:
3. XY-Dependent Noise. The most complex assumption relies upon a noise function where there is an influence of
both the features and label value conditioning the new label ùëÉ( ÃÉùë¶‚à£ùë¶, ùë•).
The intrinsic nature of distributed learning across different devices involves varying computational resources.
The annotated data may be obtained from machine-generated pseudo-labels or distinct human interactions, explicit
or implicit, with varying levels of expertise. This diversity can lead to an increase in faulty annotations: noisy labels.
An undesirable issue often observed in Machine Learning processes is the presence of noisy labels in the training
data. Their presence in the learning mechanism invokes the following behaviour: First, typically, a model learns the
standard/unadulterated data, and lastly, after many learning steps the model starts overfitting to encompass the local
noisy space deformations [173].
Local Intrinsic Dimensionality is a score attributed to data that models the complexity of dimensionality of
samples, which consequently helps segregate noisy labels from standard ones [173].
Systematically, Noisy Label learning literature applies the following techniques: 1. Study Robust Learning,
where a Robust Loss function accounts for noise errors 2. Directly manipulate the labelled data based either on a
parametric/non-parametric model, while assuming specific noise rates.
These works target the creation of Robust mechanisms to overcome the effect of Noisy Labels in the Machine
Learning process. However, it is also possible to identify, to a certain point the noisy labels present in a dataset and
correct them to fix unwanted bias and fairness in the original data [247].
In the FL setting, for instance, FedCorr [301] has been presented to deal with heterogeneous environments and
correct local client noisy labels.
RoFL [310] bases their work on a star-schema FL setting, where each client node shares both the model weights
and the centroids of each label class and is also inspired by noisy label correction techniques. The aggregation step is
Frederico Vicente et al.
Page 45 of 70
Modular Federated Learning: A Meta-Framework Perspective
performed through a similarity-based summation of the local centroids method. Though, RoFL, assumes and focuses
on clients who share different noise distributions, they lack the exploration of inevitable non-iid data.
Symmetric Cross Entropy Learning (SL: Wang et al. [281]) is a robust loss mechanism, which weights the
correction of the prediction versus the target label with a term that helps to learn hard classes in a noise-tolerant
way.
RHFL [79] assumes no model architecture protocol between clients (heterogeneous modelling) and knowledge
between models is shared through a common public dataset available to all clients and a knowledge distillation
technique to align the different knowledge distributions. To overcome noisy inputs, locally it utilises the noise-robust
Symmetric Cross Entropy loss and between other clients, it ranks the reliability/quality of other clients‚Äô data.
Assuming noisy annotated data and heterogeneous Clients, FEDCNI [290] proposes the usage of a prototypical
noise detector to distinguish noisy samples, a pseudo labelling method and a denoise Mixup training strategy. First, on
a client, they obtain the model computed features of a data point and through a similarity metric they classify, using
a Gaussian Mixture Model, the quality of the provided annotated label. Then they use a pseudo-labeling method to
correct the labels. Finally, they use a robust aggregation method, where until a specific timestep they operate a FedAvg
aggregation scheme but later they weigh each client update based on their noise rate.
Based on user feedback from mobile application interfaces [242], research has explored modelling feedback
noise using a parametric approach. This method assigns user-specific probabilities to correctly providing positive and
negative feedback. By adjusting these probabilities, it becomes possible to simulate different user behaviours, including
well-behaved and adversarial users.
4.8.4. Fairness
Any learning process exploits the intrinsic nature of bias, which can have a positive or negative impact. A trustful
Machine Learning system must weigh such bias nature upon its design to avoid discrimination/lack of representativity,
among other issues. For instance, the FedAvg [177] algorithm has been shown to lead to unfair results when clients‚Äô
local data distributions depart from each other [337], due to clients‚Äô weight divergence.
Specifically targeting FL, fairness is exploited in the contexts of Client Selection and Fair Optimisation.
Fair client selection. In Federated Learning, often only a cohort of the total clients from a federation is selected,
either as a consequence of their hardware resources limitations, availability, performance or secure breaches suspicions.
FL Dropout [36], concerned with communication bandwidth costs and inspired by the popular Deep Learning
‚ÄúDropout‚Äù technique developed a framework to locally train sub-models of the global model to reduce the transfer size
footprint. In this setting, each client does not know the global model architecture, therefore it trains its local sub-model
and sends its update to a server which consequently aligns these sub-model updates back to the global model,
Engineered solutions, which through some key attributes provide preference to selecting some clients over others
to overcome: learning contamination, such as Contra [12]; faulty convergence Power-of-Choice [54] can put at risk
their fairness nature. Balancing good performance with fairness characteristics is therefore a challenge.
Fair optimisation. Federated optimisation algorithms, directly or indirectly introduce unfair biases. Considering the
local clients‚Äô parameters, upon a round of training and the error measures, the respective adjustments (gradients) to be
performed on each client‚Äôs parameters to lower the errors can be substantially different for each client.
FedFV [283] explores the paramount behaviour of the difference of adjustments (gradients) for each client
parameter, both in magnitude and direction. FedFV does not communicate parameters, but rather the gradients (the
changes necessary to improve the error considering each parameter). This work uses the Gradient Projection technique
to resolve Cohort and global gradient conflicts better.
We encourage the reader to explore the topic of fairness in Federated Learning in greater depth through the
survey [214].
4.8.5. Informed Learning
One of the most prominent use cases of Federated Learning lies in the cooperation of smartphone applications. In
such scenarios, even when data annotations are absent, user feedback pseudo-labels [242] are often available masked
with some uncertain noise, which is useful for supervised learning tasks. In contrast, in Federated Learning the
Frederico Vicente et al.
Page 46 of 70
Modular Federated Learning: A Meta-Framework Perspective
availability of annotated data is scarce. One of the main reasons relates to the nature of the data produced in edge
devices following a streaming fashion with a high-velocity rate.
To address the challenge of unlabelled data and enhance the robustness of Machine Learning frameworks, a
promising avenue of research is to incorporate explicit knowledge through Informed Machine Learning. Informed
Machine Learning can have many flavours: constraining parameter solutions to physical laws or geometric rules,
constraining parameter space to pre-defined logical rules about the world. Similarly, the mechanism for injection
explicit noise can be performed in many ways: domain knowledge input data, loss function, and specialised neural
network architecture blocks.
In FL, Physics-Informed Neural Networks have been used, for instance, to estimate the state of vehicle
traffic [277], integrating traffic flow physical theory in the model losses and using Cell Transmission Models.
F-MADRL [154] is a reinforcement learning solution for Multi-Microgrid energy management, which leverages
physically informed rewards to score the actions being learnt. This work stands apart from other reinforcement learning
studies by conscientiously addressing the inherent physical constraints of the problem.
Concerning Neuro-Symbolic AI, FedSTL [6] explores temporal logic reasoning in an FL setting, where each
client learns local concept properties and shares these concepts along with the learnt model. LR-XFL [332], also in the
symbolic domain, researches explainable properties of FL frameworks using symbolic mechanisms to capture logic
rules from entropy-based linear layers [17].
4.8.6. Visualisation
There is an underlying interest in providing visual cues about the learning process of complex systems (e.g.
Federated Learning). For example, privacy enhancement techniques like differential privacy are often integrated into
FL optimisation, which can further reduce explainability and limit confidence in the results.
HetVis [279] has developed a pipeline visualisation framework, facilitating the introspection of horizontal
Federated Learning applications in 3 distinct phases (model learning, predictions comparison, and heterogeneity
examination).
More focused on data privacy implications, Guo et al. [97] developed a framework allowing data owners to visually
analyze privacy risks in FL.
To conclude the FL Trustworthiness section, an essential foundation for real-world applications, we encourage
the reader to explore a more in-depth survey on trustworthy Federated Learning [333].
4.9. Final Reflections on the Meta-Framework Perspective
In this section, we have provided a detailed review of the literature addressing each sub-module within our modular
Meta-Framework perspective. We proposed that Federated Learning can be viewed as a modular system composed of
interchangeable and complementary components. To illustrate how these modules integrate within the broader FL
framework, we refer the reader to Fig. 21. We hope this visual representation facilitates a deeper understanding of FL
as a structured and adaptable framework, where different methods can be combined to enhance key properties such as
security, privacy, trustworthiness, efficiency, and convergence.
5. Frameworks & Libraries
Unlike classical Machine Learning or Deep Learning projects mainly using a learning framework like PyTorch
or Jax, Federated Learning also requires a special learning infrastructure to deal with clients and server processes/-
communication. Therefore, in an attempt to ease the burden of every FL researcher creating a boilerplate for the
FL infrastructure and also in a pursuit to create a distributed learning framework standard, several frameworks have
been proposed. We explore the vast alternatives and expand upon a previous analysis that encompasses several FL
frameworks [33].
5.1. Federated Learning Frameworks
General Federated Learning Frameworks:
‚Ä¢ Tensorflow Federated (TFF) [93]. TFF is an open-source FL framework originated by the TensorFlow team. The
framework interface is divided into two core layers: Federated Learning (FL) API ‚Äì high-level layer designed
Frederico Vicente et al.
Page 47 of 70
Modular Federated Learning: A Meta-Framework Perspective
Client 1
Local
Data
+
Labels Noise
Injection
+
Differential
Privacy Noise
+
Encryption
Data Processing (Training Data)
Model
Parameters
+
Uncertainty
Estimation
+
Differential
Privacy Noise
Learning Parameters
Normal
Homomorphic Encryption
|
Public
Data
ùú≠c
ZK Proofs
|
Gradients
Parameters
Statistics
|
Predictions (Logits)
|
Proxy parameters
|
Token parameters
|
Embeddings
|
Communication (Content)
Infrastructure
TEE
Normal
|
Blockchain
|
+
Local Data
Fidelity 
+
+
Model 
Regularisation 
Global Model
Regularisation
+
Secure 
Aggregation
(Masks)
Local Optimisation ùìõ(ùú≠ )
c
Client c
Parameters Average
Aggregation
Knowledge Distillation
|
Local Data Training 
|
Server
Parameters/Gradients 
Average
Knowledge Distillation
Aggregation
|
Features Average
|
Concatenation
|
|
ùú≠
Synchronous
Asynchronous
|
Semi-Synchronous
|
Learning / Communication (Periodicity)
+
Secure 
Aggregation
(Masks)
Infrastructure
Threat
Protection
Distributed
Optimization
Data
Model
Design
Figure 21: An architectural overview of the modular options for building an FL framework is presented. The + operator
indicates the possibility of stacking modules, while the | operator represents a modular design choice. Although we aimed to
cover many modular possibilities in this diagram, it is not exhaustive (e.g. Differential Privacy can be applied to parameters,
loss functions, or optimisers, among others).
Frederico Vicente et al.
Page 48 of 70
Modular Federated Learning: A Meta-Framework Perspective
for applying pre-built FL algorithms and evaluation schemes; Federated Core (FC) API ‚Äì low-level layer to
customise communication and federated algorithms (it is the basis of the first layer).
‚Ä¢ FATE [166]. Open-source FL framework designed for industry deployments and deeply rooted to secure
computation protocols based on Homomorphic Encryption and Multi-Party Computation (MPC)
‚Ä¢ PySyft [230]. Open-source data science framework with some Federated Learning capabilities.
‚Ä¢ NVIDIA Flare (NVFlare) [224]. NVIDIA Federated Learning Application Runtime Environment is an open-
source FL Framework designed for private and secure real-world deployments, and it is flexible enough for
research applications.
‚Ä¢ IBM FL [169]. IBM Federated Learning is a Python framework for Federated Learning that includes built-in
fusion algorithms and allows for customisation of aggregation methods.
‚Ä¢ OpenFL [83]. Originally designed for the healthcare domain, OpenFL is an open-source Federated Learning
framework concerned with providing a scalable and secure implementation for both research and production
use. All federation collaborators agree on a Federated Plan (inspired by [27]), which is parsed both at the client
and server side to process and communicate the learning procedure.
‚Ä¢ MetisFL [250]. MetisFL proposes a blatant fast open source Federated Learning framework, designed with
asynchronous communication by default. MetisFL implemented the server component in C++ to provide low-
level optimisations to the server operations, along with other key useful abstractions: model-store databases, and
secure aggregators. They introduce this notion of a Federation Driver driven by a user/client configuration file,
which is responsible for Secure Key generation, model/system initiation and monitoring.
‚Ä¢ PaddleFL [200]. An open-source Federated Learning framework based on PaddlePaddle. Supports both Hori-
zontal and Vertical Learning strategies.
‚Ä¢ FedLab [325]. FedLab is an open-source FL framework with several federated optimisation algorithms imple-
mented and data partitioning techniques.
‚Ä¢ Flower [23]. An open-source Federated Learning framework, very flexible by design providing easy-to-follow
and in-depth documentation, with key characteristics (e.g. asynchronous communication protocols).
‚Ä¢ SubstraFL [85]. Exploring the deficiencies of other FL frameworks regarding robustness to real-world deploy-
ments, while guaranteeing easy and fast R&D Research Substra and SubstraFL were created. Substra is an
SDK library running on clients, whereas SubstraFL is a Python high-level framework based on Substra to run
Federated Learning experiments at scale.
‚Ä¢ FedML Federate [107]. FedML is a commercial ML framework to train, to collect data and to serve models. One
of their solutions is the FedML Federate to train and serve federated models.
‚Ä¢ FEDn [75]. FedN is an efficient and lightweight open-source Federated Learning framework providing a
Hierarchical FL solution. It is deeply inspired by the MapReduce programming model since it hierarchically
combines and reduces distributed computation.
Tree-based Federated Learning Frameworks:
‚Ä¢ Federated XGBoost [295]. This framework is a Federated Learning extension to the XGBoost-optimised
distributed gradient boosting library.
‚Ä¢ FedTree [150]. It is a framework to train gradient boosting decision tree models, having in consideration
privacy/security and data heterogeneity concerns.
Frederico Vicente et al.
Page 49 of 70
Modular Federated Learning: A Meta-Framework Perspective
Table 6
Comparison between FL frameworks in regards to their respective data, privacy & security implementations.
Framework
Purpose
ML
Backend
Horizontal
FL
Vertical
FL
Privacy & Secure
Mechanisms
Crypto
Library
NVFlare
FL
Torch | TF | MONAI
‚úì
√ó
FHE
TenSeal
FATE
FL
Torch
‚úì
‚úì
MPC | PSI | FHE | SE
curve25519_dalek
| x25519_dalek
| native
PySyft
Data Science | FL
Torch
‚úì
√ó
FHE
TenSeal
IBM FL
FL
Torch | TF
‚úì
√ó
FHE
HElayers
OpenFL
FL
Torch | TF
‚úì
√ó
TEE
Graphene
TFF
FL | Analytics
TF
‚úì
√ó
DP | SE | etc
native (TFP)
MetisFL
FL
Torch | TF
‚úì
√ó
FHE
PALISADE
FedLab
FL
Torch
‚úì
√ó
-
-
PaddleFL
FL
Torch
‚úì
‚úì
FHE
TenSeal
Flower
FL | Analytics
agnostic
‚úì
√ó
DP | Masking | FHE
Native
SubstraFL
FL | Analytics
agnostic
‚úì
√ó
-
-
FedML Federate
FL
Torch | TF | MX | JAX
‚úì
√ó
Masking | FHE
Native
FEDn
FL
agnostic
‚úì
√ó
-
-
Domain focused frameworks:
‚Ä¢ Fed-BioMed [60]. A framework designed to be used for real-world medical applications including Federated
Learning/analytics.
Apart from the Tensorflow Federated project, Google has also proposed FedJax [221], a Federated Learning
simulations framework specially designed for JAX. More recently, Google proposed a federated auto differentiation
framework [228] and published a library (FAX: Rush et al. [229]) based on the JAX deep learning framework to utilise
it.
Apple has developed pfl [96], a Python framework for Private Federated Learning simulations focusing on privacy
features, flexible ML model support and straightforward benchmark testing.
P2PFL [199] is an open-source Python library designed to develop applications in real and simulated environments.
It focuses on peer-to-peer networks, utilizing decentralised and gossip protocols.
ChainFL [213] is a general simulation framework written in Python for training Federated Learning models on
distributed edge environments. It provides security guarantees similar to blockchain algorithms, ensuring updated
parameters‚Äô integrity by preventing modification.
5.2. Frameworks in-depth comparison
Inspired by the framework comparison approach introduced by MetisFL [250], we present systematic tables that
summarise the key differences among general-purpose Federated Learning frameworks.
‚Ä¢ Table 6 provides an overview of the privacy and security protocols implemented in each framework.
‚Ä¢ Table 7 highlights the communication strategies and implementation choices.
‚Ä¢ Table 8 offers a broader comparative analysis, capturing the general distinctions between the frameworks.
These structured comparisons aim to provide a clear and comprehensive understanding of the current state of
Federated Learning frameworks.
5.3. On-device Learning Frameworks
Concerned with the hardware limitations of edge devices, Tiny Training Engine [159], TinyTL [34] and Tiny-
Train [141] frameworks have been proposed to depart from the continuous communication dependency between
devices in a Federated Learning Schema. These frameworks focus on leveraging techniques to make the on-device
learning process more efficient while using fewer resources (e.g. Transfer Learning, Layers Pruning, Meta-Learning,
and Sparse Learning techniques). Moreover, Tinygrad [58] is a promising low-resource and open-source deep learning
Frederico Vicente et al.
Page 50 of 70
Modular Federated Learning: A Meta-Framework Perspective
Table 7
Comparison between FL frameworks in regards to their corresponding federated communication utilities.
Framework
Centralised
Decentralised
Hierarchical
Protocol
Synchronous
Asynchronous
NVFlare
‚úì
√ó
√ó
gRPC
‚úì
√ó
FATE
‚úì
√ó
√ó
gRPC/MQ
‚úì
√ó
PySyft
‚úì
√ó
√ó
REST
‚úì
√ó
IBM FL
‚úì
√ó
√ó
AMQP
‚úì
√ó
OpenFL
‚úì
√ó
√ó
gRPC
‚úì
√ó
TFF
‚úì
√ó
√ó
gRPC
‚úì
√ó
MetisFL
‚úì
√ó
√ó
gRPC
‚úì
‚úì
FedLab
‚úì
√ó
‚úì
Gloo
‚úì
‚úì
PaddleFL
‚úì
‚úì
‚úì
gRPC
‚úì
√ó
Flower
‚úì
√ó
√ó
gRPC
‚úì
√ó
SubstraFL
‚úì
√ó
√ó
REST
‚úì
‚úì
FedML Federate
‚úì
‚úì
√ó
MPI
‚úì
√ó
FEDn
‚úì
√ó
‚úì
gRPC & REST
‚úì
‚úì
Table 8
Meta-information comparison between FL frameworks. (*) indicates low quality, while (***) represents high quality.
Framework
Deprecated /
Unmaintained
Host
Documentation
Quality
User
Friendly
NVFlare
√ó
NVidia
***
**
FATE
√ó
Linux Foundation
**
**
PySyft
√ó
OpenMined
**
**
IBM FL
‚úì
IBM
**
*
OpenFL
√ó
Linux Foundation
**
*
TFF
√ó
Tensorflow
***
***
MetisFL
√ó
MetisFL
**
***
FedLab
√ó
SMILELab-FL
**
**
PaddleFL
‚úì
PaddlePaddle
*
*
Flower
√ó
Flower
***
***
SubstraFL
√ó
Linux Foundation
***
***
FedML Federate
√ó
FedML
**
**
FEDn
√ó
Scaleout Systems
**
**
framework with a strong focus on being compatible with on-device chip accelerators. Since these frameworks do not
consider FL algorithms design, we do not explore them in detail. However, we believe that the combination of on-device
learning methodologies and FL is a step forward to more robust real-world ML Edge applications.
6. Alternative Paths in Distributed Learning
6.1. Distributed Deep Neural Networks
At present, large models with billions are extensively being trained, either in the Natural Language Processing or
in the image/video synthesis domain. The training pipeline duration of those large architectures can last a considerable
number of hours/days. Thus, the necessity to accelerate the training procedure is real. One way to accelerate the
training process is to dismount the complete model architecture into sub-parts within several distributed nodes. Such a
distributed learning mechanism is called Model Parallelism of Distributed Deep Neural Networks (DDNN: Shoeybi
et al. [246]). This methodology proves to be complex since it requires a decision on how and where to partition the
model into several network nodes [86].
In an orthogonal direction, Data Parallelism, consists of learning the same model through multiple distributed
data silos. From a holistic perspective, homogeneous model training within Federated Learning can be considered a
take on Data Parallelism within a distributed learning setting.
Frederico Vicente et al.
Page 51 of 70
Modular Federated Learning: A Meta-Framework Perspective
There is also the Pipelining parallelism technique, which divides training tasks for DNN models into sequential
processing stages, through the assumption that models are sequentially composed and can be relaxed (e.g. using skip
connections). Consider Torchgpipe work [133], a torch implementation of GPipe [114], a framework for computing a
model training distributively by pipelining model layers computations in a parallel arrangement.
Finally, some works utilise Hybrid Parallelisation techniques [188, 78], which combine Data and Model
Parallelisation methodologies to mitigate communication overhead/increase training speed convergence.
Orthogonal to these methodologies, there are also Distributed Tensor Computation techniques, which partition
tensor operations into distributed machines to speed up computation or permit bigger model size training [308].
We invite the reader to further explore this theme through the survey [65].
6.2. Modular Deep Learning
Modular Deep Learning [206] is gaining popularity, as a solution to build an autonomous multi-task model
combining many expert models on specific tasks, whilst mitigating the negative interference of the models merging. In
this line of Modular Deep Learning, DiPaCo [73] has proposed a sparsely-activated modular learning network where
data and computation are distributed between clients. This results in a distributed learning network which on inference
selects one of many expert paths of nodes to make a prediction, thus, using only a sparse set of clients.
6.2.1. Model Merging
In the Large Language Model (LLM) literature, the notion of model fusion where different task-based models
are merged to procreate a more general model with better out-of-distribution performance is gaining popularity. It
entails an orthogonal direction to Federated Learning since no distributed learning is performed, however, the action
of model fusion is intrinsically customary to the FL framework. Consequently, this raises the question of whether
there are some methodologies from this new model fusion trend which could inspire some better model alignment in
FL. Since there is an analogous relationship between Federated Learning model alignment and the new approaches to
LLM model merging, we briefly discuss the main model fusion techniques: Model Soup [289], Task Arithmetic [117],
TIES-Merging [307], DARE [319].
Model Soup. This technique uses a weighted average of trained models, without retraining them. In spirit, this
merging technique is similar to a weighted FedAvg, not only due to the weighted model aggregation but also due
to the data used for training each model not being the same. In Model Soup, model training further distinguishes itself
by the usage of different training hyper-parameters.
Task Arithmetic. Focused on the notion of task vectors (delta between the weights of a task fine-tuned model and
its corresponding pre-trained model), Task Arithmetic is a method, which applies vector operations over a set of task-
specific fine-tuned models (adding/negating/relating vectors) to have an end-model more general.
Ties-Merging. Confronted with the redundancy of parameters and conflicting element-wise sign values in model
merging techniques, Ties-Merging proposes an extension to Task Arithmetic work. Ties-Merging trims useless
parameter values, resolves conflicting signs and aligns parameters which are in agreement.
DARE. Delta parameters (i.e. the difference between fine-tuned and pre-trained parameters) do not all have the same
beneficial impact on the fine-tuned task. DARE took this idea and systematically dropped delta parameters which do
not influence performance when merging models, whilst increasing the capabilities of the final model.
Considering the panoramic view of these works, one could use these methodologies (e.g. Task Arithmetic based),
in a peer-to-peer network with homogeneous models to better guide the learning from each local client model.
6.3. Federated Statistics
We have showcased that distributed systems can be designed to support learning mechanisms, as discussed
throughout this survey. However, general data science tasks can also be performed in a federated setting (e.g., statistical
analysis such as binning data into intervals or building histograms) without compromising user data. This adjacent
field to Federated Learning is called Federated Statistics. Differential Privacy and Secure Aggregation mechanisms we
explored in Section. 4.7 and Section. 4.6 represent the foundational mechanism for computing statistics of the federation
Frederico Vicente et al.
Page 52 of 70
Modular Federated Learning: A Meta-Framework Perspective
population, whilst preserving some level of anonymity. McMillan et al. [178] extend this approach by incorporating
an on-device Differential Privacy mechanism, allowing the end-user/client to control the privacy level.
6.4. Distributed Consensus
In Federated Learning, the most common objective is to obtain a global consensus on a global model which best
fits all the clients. This implies that some sort of network topology is in place ensuring that they can communicate and
that it is robust to network perturbations. In the distributed systems field, this inherent consensus goal of FL dates back
to the 1980s through the work of Lamport [142]. Lamport presented the Paxos consensus algorithm, focusing mainly
on single-decree Paxos.
Raft [198] was presented in 2014, attempting to create a simpler consensus protocol and combat deficiencies of the
Paxos method. Raft defines the existence of a leader in a network as one who is elected by other nodes in a network.
This leader changes occasionally, and the network is designed to be fault-tolerant, and a new leader is elected when
needed. The objective of the leader is to ensure a consensus is guaranteed in good terms. The notary properties of Raft
(e.g. a fault-tolerant algorithm) make it useful for FL decentralised network topologies, as explored by Behera et al.
[20].
7. Federated Learning in Practice and Deployment
7.1. Contemporary use-cases
Conventional Machine Learning applications on business projects stand heavy on exploring the data and conducting
analysis over it. Since the data is localised and not accessible, monitoring and debugging stand as a challenging aspect of
building federated solutions. By maintaining data processing, model training, and model inference locally on devices,
sensitive user data is not transmitted across borders or regions, thereby avoiding major compliance challenges for
organizations. Nevertheless, the useful properties of FL have led to developments and research in several fields:
7.1.1. Healthcare
In the health domain, patient privacy is taken very seriously, which hinders the availability and access to data.
The data itself is also very expensive to acquire/annotate: BrainTorrent [225] notes that a 3D brain MRI scan manual
annotation can take up to a week by a trained professional. In this work, they take a peer-to-peer approach to Federated
Learning. In contrast, Ogier du Terrail et al. [261] adheres to a distributed star-schema topology, exemplifying a
collaborative effort among multiple hospitals aimed at enhancing the accuracy and efficiency of predicting patients‚Äô
histological response to Neoadjuvant Chemotherapy (NACT).
On Drug Discovery research, the MELLODY project is an attempt to enhance predictive Machine Learning models
on decentralised data over many partner companies, without exposing proprietary information.
The MetaBreast project in an orthogonal direction has paved the way for creating a public cloud data health centre
with anonymous data.
FL-based smart healthcare applications can also be found under the domain of the Medical Internet of Things
(MIoT), which normally follows a more complex network infrastructure [210]. Typical solutions, normally invoke
the combination of IoT devices (e.g. smart inhaler, smart-watch) with more resilient edge devices (e.g. smartphone).
Contrasting with standard FL applications, the data in a local network can move from an IoT device to a more powerful
edge device, to perform training/inference with better reliability.
Accessibility. IoT/Embedded systems advancements allow for potential breakthroughs in designing systems to help
people with accessibility issues. Most importantly, FL helps to bring personalised solutions to these people. Machine
Learning Systems with TinyML book [218] suggests some interesting applications: a. Responsive prosthetic limbs,
which through the analysis of nerve signals, and muscle tension can move and adjust the grip of the prosthetics and
exoskeletons dynamically; b. Voice-enabled devices can be designed to translate non-verbal inputs to personalised
vocal outputs; c. The creation of interfaces to convert gestures into natural speech tailored for individual users and
the opposite. d. Development of smart glasses to convert visual information into audio input. e. Hearing aids to help
intelligently amplify different sources of audio.
7.1.2. Factories (Industry 4.0)
Industry 4.0 represents a significant advancement in the manufacturing industry, where the seamless interconnectiv-
ity of machines serves as a cornerstone for enhanced monitoring, performance optimization, and accountability. In this
Frederico Vicente et al.
Page 53 of 70
Modular Federated Learning: A Meta-Framework Perspective
envisioned landscape, wireless networks emerge as indispensable due to their unparalleled flexibility and portability,
offering distinct advantages over traditional cable or optical fibre solutions.
Digital Twins are the basis of this new revolution in which physical machines have a corresponding digital
representation, through the usage of sensors and other IoT devices deeply connected to the original devices. The
presence of such technology in factories, for instance, permits machine equipment to be automatically diagnosed,
either for faulty clues or for production quality inspection with the help of Federated Learning methodologies.
FedGS [155] proposes a clustered Federated Learning solution for factory environments where OCR is used to
identify factory artefacts (e.g., packing boxes) through the reading of their badges. Faced with the fact data distributions
vary among factories, they propose a constrained gradient-based optimiser (Gradient-Based Binary Permutation Client
Selection: GBP-CS) with group/cluster synchronisation.
7.1.3. Energy & Agriculture
Smart Homes are gaining popularity through the increasing integration of small IoT devices inside peoples‚Äô
houses. Their utility explains their search in helping to register energy consumption, optimise energy spending, and
record raw data (e.g. CCTV Cameras): Lee and Choi [144]. Water supply can also be optimised through personalised
analysis of individual houses, resulting in smaller bills and wasted resources [76]. The distributed nature of energy and
water resources enhances the collaboration dynamism and reliability of estimations when using Federated Learning
techniques.
Drones equipped with sensors and cameras are helping to gather data previously very hard and expensive to obtain.
Further, a coordinated mesh of drones can capture with much more fidelity ground terrains, leading to better quality
data which can increase models‚Äô predictive performance [53].
Digital twins can also be used in renewable energy-producing devices along with Federated Learning to better
maintain them and optimise their efficiency.
To better preserve limited resources (e.g. water), there is interest in turning agriculture more efficient, sustainable
and more robust to natural disasters. Smart Agriculture is a paradigm that utilises low-energy devices (e.g. sensors) to
help better monitor agriculture production.
On this domain, PEFL [140], concerned with malicious attacks, proposes a combination of a two-level privacy
module of perturbation-based encoding with an intrusion detection trained using the FL framework and a Gated
Recurrent Unit (GRU) model to flag out corrupted devices.
For diseases/pests control of crops, Deng et al. [66] have proposed a Federated Learning framework using R-CNN
architectures.
7.1.4. Space
The space domain faces many challenges, from logistical cooperation between organisations to practical operations
such as rocket launching, and lunar vehicle mobilisation. FRIENDS [57] proposes an inter-connected network of Lunar
nodes for a more robust lunar exploration. A federated deployment of MoonNet was used and it resorted to pseudo-
labelled training updates.
Furthermore, there is interest in the collaboration of different public and private entities, provided that space
exploration is a global effort. Initiatives, such as SpaceDAO [31], are developing a Blockchain-Based Consensus
Mechanism to support, among other use cases, a Federated Learning ecosystem to ensure safer collaborative space
traffic.
7.1.5. Others
Google Keyboard (Gboard) is historically an early adopter of Federated Learning [104, 304], using it for three
main tasks: 1. Next Word Prediction (NWP) to predict the next word to be typed; 2. Smart Compose (SC) to suggest
probable inline characters to be typed; 3. On-The-Fly Re-scoring (OTF) to re-rank next-word candidates.
Recently, ‚ÄúGenerative AI‚Äù gained considerable popularity by introducing high-quality Large Language Models in
mundane applications, along with state-of-the-art Diffusion Models in the image generation realm. Adapting these
models to federated training/fine-tuning is a promising future direction. FedTabDiff [233], in the domain of table data
synthetic generation, proposes a federation learning approach to Denoising Diffusion Models.
Mixing genetic evolutionary algorithms with clustering techniques has also been proposed to improve training
hyperparameter tuning [4].
Frederico Vicente et al.
Page 54 of 70
Modular Federated Learning: A Meta-Framework Perspective
In a different line of work, there is research [326] fusing Federated Learning with over-the-air computation in the
maritime domain to reduce the communication overhead, by applying computation over communication frequencies.
7.2. Federated Learning as a Service (FLaaS)
Machine Learning as a Service (MLaaS) has exploded in popularity in recent years since it provides easy access
to public data, novel models and infrastructure provisioning. To expand the cloud provisioning of Machine Learning
solutions we argue that there is a considerable market for Federated Learning as a Service (FLaaS).
FLaaS may provide collaborative heterogeneous learning solutions, where entities interested in a similar learning
task may interchange a proxy model learnt on local data to train a global model accessible to the participating parties,
without revealing either raw local data or model architectures.
In the literature, CrowdFL [81] implements a simple collaborative learning infrastructure, focusing on mobile
devices, but without exploring the essence of the heterogeneous virtue of the data and even models underlying
federation learning applicability. FLaaS [138] explores a robust take on Federated Learning as a Service, whilst building
an infrastructure with specific APIs for data, model, protection and training resources.
We envision a key role of homogeneous and heterogeneous model learning and, therefore provide two clear paths
for an FLaaS Marketplace solution:
‚Ä¢ Within a network each independent entity agrees on a shared model architecture protocol to solve a specific task
(the local and shared models are the same);
‚Ä¢ Similar to Proxy Model Sharing work [127], following a more relaxed cooperation mechanism, each entity
in the federation solely agrees on a task. This vision assumes heterogeneous modelling between the entities
participating in the federation. Thus, the communicated/shared model acts as a communication protocol, where
the data transmitted is a local model representing the heterogeneous compressed knowledge.
7.3. Federated Learning Operations (FLOps)
Designing a Machine Learning pipeline involves a thoughtful life-cycle development. This practice of orchestrating
well-grounded workflows and robust Machine Learning systems is called Machine Learning Operations (MLOps).
Normally, it consists of a hierarchical directed graph with three main phases: 1. Data Handling Phase; 2. Training
Phase; 3. Deployment Phase (See Fig. 22 for a holistic view of the standard approach to a Machine Learning pipeline).
| Sensor Stream
| Data Vendor
| Concept Drift
| Data Drift
| Up-to-date Data
| Human  Generated
| Machine Generated
Data 
Acquirement
Data
Annotation
Data
Processing
Model
Training
Model
Validation
Model
Deployment
Inference
(Edge)
Training Phase
Deployment Phase
Continual Learning
| Replace
| Canary Deployment
Monitoring
Monitoring
Figure 22: Standard Machine Learning Application life-cycle. Deployment Machine Learning pipelines, normally, have 3 main
phases: 1. Data Management; 2. Model Training; 3. Model Deployment. To make the pipeline robust, the introduction
of a cycle comes naturally with the help of monitoring mechanisms. Whereas during training, monitoring helps debug
processes and reproduce experiments, in the deployment phase it helps to audit shifts in performance. This notion of a
cycle represents the system‚Äôs ongoing evolution in its quest for enhanced performance within an ever-changing environment.
Federated Learning Operations can be regarded as an extension of the well-studied domain of Machine Learning
Operations, where the mechanics of a Machine Learning life-cycle are put into practice in a distributed setting.
A combination of Federated Learning Frameworks (e.g. Flower) focusing on easing the distributed learning
infrastructure; Machine Learning Monitoring frameworks (e.g. WandB: Biewald [24]); And On-Device Learning
frameworks (e.g. Edge Impulse: Hymel et al. [116]) designed for monitoring/deploying inference real-time products
provide a solid FLOps architecture.
Frederico Vicente et al.
Page 55 of 70
Modular Federated Learning: A Meta-Framework Perspective
7.4. Environment Impact
Federated Learning reduces the bandwidth of sending raw data across devices and the cloud, however the compu-
tation and communication overhead of aligning the several intertwined devices‚Äô models computed by heterogeneous
devices is non-negligible. As stated by Wu et al. [291], FL pipelines can be malign to the environment because most
devices are on the edge computing on low energy efficient devices, consuming fossil-based energy. Cloud premises,
differently, have further control since green energies can power them and use special hardware for more optimal
resource spending (See Fig. 23, an adaptation figure from Wu et al. [291]).
3.5
2.5
1
1.5
0
0.5
CO2e(kg)
Hundreds
Download
Upload
Compute
Facebook
FL-1
FL-2
TPU-Base
TPU-Green
V100-Base
V100-Green
Transformer-big (non-FL)
2
3
Figure 23: According to Wu et al. [291], Federated Learning can have considerable CO2 emissions (carbon footprint),
when compared with standard centralised Large Models training.
Due to the limited resources found in Edge Devices, each training round is expected to take considerably more time
than training it on a cloud server, considering an identical task.
Green Federated Learning [316], aware of the inefficiency attribute of Federated Learning has suggested the
consideration of Carbon Emissions as an optimisation variable. They establish a strong correlation between the training
time and the cohort size of a federation as strong factors for large-scale carbon emissions. Thus, carbon footprint
optimisation relies on the client side (training) and communication side (upload/download weights/statistics). From
their analysis, with the right parameterisation, AsyncFL converges faster reducing training time, however, it pollutes
considerably more than the respective synchronous version.
Model compression and quantisation can also help reduce the environmental impact while increasing the efficiency
of the training/communication. For instance, implementing the widely-used int8 quantization technique in FL, as
developed by Prasad et al. [209], and estimated by Yousefpour et al. [316], can potentially decrease the carbon footprint
by a factor of 1.8.
The rise of interest in measuring ML carbon footprint has given birth to the CodeCarbon [236] framework, which
provides extensive utilities to measure an estimation of CPU, GPU and RAM computations carbon footprint.
8. Future Directions
Federated Learning (FL) continues to evolve, driven by its ability to facilitate distributed learning while addressing
privacy, security, and data sovereignty concerns. However, despite its growing adoption, several challenges persist,
particularly in terms of privacy guarantees, communication efficiency, resource heterogeneity, and the lack of
standardised FL frameworks. To advance the field, we outline key research directions that will be crucial for future
developments.
8.1. Enhancing Trustworthiness
Ensuring trust in FL is critical for its adoption in high-stakes domains such as healthcare, finance, and autonomous
systems. A major research priority is improving uncertainty estimation techniques, which allow models to quantify
Frederico Vicente et al.
Page 56 of 70
Modular Federated Learning: A Meta-Framework Perspective
confidence in their predictions and detect unreliable outputs. Additionally, more robust learning mechanisms must be
developed to handle adversarial threats, including data poisoning and model inversion attacks. Privacy-preserving
model auditing frameworks are also essential to ensure that FL systems comply with ethical AI principles and
regulatory requirements, fostering broader adoption in privacy-sensitive applications. As we have explored, informed
learning in Federated Learning plays a crucial role in enabling more controlled and robust distributed models. This
approach allows for the integration of domain-specific rules, expert knowledge, mathematical constraints, and physical
dynamics, enhancing both the reliability and interpretability of FL systems.
8.2. Optimising Communication and Resource Management
FL operates in highly heterogeneous environments where participating devices differ in computational capacity,
energy constraints, and network connectivity. Future work should focus on adaptive parameter optimisation methods
that dynamically balance local computation efficiency with global convergence speed. Additionally, communication-
aware aggregation strategies must be developed to reduce bandwidth consumption without degrading model perfor-
mance. Research into efficient offloading techniques that intelligently distribute computation across heterogeneous
hardware, including edge devices, microcontrollers, and AI accelerators, will be key to improving FL‚Äôs scalability.
8.3. Standardisation and Open Federated Learning Platforms
The absence of standardised frameworks for FL hinders its widespread adoption. A promising direction is the
development of federated open platforms where multiple organisations can collaborate securely on decentralised
learning tasks. This requires advances in secure multi-party computation, ensuring that entities with different trust
levels can jointly train models without compromising data privacy. Establishing interoperability standards for FL
systems, along with curated benchmark datasets and evaluation metrics, would further facilitate FL research and
deployment across different domains.
8.4. Resource-Constrained Learning
Deploying FL on low-power devices, such as IoT sensors and embedded systems, remains challenging due to
their limited computational resources. Future research should explore energy-efficient training algorithms that
optimise power consumption while maintaining learning effectiveness. Hardware-aware FL optimisations, leveraging
AI chip accelerators, will also be necessary to enhance model inference efficiency. Moreover, advances in gradient
compression techniques could significantly reduce communication overhead, making FL more viable in bandwidth-
constrained environments.
8.5. Model Compression and Quantisation Strategies
Communication costs continue to be a major bottleneck in FL. Future research should investigate model
compression techniques such as pruning, distillation, and tensor decomposition to reduce the complexity of FL models
while preserving performance. Low-precision quantisation methods can further decrease transmission costs by
encoding model updates more efficiently. Additionally, sparse learning approaches and federated dropout strategies
could improve communication efficiency while maintaining model robustness.
8.6. Interdisciplinary Synergies and Emerging Applications
FL can benefit from advances in complementary research fields. Integrating neurosymbolic AI could improve
model interpretability by combining FL with structured reasoning. Similarly, self-supervised and continual learning
could enhance FL‚Äôs ability to adapt to dynamic, non-stationary data distributions. Another promising direction is
federated reinforcement learning, which has the potential to optimise decentralised decision-making in applications
such as smart grids, autonomous vehicles, and industrial automation.
9. Conclusion
Federated Learning (FL) is transforming machine learning in critical domains such as healthcare, finance, and
edge computing by enabling distributed learning while offering the potential for enhanced privacy, security, and
trustworthiness. However, as FL adoption grows, it is crucial to develop systematic methodologies that enhance its
design, adaptability, and real-world applicability.
In this survey, we have proposed a Meta-Framework perspective that organises FL as a modular and composable
system, structuring its key dimensions into interoperable components. This approach provides a unifying blueprint
Frederico Vicente et al.
Page 57 of 70
Modular Federated Learning: A Meta-Framework Perspective
for systematically designing and implementing FL frameworks, offering both a theoretical foundation and a practical
guide for researchers and practitioners.
Additionally, we introduce a novel taxonomy for Alignment, positioning it as a fundamental counterpart to
Aggregation in FL. By recognising that aggregation not only combines parameters but also constrains them to ensure
knowledge alignment, this perspective deepens our understanding of FL‚Äôs learning dynamics and its effectiveness in
heterogeneous environments.
To further contextualise FL, we have traced its historical evolution, linking it to distributed optimisation and
demonstrating how its foundations have shaped modern advancements. Recognising the need for accessibility, we
have also provided a structured introduction to FL, lowering the barrier to entry for new researchers. Additionally, we
offer a systematic analysis of Python-based FL frameworks, identifying key tools for hands-on experimentation and
deployment. Finally, we have categorised pressing challenges across FL sub-fields, outlining key research directions
for the community.
Despite significant progress, FL still faces major hurdles. Future research must focus on parameter-efficient
models, communication-aware optimisation, knowledge alignment techniques, and the development of Green FL
methodologies to enhance sustainability. Equally critical is the advancement of trustworthy FL, ensuring fairness,
robustness, and interpretability, particularly in critical applications.
Ultimately, FL represents a paradigm shift in machine learning, offering a scalable alternative to traditional cen-
tralised approaches. It provides potential privacy benefits, addresses data governance challenges, and offers solutions
for problems that are inherently distributed. As research progresses, refining FL methodologies and addressing existing
challenges will be crucial in unlocking its full potential. By viewing FL through a Meta-Framework perspective, we
provide a roadmap for more structured, adaptable, and impactful advancements in this evolving field.
References
[1] Acar, A., Aksu, H., Uluagac, A.S., Conti, M., 2018. A survey on homomorphic encryption schemes: Theory and implementation. ACM
Comput. Surv. 51. URL: https://doi.org/10.1145/3214303, doi:10.1145/3214303.
[2] Achituve, I., Shamsian, A., Navon, A., Chechik, G., Fetaya, E., 2021.
Personalized federated learning with gaussian processes,
in: Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., Vaughan, J.W. (Eds.), Advances in Neural Information Processing Sys-
tems, Curran Associates, Inc.. pp. 8392‚Äì8406.
URL: https://proceedings.neurips.cc/paper_files/paper/2021/file/
46d0671dd4117ea366031f87f3aa0093-Paper.pdf.
[3] Addanki, S., Garbe, K., Jaffe, E., Ostrovsky, R., Polychroniadou, A., 2022. Prio+: Privacy preserving aggregate statistics via boolean shares,
in: Galdi, C., Jarecki, S. (Eds.), Security and Cryptography for Networks, Springer International Publishing, Cham. pp. 516‚Äì539.
[4] Agrawal, S., Sarkar, S., Alazab, M., Maddikunta, P.K.R., Gadekallu, T.R., Pham, Q.V., 2021.
Genetic cfl: Hyperparameter
optimization in clustered federated learning.
Computational Intelligence and Neuroscience 2021, 7156420.
URL: https:
//onlinelibrary.wiley.com/doi/abs/10.1155/2021/7156420,
doi:https://doi.org/10.1155/2021/7156420,
arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1155/2021/7156420.
[5] Ahmed, F., Sanchez, D., Haddi, Z., Domingo-Ferrer, J., 2025. Membershield: A framework for federated learning with membership privacy.
Neural Networks 181, 106768.
[6] An, Z., Johnson, T.T., Ma, M., 2024. Formal logic enabled personalized federated learning through property inference, in: Proceedings of
the 38th AAAI Conference on Artificial Intelligence (AAAI‚Äô24). doi:10.1609/aaai.v38i10.28962.
[7] Angluin, D., Laird, P., 1988. Learning from noisy examples. Machine Learning 2, 343‚Äì370. URL: https://doi.org/10.1023/A:
1022873112823, doi:10.1023/A:1022873112823.
[8] Anguita, D., Ghio, A., Oneto, L., Parra, X., Reyes-Ortiz, J.L., et al., 2013. A public domain dataset for human activity recognition using
smartphones., in: Esann, p. 3.
[9] Anil, R., Pereyra, G., Passos, A., Ormandi, R., Dahl, G.E., Hinton, G.E., 2018. Large scale distributed neural network training through online
distillation. arXiv preprint arXiv:1804.03235 .
[10] Ardila, R., Branson, M., Davis, K., Kohler, M., Meyer, J., et al., 2020.
Common voice: A massively-multilingual speech corpus, in:
Proceedings of the Twelfth Language Resources and Evaluation Conference, European Language Resources Association, Marseille, France.
pp. 4218‚Äì4222. URL: https://aclanthology.org/2020.lrec-1.520.
[11] Armacki, A., Bajovic, D., Jakovetic, D., Kar, S., 2022. Personalized federated learning via convex clustering, in: 2022 IEEE International
Smart Cities Conference (ISC2), pp. 1‚Äì7. doi:10.1109/ISC255366.2022.9921863.
[12] Awan, S., Luo, B., Li, F., 2021. Contra: Defending against poisoning attacks in federated learning, in: Computer Security ‚Äì ESORICS 2021:
26th European Symposium on Research in Computer Security, Darmstadt, Germany, October 4‚Äì8, 2021, Proceedings, Part I, Springer-Verlag,
Berlin, Heidelberg. p. 455‚Äì475. URL: https://doi.org/10.1007/978-3-030-88418-5_22, doi:10.1007/978-3-030-88418-5_
22.
[13] Azam, S.S., Pelikan, M., Feldman, V., Talwar, K., Silovsky, H., Likhomanenko, T., 2023. Federated learning for speech recognition: Revisiting
current trends towards large-scale asr, in: NeurIPS. URL: https://openreview.net/pdf?id=ozN92d7CHX.
Frederico Vicente et al.
Page 58 of 70
Modular Federated Learning: A Meta-Framework Perspective
[14] Badawi, A.A., Bates, J., Bergamaschi, F., Cousins, D.B., Erabelli, S., Genise, N., Halevi, S., Hunt, H., Kim, A., Lee, Y., Liu, Z., Micciancio,
D., Quah, I., Polyakov, Y., R.V., S., Rohloff, K., Saylor, J., Suponitsky, D., Triplett, M., Vaikuntanathan, V., Zucca, V., 2022. Openfhe: Open-
source fully homomorphic encryption library. Cryptology ePrint Archive, Paper 2022/915. URL: https://eprint.iacr.org/2022/915.
https://eprint.iacr.org/2022/915.
[15] Bagdasaryan, E., Poursaeed, O., Shmatikov, V., 2019. Differential privacy has disparate impact on model accuracy. Curran Associates Inc.,
Red Hook, NY, USA.
[16] Bai, L., Hu, H., Ye, Q., Li, H., Wang, L., Xu, J., 2024. Membership inference attacks and defenses in federated learning: A survey. ACM
Computing Surveys 57, 1‚Äì35.
[17] Barbiero, P., Ciravegna, G., Giannini, F., Li√≥, P., Gori, M., Melacci, S., 2022.
Entropy-based logic explanations of neural networks.
Proceedings of the AAAI Conference on Artificial Intelligence 36, 6046‚Äì6054.
URL: https://ojs.aaai.org/index.php/AAAI/
article/view/20551, doi:10.1609/aaai.v36i6.20551.
[18] Baruch, G., Baruch, M., Goldberg, Y., 2019.
A little is enough: Circumventing defenses for distributed learning 32.
URL: https:
//proceedings.neurips.cc/paper_files/paper/2019/file/ec1c59141046cd1866bbbcdfb6ae31d4-Paper.pdf.
[19] Bedi, A.S., Fan, C., Koppel, A., Sahu, A.K., Sadler, B.M., Huang, F., Manocha, D., 2022. Fedbc: Calibrating global and local models via
federated learning beyond consensus. arXiv preprint arXiv:2206.10815 .
[20] Behera, M.R., upadhyay, s., Shetty, S., Otter, R., 2021. Federated learning using peer-to-peer network for decentralized orchestration of
model weights URL: http://dx.doi.org/10.36227/techrxiv.14267468.v1, doi:10.36227/techrxiv.14267468.v1.
[21] Ben-Itzhak, Y., M√∂llering, H., Pinkas, B., Schneider, T., Suresh, A., Tkachenko, O., Vargaftik, S., Weinert, C., Yalame, H., Yanai, A., 2024.
Scionfl: Efficient and robust secure quantized aggregation, in: 2024 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML),
IEEE. pp. 490‚Äì511.
[22] Bertsekas, D.P., Tsitsiklis, J.N., 1997. Parallel and Distributed Computation: Numerical Methods. Athena Scientific.
[23] Beutel, D.J., Topal, T., Mathur, A., Qiu, X., Fernandez-Marques, J., Gao, Y., Sani, L., Li, K.H., Parcollet, T., de Gusm√£o, P.P.B., et al., 2020.
Flower: A friendly federated learning research framework. arXiv preprint arXiv:2007.14390 .
[24] Biewald, L., 2020. Experiment tracking with weights and biases. URL: https://www.wandb.com/. software available from wandb.com.
[25] Birrell, E., Rodolitz, J., Ding, A., Lee, J., McReynolds, E., Hutson, J., Lerner, A., 2024. Sok: Technical implementation and human impact
of internet privacy regulations, in: 2024 IEEE Symposium on Security and Privacy (SP), IEEE. pp. 673‚Äì696.
[26] Blanchard, P., El Mhamdi, E.M., Guerraoui, R., Stainer, J., 2017.
Machine learning with adversaries: Byzantine tolerant gradient
descent, in: Guyon, I., Luxburg, U.V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., Garnett, R. (Eds.), Advances in Neural
Information Processing Systems, Curran Associates, Inc.
URL: https://proceedings.neurips.cc/paper_files/paper/2017/
file/f4b9ec30ad9f68f89b29639786cb62ef-Paper.pdf.
[27] Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov, V., Kiddon, C., Koneƒçn√Ω, J., Mazzocchi, S., McMahan, B.,
Van Overveldt, T., Petrou, D., Ramage, D., Roselander, J., 2019. Towards federated learning at scale: System design, in: Talwalkar, A.,
Smith, V., Zaharia, M. (Eds.), Proceedings of Machine Learning and Systems, pp. 374‚Äì388. URL: https://proceedings.mlsys.org/
paper_files/paper/2019/file/7b770da633baf74895be22a8807f1a8f-Paper.pdf.
[28] Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H.B., Patel, S., Ramage, D., Segal, A., Seth, K., 2017.
Practical
secure aggregation for privacy-preserving machine learning, in: Proceedings of the 2017 ACM SIGSAC Conference on Computer and
Communications Security, Association for Computing Machinery, New York, NY, USA. p. 1175‚Äì1191. URL: https://doi.org/10.
1145/3133956.3133982, doi:10.1145/3133956.3133982.
[29] Bonawitz, K.A., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H.B., Patel, S., Ramage, D., Segal, A., Seth, K., 2016.
Practical
secure aggregation for federated learning on user-held data, in: NIPS Workshop on Private Multi-Party Machine Learning. URL: https:
//arxiv.org/abs/1611.04482.
[30] Borkar, V., Varaiya, P., 1982. Asymptotic agreement in distributed estimation. IEEE transactions on automatic control 27, 650‚Äì655.
[31] Boumghar, R., Riccardi, A., Guzm√°n Alvarez, C., Ameen, S., 2023. Orbit decentralized autonomous organization using blockchain-based
consensus mechanisms.
[32] Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., 2011. Distributed optimization and statistical learning via the alternating direction
method of multipliers. Foundations and Trends¬Æ in Machine Learning 3, 1‚Äì122. URL: http://dx.doi.org/10.1561/2200000016,
doi:10.1561/2200000016.
[33] Braungardt, A., 2023.
Fate, flower, pysyft & co. ‚Äî federated learning frameworks in python.
https://medium.com/elca-it/
flower-pysyft-co-federated-learning-frameworks-in-python-b1a8eda68b0d. Accessed: 2024-01-23.
[34] Cai, H., Gan, C., Massachusetts Institute of Technology, L.Z., Massachusetts Institute of Technology, S.H., 2020. Tinytl: reduce memory, not
parameters for efficient on-device learning, in: Proceedings of the 34th International Conference on Neural Information Processing Systems,
Curran Associates Inc., Red Hook, NY, USA.
[35] Caldas, S., Duddu, S.M.K., Wu, P., Li, T., Koneƒçn`y, J., McMahan, H.B., Smith, V., Talwalkar, A., 2018a. Leaf: A benchmark for federated
settings. arXiv preprint arXiv:1812.01097 .
[36] Caldas, S., Koneƒçny, J., McMahan, H.B., Talwalkar, A., 2018b. Expanding the reach of federated learning by reducing client resource
requirements. arXiv preprint arXiv:1812.07210 .
[37] Cao, L., Chen, H., Fan, X., Gama, J., Ong, Y.S., Kumar, V., 2023a. Bayesian federated learning: A survey. arXiv:2304.13267.
[38] Cao, L., Chen, H., Fan, X., Gama, J., Ong, Y.S., Kumar, V., 2023b. Bayesian federated learning: A survey. arXiv preprint arXiv:2304.13267
.
[39] Cassavia, N., Caviglione, L., Guarascio, M., Liguori, A., Zuppelli, M., 2023.
Learning autoencoder ensembles for detecting mal-
ware hidden communications in iot ecosystems.
Journal of Intelligent Information Systems URL: https://doi.org/10.1007/
s10844-023-00819-8, doi:10.1007/s10844-023-00819-8.
Frederico Vicente et al.
Page 59 of 70
Modular Federated Learning: A Meta-Framework Perspective
[40] Cattivelli, F.S., Lopes, C.G., Sayed, A.H., 2008. Diffusion recursive least-squares for distributed estimation over adaptive networks. IEEE
Transactions on Signal Processing 56, 1865‚Äì1877. doi:10.1109/TSP.2007.913164.
[41] Ceballos, I., Sharma, V., Mugica, E., Singh, A., Roman, A., Vepakomma, P., Raskar, R., 2020. Splitnn-driven vertical partitioning. arXiv
preprint arXiv:2008.04137 .
[42] Chai, Z., Ali, A., Zawad, S., Truex, S., Anwar, A., Baracaldo, N., Zhou, Y., Ludwig, H., Yan, F., Cheng, Y., 2020.
Tifl: A tier-based
federated learning system, in: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing,
Association for Computing Machinery, New York, NY, USA. p. 125‚Äì136.
URL: https://doi.org/10.1145/3369583.3392686,
doi:10.1145/3369583.3392686.
[43] Chakraborty, O., Boudguiga, A., 2024. A decentralized federated learning using reputation. Cryptology ePrint Archive .
[44] Chambolle, A., Ehrhardt, M.J., Richt√°rik, P., Sch√∂nlieb, C.B., 2018.
Stochastic primal-dual hybrid gradient algorithm with arbitrary
sampling and imaging applications. SIAM Journal on Optimization 28, 2783‚Äì2808. URL: https://doi.org/10.1137/17M1134834,
doi:10.1137/17M1134834, arXiv:https://doi.org/10.1137/17M1134834.
[45] Chambolle, A., Pock, T., 2011. A first-order primal-dual algorithm for convex problems with applications to imaging. Journal of mathematical
imaging and vision 40, 120‚Äì145.
[46] Chang, Y., Fang, C., Sun, W., 2021. A blockchain-based federated learning method for smart healthcare. Computational Intelligence and
Neuroscience 2021.
[47] Chen, A.I., Chen, A.I., Ozdaglar, A., Ozdaglar, A., 2012.
A fast distributed proximal-gradient method.
Allerton Conference on
Communication, Control, and Computing doi:10.1109/allerton.2012.6483273.
[48] Chen, H., Ye, Y., Xiao, M., Skoglund, M., 2023a. Asynchronous parallel incremental block-coordinate descent for decentralized machine
learning. IEEE Transactions on Big Data 9, 1252‚Äì1259. doi:10.1109/TBDATA.2022.3230335.
[49] Chen, J., Pan, X., Monga, R., Bengio, S., Jozefowicz, R., 2016. Revisiting distributed synchronous sgd. arXiv preprint arXiv:1604.00981 .
[50] Chen, Q., Wang, Z., Wang, H., Lin, X., 2023b. Feddual: Pair-wise gossip helps federated learning in large decentralized networks. IEEE
Transactions on Information Forensics and Security 18, 335‚Äì350. doi:10.1109/TIFS.2022.3222935.
[51] Chen, T., Kornblith, S., Norouzi, M., Hinton, G., 2020. A simple framework for contrastive learning of visual representations, in: III,
H.D., Singh, A. (Eds.), Proceedings of the 37th International Conference on Machine Learning, PMLR. pp. 1597‚Äì1607. URL: https:
//proceedings.mlr.press/v119/chen20j.html.
[52] Chen, Y., Su, L., Xu, J., 2017. Distributed statistical machine learning in adversarial settings: Byzantine gradient descent. Proc. ACM Meas.
Anal. Comput. Syst. 1. URL: https://doi.org/10.1145/3154503, doi:10.1145/3154503.
[53] Cheng, D., Ojeda, F.C., Prabhu, A., Liu, X., Zhu, A., Green, P.C., Ehsani, R., Chaudhari, P., Kumar, V., 2023. Treescope: An agricultural
robotics dataset for lidar-based mapping of trees in forests and orchards. arXiv preprint arXiv:2310.02162 .
[54] Cho, Y.J., Wang, J., Joshi, G., 2020. Client selection in federated learning: Convergence analysis and power-of-choice selection strategies.
arXiv preprint arXiv:2010.01243 .
[55] Collins, L., Hassani, H., Mokhtari, A., Shakkottai, S., 2021.
Exploiting shared representations for personalized federated learning, in:
Meila, M., Zhang, T. (Eds.), Proceedings of the 38th International Conference on Machine Learning, PMLR. pp. 2089‚Äì2099.
URL:
https://proceedings.mlr.press/v139/collins21a.html.
[56] Condat, L., Richt√°rik, P., 2023.
Randprox: Primal-dual optimization algorithms with randomized proximal updates, in: The Eleventh
International Conference on Learning Representations. URL: https://openreview.net/forum?id=cB4N3G5udUS.
[57] Control, M., 2022. Friends ‚Äì federated reconfigurable infrastructure via edge devices in space. https://nebula.esa.int/content/
beyond-mission-paradigm-federated-reconfigurable-infrastructure-edge-devices-space-friends. Accessed: 2024-
02-12.
[58] tiny corp, 2020. tinygrad. https://github.com/tinygrad/tinygrad.
[59] Corrigan-Gibbs, H., Boneh, D., 2017. Prio: Private, robust, and scalable computation of aggregate statistics, in: 14th USENIX Symposium
on Networked Systems Design and Implementation (NSDI 17), USENIX Association, Boston, MA. pp. 259‚Äì282. URL: https://www.
usenix.org/conference/nsdi17/technical-sessions/presentation/corrigan-gibbs.
[60] Cremonesi, F., Vesin, M., Cansiz, S., Bouillard, Y., Balelli, I., Innocenti, L., Silva, S., Ayed, S.S., Taiello, R., Kameni, L., et al., 2023.
Fed-biomed: open, transparent and trusted federated learning for real-world healthcare applications. arXiv preprint arXiv:2304.12012 .
[61] Darlow, L.N., Crowley, E.J., Antoniou, A., Storkey, A.J., 2018. Cinic-10 is not imagenet or cifar-10. arXiv:1810.03505.
[62] Das, R., Acharya, A., Hashemi, A., Sanghavi, S., Dhillon, I.S., Topcu, U., 2022. Faster non-convex federated learning via global and local
momentum, in: Uncertainty in Artificial Intelligence, PMLR. pp. 496‚Äì506.
[63] Defazio, A., Bach, F., Lacoste-Julien, S., 2014. Saga: A fast incremental gradient method with support for non-strongly convex composite
objectives. Advances in neural information processing systems 27.
[64] DeGroot, M.H., 1974. Reaching a consensus. Journal of the American Statistical Association 69, 118‚Äì121. URL: http://www.jstor.
org/stable/2285509.
[65] Dehghani, M., Yazdanparast, Z., 2023. From distributed machine to distributed deep learning: a comprehensive survey. Journal of Big Data
10, 158. URL: https://doi.org/10.1186/s40537-023-00829-x, doi:10.1186/s40537-023-00829-x.
[66] Deng, F., Mao, W., Zeng, Z., Zeng, H., Wei, B., 2022. Multiple diseases and pests detection based on federated learning and improved faster
r-cnn. IEEE Transactions on Instrumentation and Measurement 71, 1‚Äì11. doi:10.1109/TIM.2022.3201937.
[67] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., 2009. Imagenet: A large-scale hierarchical image database, in: 2009 IEEE
Conference on Computer Vision and Pattern Recognition, pp. 248‚Äì255. doi:10.1109/CVPR.2009.5206848.
[68] Desfontaines, D., 2021.
A friendly, non-technical introduction to differential privacy.
https://desfontain.es/privacy/
friendly-intro-to-differential-privacy.html. Ted is writing things (personal blog).
[69] Developer, N., 2024. Confidential computing on h100 gpus for secure and trustworthy ai. URL: https://developer.nvidia.com/
blog/confidential-computing-on-h100-gpus-for-secure-and-trustworthy-ai/. accessed: 2025-02-07.
Frederico Vicente et al.
Page 60 of 70
Modular Federated Learning: A Meta-Framework Perspective
[70] developers, O.R., 2021. Onnx runtime. https://onnxruntime.ai/. Version: x.y.z.
[71] Dhawan, N., Mitchell, N., Charles, Z., Garrett, Z., Dziugaite, G.K., 2023. Leveraging function space aggregation for federated learning at
scale. arXiv preprint arXiv:2311.10291 .
[72] Dorigo, M., Maniezzo, V., Colorni, A., 1996. Ant system: optimization by a colony of cooperating agents. IEEE Transactions on Systems,
Man, and Cybernetics, Part B (Cybernetics) 26, 29‚Äì41. doi:10.1109/3477.484436.
[73] Douillard, A., Feng, Q., Rusu, A.A., Kuncoro, A., Donchev, Y., Chhaparia, R., Gog, I., Ranzato, M., Shen, J., Szlam, A., 2024. Dipaco:
Distributed path composition.
[74] Dwork, C., Roth, A., 2014. The algorithmic foundations of differential privacy. Found. Trends Theor. Comput. Sci. 9, 211‚Äì407. URL:
https://doi.org/10.1561/0400000042, doi:10.1561/0400000042.
[75] Ekmefjord, M., Ait-Mlouk, A., Alawadi, S., √Ökesson, M., Stoyanova, D., Spjuth, O., Toor, S., Hellander, A., 2021. Scalable federated
machine learning with fedn. arXiv preprint arXiv:2103.00148 .
[76] El Hanjri, M., Kabbaj, H., Kobbane, A., Abouaomar, A., 2023. Federated learning for water consumption forecasting in smart cities, in: ICC
2023 - IEEE International Conference on Communications, pp. 1798‚Äì1803. doi:10.1109/ICC45041.2023.10279576.
[77] Ernstberger, J., Chaliasos, S., Zhou, L., Jovanovic, P., Gervais, A., 2024. Do you need a zero knowledge proof? Cryptology ePrint Archive .
[78] Fan, S., Rong, Y., Meng, C., Cao, Z., Wang, S., Zheng, Z., Wu, C., Long, G., Yang, J., Xia, L., Diao, L., Liu, X., Lin, W., 2021. Dapple: a
pipelined data parallel approach for training large models, in: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice
of Parallel Programming, Association for Computing Machinery, New York, NY, USA. p. 431‚Äì445. URL: https://doi.org/10.1145/
3437801.3441593, doi:10.1145/3437801.3441593.
[79] Fang, X., Ye, M., 2022. Robust federated learning with noisy and heterogeneous clients, in: 2022 IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 10062‚Äì10071. doi:10.1109/CVPR52688.2022.00983.
[80] Feldman, V., Zhang, C., 2020. What neural networks memorize and why: discovering the long tail via influence estimation, in: Proceedings
of the 34th International Conference on Neural Information Processing Systems, Curran Associates Inc., Red Hook, NY, USA.
[81] Feng, D., Helena, C., Lim, W.Y.B., Ng, J.S., Jiang, H., Xiong, Z., Kang, J., Yu, H., Niyato, D., Miao, C., 2022. Crowdfl: A marketplace
for crowdsourced federated learning. Proceedings of the AAAI Conference on Artificial Intelligence 36, 13164‚Äì13166. URL: https:
//ojs.aaai.org/index.php/AAAI/article/view/21715, doi:10.1609/aaai.v36i11.21715.
[82] Feng, T., Bose, D., Zhang, T., Hebbar, R., Ramakrishna, A., Gupta, R., Zhang, M., Avestimehr, S., Narayanan, S., 2023. Fedmultimodal: A
benchmark for multimodal federated learning, in: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data
Mining, pp. 4035‚Äì4045.
[83] Foley, P., Sheller, M.J., Edwards, B., Pati, S., Riviera, W., Sharma, M., Moorthy, P.N., Wang, S.h., Martin, J., Mirhaji, P., Shah, P., Bakas, S.,
2022. Openfl: the open federated learning library. Physics in Medicine & Biology URL: http://iopscience.iop.org/article/10.
1088/1361-6560/ac97d9, doi:10.1088/1361-6560/ac97d9.
[84] Fu, Y., Li, C., Yu, F.R., Luan, T.H., Zhang, Y., 2023. A selective federated reinforcement learning strategy for autonomous driving. IEEE
Transactions on Intelligent Transportation Systems 24, 1655‚Äì1668. doi:10.1109/TITS.2022.3219644.
[85] Galtier, M.N., Marini, C., 2019. Substra: a framework for privacy-preserving, traceable and collaborative machine learning. arXiv preprint
arXiv:1910.11567 .
[86] Gandhi, S., Iyer, A.P., 2021.
P3: Distributed deep graph learning at scale, in: 15th USENIX Symposium on Operating Systems
Design and Implementation (OSDI 21), USENIX Association. pp. 551‚Äì568. URL: https://www.usenix.org/conference/osdi21/
presentation/gandhi.
[87] Gao, Y., Al-Sarawi, S.F., Abbott, D., 2020. Physical unclonable functions. Nature Electronics 3, 81‚Äì91. URL: https://doi.org/10.
1038/s41928-020-0372-5, doi:10.1038/s41928-020-0372-5.
[88] Geiping, J., Bauermeister, H., Dr√∂ge, H., Moeller, M., 2020. Inverting gradients - how easy is it to break privacy in federated learning?, in:
Proceedings of the 34th International Conference on Neural Information Processing Systems, Curran Associates Inc., Red Hook, NY, USA.
[89] Ghodsi, Z., Javaheripi, M., Sheybani, N., Zhang, X., Huang, K., Koushanfar, F., 2023. zprobe: Zero peek robustness checks for federated
learning, in: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 4860‚Äì4870.
[90] Ghosh, A., Chung, J., Yin, D., Ramchandran, K., 2020.
An efficient framework for clustered federated learning. Advances in Neural
Information Processing Systems 33, 19586‚Äì19597.
[91] Glowinski, R., 2014. On Alternating Direction Methods of Multipliers: A Historical Perspective. Springer Netherlands, Dordrecht. pp.
59‚Äì82. URL: https://doi.org/10.1007/978-94-017-9054-3_4, doi:10.1007/978-94-017-9054-3_4.
[92] Goldreich, O., Micali, S., Wigderson, A., 2019. Proofs that yield nothing but their validity and a methodology of cryptographic protocol
design. Association for Computing Machinery, New York, NY, USA. p. 285‚Äì306. URL: https://doi.org/10.1145/3335741.3335754.
[93] Google, 2018. tensorflow-federated. https://github.com/google-parfait/tensorflow-federated.
[94] Google, 2019. differential-privacy. https://github.com/google/differential-privacy.
[95] Google, 2024. Litert. https://github.com/google-ai-edge/LiteRT.
[96] Granqvist, F., Song, C., √Åine Cahill, van Dalen, R., Pelikan, M., Chan, Y.S., Feng, X., Krishnaswami, N., Chitnis, M., Jina, V., 2024. pfl:
simulation framework for accelerating research in private federated learning. URL: https://github.com/apple/pfl-research.
[97] Guo, Y., Liu, F., Zhou, T., Cai, Z., Xiao, N., 2023. Seeing is believing: Towards interactive visual exploration of data privacy in federated
learning. Information Processing & Management 60, 103162. URL: https://www.sciencedirect.com/science/article/pii/
S0306457322002631, doi:https://doi.org/10.1016/j.ipm.2022.103162.
[98] Gupta, K., Fournarakis, M., Reisser, M., Louizos, C., Nagel, M., 2022. Quantization robust federated learning for efficient inference on
heterogeneous devices. arXiv preprint arXiv:2206.10844 .
[99] Gupta, O., Raskar, R., 2018. Distributed learning of deep neural network over multiple agents. Journal of Network and Computer Applications
116, 1‚Äì8.
Frederico Vicente et al.
Page 61 of 70
Modular Federated Learning: A Meta-Framework Perspective
[100] Hallaji, E., Razavi-Far, R., Saif, M., Wang, B., Yang, Q., 2024. Decentralized federated learning: A survey on security and privacy. IEEE
Transactions on Big Data .
[101] Han, B., Yao, Q., Yu, X., Niu, G., Xu, M., Hu, W., Tsang, I.W., Sugiyama, M., 2018. Co-teaching: robust training of deep neural networks with
extremely noisy labels, in: Proceedings of the 32nd International Conference on Neural Information Processing Systems, Curran Associates
Inc., Red Hook, NY, USA. p. 8536‚Äì8546.
[102] Han, S., Park, S., Wu, F., Kim, S., Wu, C., Xie, X., Cha, M., 2022. Fedx: Unsupervised federated learning with cross knowledge distillation,
in: Computer Vision ‚Äì ECCV 2022, Springer Nature Switzerland, Cham. pp. 691‚Äì707.
[103] Hanzely, F., Hanzely, S., Horv√°th, S., Richtarik, P., 2020. Lower bounds and optimal algorithms for personalized federated learning, in:
Advances in Neural Information Processing Systems, Curran Associates, Inc.. pp. 2304‚Äì2315. URL: https://proceedings.neurips.
cc/paper_files/paper/2020/file/187acf7982f3c169b3075132380986e4-Paper.pdf.
[104] Hard, A., Rao, K., Mathews, R., Ramaswamy, S., Beaufays, F., Augenstein, S., Eichner, H., Kiddon, C., Ramage, D., 2018. Federated learning
for mobile keyboard prediction. arXiv preprint arXiv:1811.03604 .
[105] He, C., Annavaram, M., Avestimehr, S., 2020a. Towards non-iid and invisible data with fednas: Federated deep learning via neural architecture
search. arXiv preprint arXiv:2004.08546 .
[106] He, C., Balasubramanian, K., Ceyani, E., Yang, C., Xie, H., et al., 2021. Fedgraphnn: A federated learning system and benchmark for graph
neural networks. arXiv preprint arXiv:2104.07145 .
[107] He, C., Li, S., So, J., Zeng, X., Zhang, M., et al., 2020b. Fedml: A research library and benchmark for federated machine learning. arXiv
preprint arXiv:2007.13518 .
[108] Heged≈±s, I., Danner, G., Jelasity, M., 2019. Gossip learning as a decentralized alternative to federated learning, in: Pereira, J., Ricci, L.
(Eds.), Distributed Applications and Interoperable Systems, Springer International Publishing, Cham. pp. 74‚Äì90.
[109] Hendrikx, H., 2023. A principled framework for the design and analysis of token algorithms, in: Ruiz, F., Dy, J., van de Meent, J.W.
(Eds.), Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, PMLR. pp. 470‚Äì489. URL: https:
//proceedings.mlr.press/v206/hendrikx23a.html.
[110] Hong, M., Razaviyayn, M., Lee, J., 2018. Gradient primal-dual algorithm converges to second-order stationary solution for nonconvex
distributed optimization over networks, in: International Conference on Machine Learning, PMLR. pp. 2009‚Äì2018.
[111] Hsu, H., Qi, H., Brown, M., 2019.
Measuring the effects of non-identical data distribution for federated visual classification.
URL:
https://arxiv.org/abs/1909.06335.
[112] Hu, X., Li, S., Liu, Y., 2023. Generalization bounds for federated learning: Fast rates, unparticipating clients and unbounded losses, in: The
Eleventh International Conference on Learning Representations.
[113] Huang, H., Zhang, L., Sun, C., Fang, R., Yuan, X., Wu, D., 2022. Fedtiny: Pruned federated learning towards specialized tiny models .
[114] Huang, Y., Cheng, Y., Bapna, A., Firat, O., Chen, D., Chen, M., Lee, H., Ngiam, J., Le, Q.V., Wu, Y., Chen, z., 2019. Gpipe: Efficient training
of giant neural networks using pipeline parallelism, in: Wallach, H., Larochelle, H., Beygelzimer, A., d'Alch√©-Buc, F., Fox, E., Garnett, R.
(Eds.), Advances in Neural Information Processing Systems, Curran Associates, Inc. URL: https://proceedings.neurips.cc/paper_
files/paper/2019/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf.
[115] Huba, D., Nguyen, J., Malik, K., Zhu, R., Rabbat, M., Yousefpour, A., et al., 2022.
Papaya: Practical, private, and scalable federated
learning, in: Marculescu, D., Chi, Y., Wu, C. (Eds.), Proceedings of Machine Learning and Systems, pp. 814‚Äì832.
URL: https:
//proceedings.mlsys.org/paper_files/paper/2022/file/a8bc4cb14a20f20d1f96188bd61eec87-Paper.pdf.
[116] Hymel, S., Banbury, C., Situnayake, D., Elium, A., Ward, C., Kelcey, M., Baaijens, M., Majchrzycki, M., Plunkett, J., Tischler, D., et al.,
2022. Edge impulse: An mlops platform for tiny machine learning. arXiv preprint arXiv:2212.03332 .
[117] Ilharco, G., Ribeiro, M.T., Wortsman, M., Gururangan, S., Schmidt, L., Hajishirzi, H., Farhadi, A., 2022. Editing models with task arithmetic.
arXiv preprint arXiv:2212.04089 .
[118] Jadbabaie, A., Lin, J., Morse, A.S., 2003.
Coordination of groups of mobile autonomous agents using nearest neighbor rules.
IEEE
Transactions on automatic control 48, 988‚Äì1001.
[119] Jakovetiƒá, D., Xavier, J., Moura, J.M., 2014. Fast distributed gradient methods. IEEE Transactions on Automatic Control 59, 1131‚Äì1146.
[120] Jeong, E., Oh, S., Kim, H., Park, J., Bennis, M., Kim, S.L., 2018. Communication-efficient on-device machine learning: Federated distillation
and augmentation under non-iid private data. arXiv preprint arXiv:1811.11479 .
[121] Ji, S., Pan, S., Long, G., Li, X., Jiang, J., Huang, Z., 2019. Learning private neural language modeling with attentive aggregation, in: 2019
International joint conference on neural networks (IJCNN), IEEE. pp. 1‚Äì8.
[122] Jiang, J., Ji, S., Long, G., 2020. Decentralized knowledge acquisition for mobile internet applications. World Wide Web 23, 2653‚Äì2669.
[123] Johansson, B., Rabi, M., Johansson, M., 2010. A randomized incremental subgradient method for distributed optimization in networked
systems. SIAM Journal on Optimization 20, 1157‚Äì1170. URL: https://doi.org/10.1137/08073038X, doi:10.1137/08073038X,
arXiv:https://doi.org/10.1137/08073038X.
[124] Johnson, R., Zhang, T., 2013. Accelerating stochastic gradient descent using predictive variance reduction. Advances in neural information
processing systems 26.
[125] Jothimurugesan, E., Hsieh, K., Wang, J., Joshi, G., Gibbons, P.B., 2023. Federated learning under distributed concept drift, in: Ruiz, F., Dy, J.,
van de Meent, J.W. (Eds.), Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, PMLR. pp. 5834‚Äì5853.
URL: https://proceedings.mlr.press/v206/jothimurugesan23a.html.
[126] Kairouz, P., McMahan, H.B., Avent, B., Bellet, A., Bennis, M., et al., 2021. Advances and open problems in federated learning. Foundations
and Trends¬Æ in Machine Learning 14, 1‚Äì210. URL: http://dx.doi.org/10.1561/2200000083, doi:10.1561/2200000083.
[127] Kalra, S., Wen, J., Cresswell, J.C., Volkovs, M., Tizhoosh, H.R., 2023. Decentralized federated learning through proxy model sharing. Nature
Communications 14, 2899. URL: https://doi.org/10.1038/s41467-023-38569-4, doi:10.1038/s41467-023-38569-4.
[128] Kan, A.K., 2022. Federated hypergradient descent. arXiv preprint arXiv:2211.02106 .
Frederico Vicente et al.
Page 62 of 70
Modular Federated Learning: A Meta-Framework Perspective
[129] Karargyris, A., Umeton, R., Sheller, M.J., Aristizabal, A., George et al, J., 2023. Federated benchmarking of medical artificial intelligence
with medperf. Nature Machine Intelligence 5, 799‚Äì810. URL: https://doi.org/10.1038/s42256-023-00652-2, doi:10.1038/
s42256-023-00652-2.
[130] Karimireddy, S.P., Kale, S., Mohri, M., Reddi, S., Stich, S., Suresh, A.T., 2020. SCAFFOLD: Stochastic controlled averaging for federated
learning, in: III, H.D., Singh, A. (Eds.), Proceedings of the 37th International Conference on Machine Learning, PMLR. pp. 5132‚Äì5143.
URL: https://proceedings.mlr.press/v119/karimireddy20a.html.
[131] Kempe, D., Dobra, A., Gehrke, J., 2003.
Gossip-based computation of aggregate information, in: 44th Annual IEEE Symposium on
Foundations of Computer Science, 2003. Proceedings., IEEE. pp. 482‚Äì491.
[132] Khan, T., Nguyen, K., Michalas, A., 2023. Split ways: Privacy-preserving training of encrypted data using split learning. arXiv preprint
arXiv:2301.08778 .
[133] Kim, C., Lee, H., Jeong, M., Baek, W., Yoon, B., Kim, I., Lim, S., Kim, S., 2020. torchgpipe: On-the-fly pipeline parallelism for training
giant models. arXiv preprint arXiv:2004.09910 .
[134] Kim, J., Park, Y., Kim, G., Hwang, S.J., 2017. SplitNet: Learning to semantically split deep networks for parameter reduction and model
parallelization, in: Precup, D., Teh, Y.W. (Eds.), Proceedings of the 34th International Conference on Machine Learning, PMLR. pp. 1866‚Äì
1874. URL: https://proceedings.mlr.press/v70/kim17b.html.
[135] Kim, S., Shin, W., Jang, S., Song, H., Yun, S.Y., 2022.
Fedrn: Exploiting k-reliable neighbors towards robust federated learning, in:
Proceedings of the 31st ACM International Conference on Information & Knowledge Management, Association for Computing Machinery,
New York, NY, USA. p. 972‚Äì981. URL: https://doi.org/10.1145/3511808.3557322, doi:10.1145/3511808.3557322.
[136] Komodakis, N., Paragios, N., Tziritas, G., 2010. Mrf energy minimization and beyond via dual decomposition. IEEE transactions on pattern
analysis and machine intelligence 33, 531‚Äì552.
[137] Koneƒçn`y, J., McMahan, H.B., Ramage, D., Richt√°rik, P., 2016.
Federated optimization: Distributed machine learning for on-device
intelligence. arXiv preprint arXiv:1610.02527 .
[138] Kourtellis, N., Katevas, K., Perino, D., 2020. Flaas: Federated learning as a service, in: Proceedings of the 1st Workshop on Distributed
Machine Learning, Association for Computing Machinery, New York, NY, USA. p. 7‚Äì13. URL: https://doi.org/10.1145/3426745.
3431337, doi:10.1145/3426745.3431337.
[139] Krizhevsky, A., Hinton, G., et al., 2009. Learning multiple layers of features from tiny images, Toronto, ON, Canada.
[140] Kumar, P., Gupta, G.P., Tripathi, R., 2022. Pefl: Deep privacy-encoding-based federated learning framework for smart agriculture. IEEE
Micro 42, 33‚Äì40. doi:10.1109/MM.2021.3112476.
[141] Kwon, Y.D., Li, R., Venieris, S.I., Chauhan, J., Lane, N.D., Mascolo, C., 2023. Tinytrain: Deep neural network training at the extreme edge.
arXiv preprint arXiv:2307.09988 .
[142] Lamport, L., 1998. The part-time parliament. ACM Trans. Comput. Syst. 16, 133‚Äì169. URL: https://doi.org/10.1145/279227.
279229, doi:10.1145/279227.279229.
[143] Laridi, S., Palmer, G., Tam, K.M.M., 2024. Enhanced federated anomaly detection through autoencoders using summary statistics-based
thresholding. Scientific Reports 14, 26704.
[144] Lee, S., Choi, D.H., 2022.
Federated reinforcement learning for energy management of multiple smart homes with distributed energy
resources. IEEE Transactions on Industrial Informatics 18, 488‚Äì497. doi:10.1109/TII.2020.3035451.
[145] Li, A., Liu, R., Hu, M., Tuan, L.A., Yu, H., 2023a. Towards interpretable federated learning. arXiv:2302.13473.
[146] Li, D., Wang, J., 2019. Fedmd: Heterogenous federated learning via model distillation. arXiv preprint arXiv:1910.03581 .
[147] Li, H., Lin, H., Polychroniadou, A., Tessaro, S., 2023b.
Lerna: Secure single-server aggregation via key-homomorphic masking, in:
Advances in Cryptology ‚Äì ASIACRYPT 2023: 29th International Conference on the Theory and Application of Cryptology and Information
Security, Guangzhou, China, December 4‚Äì8, 2023, Proceedings, Part I, Springer-Verlag, Berlin, Heidelberg. p. 302‚Äì334. URL: https:
//doi.org/10.1007/978-981-99-8721-4_10, doi:10.1007/978-981-99-8721-4_10.
[148] Li, J., Chen, Z., Chong, K.F.E., Das, B., Quek, T.Q., Yang, H.H., 2024a. Robust federated learning over the air: Combating heavy-tailed
noise with median anchored clipping. arXiv preprint arXiv:2409.15100 .
[149] Li, M., Zhou, L., Yang, Z., Li, A., Xia, F., Andersen, D.G., Smola, A., 2013. Parameter server for distributed machine learning, in: Big
learning NIPS workshop, Lake Tahoe, CA.
[150] Li, Q., Wu, Z., Cai, Y., Han, Y., Yung, C.M., Fu, T., He, B., 2023c. Fedtree: A federated learning system for trees, in: Proceedings of Machine
Learning and Systems.
[151] Li, T., Sahu, A.K., Zaheer, M., Sanjabi, M., Talwalkar, A., Smith, V., 2020. Federated optimization in heterogeneous networks, in: Dhillon,
I., Papailiopoulos, D., Sze, V. (Eds.), Proceedings of Machine Learning and Systems, pp. 429‚Äì450. URL: https://proceedings.mlsys.
org/paper_files/paper/2020/file/1f5fe83998a09396ebe6477d9475ba0c-Paper.pdf.
[152] Li, X., Song, Z., Tao, R., Zhang, G., 2022a. A convergence theory for federated average: Beyond smoothness, in: 2022 IEEE International
Conference on Big Data (Big Data), IEEE. pp. 1292‚Äì1297.
[153] Li, X., Song, Z., Yang, J., 2023d. Federated adversarial learning: A framework with convergence analysis, in: International Conference on
Machine Learning, PMLR. pp. 19932‚Äì19959.
[154] Li, Y., He, S., Li, Y., Shi, Y., Zeng, Z., 2024b. Federated multiagent deep reinforcement learning approach via physics-informed reward for
multimicrogrid energy management. IEEE Transactions on Neural Networks and Learning Systems 35, 5902‚Äì5914. doi:10.1109/TNNLS.
2022.3232630.
[155] Li, Z., He, Y., Yu, H., Kang, J., Li, X., Xu, Z., Niyato, D., 2022b. Data heterogeneity-robust federated learning via group client selection in
industrial iot. IEEE Internet of Things Journal 9, 17844‚Äì17857. doi:10.1109/JIOT.2022.3161943.
[156] Li, Z., Liu, L., Zhang, J., Liu, J., 2021. Byzantine-robust federated learning through spatial-temporal analysis of local model updates ,
372‚Äì379doi:10.1109/ICPADS53394.2021.00052.
Frederico Vicente et al.
Page 63 of 70
Modular Federated Learning: A Meta-Framework Perspective
[157] Liang, S., Huang, J., Zeng, D., Hong, J., Zhou, J., Xu, Z., 2023a. Fednoisy: Federated noisy label learning benchmark. arXiv preprint
arXiv:2306.11650 .
[158] Liang, X., Liu, Y., Chen, T., Liu, M., Yang, Q., 2023b.
Federated Transfer Reinforcement Learning for Autonomous Driving.
Springer International Publishing, Cham. pp. 357‚Äì371. URL: https://doi.org/10.1007/978-3-031-11748-0_15, doi:10.1007/
978-3-031-11748-0_15.
[159] Lin, J., Chen, W.M., Lin, Y., cohn, j., Gan, C., Han, S., 2020.
Mcunet: Tiny deep learning on iot devices 33, 11711‚Äì11722.
URL:
https://proceedings.neurips.cc/paper_files/paper/2020/file/86c51678350f656dcc7f490a43946ee5-Paper.pdf.
[160] Lin, J., Zhu, L., Chen, W.M., Wang, W.C., Gan, C., Han, S., 2022.
On-device training under 256kb memory, in: Advances in Neural
Information Processing Systems, Curran Associates, Inc.. pp. 22941‚Äì22954. URL: https://proceedings.neurips.cc/paper_files/
paper/2022/file/90c56c77c6df45fc8e556a096b7a2b2e-Paper-Conference.pdf.
[161] Liu, B., Lv, N., Guo, Y., Li, Y., 2023. Recent advances on federated learning: A systematic survey. arXiv:2301.01299.
[162] Liu, J., Chen, C., Li, Y., Sun, L., Song, Y., Zhou, J., Jing, B., Dou, D., 2024a. Enhancing trust and privacy in distributed networks: a
comprehensive survey on blockchain-based federated learning. Knowledge and Information Systems , 1‚Äì27.
[163] Liu, J., Chu, M., Reich, J.E., 2007. Multitarget tracking in distributed sensor networks. IEEE Signal Processing Magazine 24, 36‚Äì46.
doi:10.1109/MSP.2007.361600.
[164] Liu, L., Jiang, X., Zheng, F., Chen, H., Qi, G.J., Huang, H., Shao, L., 2024b. A bayesian federated learning framework with online laplace
approximation. IEEE Transactions on Pattern Analysis and Machine Intelligence 46, 1‚Äì16. doi:10.1109/TPAMI.2023.3322743.
[165] Liu, X., Li, H., Xu, G., Chen, Z., Huang, X., Lu, R., 2021a. Privacy-enhanced federated learning against poisoning adversaries. IEEE
Transactions on Information Forensics and Security 16, 4574‚Äì4588. doi:10.1109/TIFS.2021.3108434.
[166] Liu, Y., Fan, T., Chen, T., Xu, Q., Yang, Q., 2021b. Fate: An industrial grade platform for collaborative learning with data protection. Journal
of Machine Learning Research 22, 1‚Äì6. URL: http://jmlr.org/papers/v22/20-815.html.
[167] Liu, Y., Zhang, X., Kang, Y., Li, L., Chen, T., Hong, M., Yang, Q., 2022. Fedbcd: A communication-efficient collaborative learning framework
for distributed features. IEEE Transactions on Signal Processing 70, 4277‚Äì4290. doi:10.1109/TSP.2022.3198176.
[168] Lu, N., Wang, Z., Li, X., Niu, G., Dou, Q., Sugiyama, M., 2022. Federated learning from only unlabeled data with class-conditional-sharing
clients. arXiv preprint arXiv:2204.03304 .
[169] Ludwig, H., Baracaldo, N., Thomas, G., Zhou, Y., Anwar, A., Rajamoni, S., Ong, Y., Radhakrishnan, J., Verma, A., Sinn, M., et al., 2020.
Ibm federated learning: an enterprise framework white paper v0. 1. arXiv preprint arXiv:2007.10987 .
[170] Lyu, L., Yu, H., Ma, X., Chen, C., Sun, L., Zhao, J., Yang, Q., Yu, P.S., 2022. Privacy and robustness in federated learning: Attacks and
defenses. IEEE transactions on neural networks and learning systems 35, 8726‚Äì8746.
[171] Ma, J., Xixiang, L., Yu, Y., Sigg, S., 2023. Ppsfl: Privacy-preserving split federated learning via functional encryption. Authorea Preprints .
[172] Ma, R., Hwang, K., Li, M., Miao, Y., 2024. Trusted model aggregation with zero-knowledge proofs in federated learning. IEEE Transactions
on Parallel and Distributed Systems .
[173] Ma, X., Wang, Y., Houle, M.E., Zhou, S., Erfani, S., Xia, S., Wijewickrema, S., Bailey, J., 2018. Dimensionality-driven learning with noisy
labels, in: Dy, J., Krause, A. (Eds.), Proceedings of the 35th International Conference on Machine Learning, PMLR. pp. 3355‚Äì3364. URL:
https://proceedings.mlr.press/v80/ma18d.html.
[174] Ma, X., Yan, M., 2024. Research progress on security and privacy of federated learning: A survey. Wireless Personal Communications 136,
2201‚Äì2242.
[175] Ma, Z., Ma, J., Miao, Y., Li, Y., Deng, R.H., 2022. Shieldfl: Mitigating model poisoning attacks in privacy-preserving federated learning.
IEEE Transactions on Information Forensics and Security 17, 1639‚Äì1654. doi:10.1109/TIFS.2022.3169918.
[176] Marfoq, O., Neglia, G., Vidal, R., Kameni, L., 2022. Personalized federated learning through local memorization, in: Chaudhuri, K., Jegelka,
S., Song, L., Szepesvari, C., Niu, G., Sabato, S. (Eds.), Proceedings of the 39th International Conference on Machine Learning, PMLR. pp.
15070‚Äì15092. URL: https://proceedings.mlr.press/v162/marfoq22a.html.
[177] McMahan, B., Moore, E., Ramage, D., Hampson, S., Arcas, B.A.y., 2017.
Communication-efficient learning of deep networks from
decentralized data, in: Singh, A., Zhu, J. (Eds.), Proceedings of the 20th International Conference on Artificial Intelligence and Statistics,
PMLR. pp. 1273‚Äì1282. URL: https://proceedings.mlr.press/v54/mcmahan17a.html.
[178] McMillan, A., Javidbakht, O., Talwar, K., Briggs, E., Chatzidakis, M., Chen, J., Duchi, J., Feldman, V., Goren, Y., Hesse, M., et al., 2022.
Private federated statistics in an interactive setting. arXiv preprint arXiv:2211.10082 .
[179] Mirsky, Y., Doitshman, T., Elovici, Y., Shabtai, A., 2018. Kitsune: an ensemble of autoencoders for online network intrusion detection. arXiv
preprint arXiv:1802.09089 .
[180] Mitra, A., Hassani, H., Pappas, G.J., 2021. Online federated learning, in: 2021 60th IEEE Conference on Decision and Control (CDC), pp.
4083‚Äì4090. doi:10.1109/CDC45484.2021.9683589.
[181] Mittone, G., Riviera, W., Colonnelli, I., Birke, R., Aldinucci, M., 2023. Model-agnostic federated learning, in: Euro-Par 2023: Parallel
Processing, Springer Nature Switzerland, Cham. pp. 383‚Äì396.
[182] Mo, F., Haddadi, H., Katevas, K., Marin, E., Perino, D., Kourtellis, N., 2021. Ppfl: privacy-preserving federated learning with trusted
execution environments, in: Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services,
Association for Computing Machinery, New York, NY, USA. p. 94‚Äì108.
URL: https://doi.org/10.1145/3458864.3466628,
doi:10.1145/3458864.3466628.
[183] Mo, F., Tarkhani, Z., Haddadi, H., 2024. Machine learning with confidential computing: A systematization of knowledge. ACM Comput.
Surv. URL: https://doi.org/10.1145/3670007, doi:10.1145/3670007. just Accepted.
[184] Morris, J., Kuleshov, V., Shmatikov, V., Rush, A., 2023.
Text embeddings reveal (almost) as much as text, in: Bouamor, H., Pino, J.,
Bali, K. (Eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, Association for Computational
Linguistics, Singapore. pp. 12448‚Äì12460.
URL: https://aclanthology.org/2023.emnlp-main.765, doi:10.18653/v1/2023.
emnlp-main.765.
Frederico Vicente et al.
Page 64 of 70
Modular Federated Learning: A Meta-Framework Perspective
[185] Moustafa, N., 2021. A new distributed architecture for evaluating ai-based security systems at the edge: Network ton_iot datasets 72.
[186] Mucs√°nyi, B., Kirchhof, M., Nguyen, E., Rubinstein, A., Oh, S.J., 2023a. Trustworthy machine learning. arXiv preprint arXiv:2310.08215 .
[187] Mucs√°nyi, B., Kirchhof, M., Nguyen, E., Rubinstein, A., Oh, S.J., 2023b. Trustworthy machine learning. arXiv preprint arXiv:2310.08215 .
[188] Narayanan, D., Harlap, A., Phanishayee, A., Seshadri, V., Devanur, N.R., Ganger, G.R., Gibbons, P.B., Zaharia, M., 2019. Pipedream:
generalized pipeline parallelism for dnn training, in: Proceedings of the 27th ACM Symposium on Operating Systems Principles, Association
for Computing Machinery, New York, NY, USA. p. 1‚Äì15.
URL: https://doi.org/10.1145/3341301.3359646, doi:10.1145/
3341301.3359646.
[189] Nedic, A., Ozdaglar, A., 2009. Distributed subgradient methods for multi-agent optimization. IEEE Transactions on Automatic Control 54,
48‚Äì61. doi:10.1109/TAC.2008.2009515.
[190] Nediƒá, A., Liu, J., 2018. Distributed optimization for control. Annual Review of Control, Robotics, and Autonomous Systems 1, 77‚Äì
103.
URL: https://www.annualreviews.org/content/journals/10.1146/annurev-control-060117-105131, doi:https:
//doi.org/10.1146/annurev-control-060117-105131.
[191] Nguyen, D.C., Ding, M., Pathirana, P.N., Seneviratne, A., Li, J., Poor, H.V., 2021. Federated learning for internet of things: A comprehensive
survey. IEEE Communications Surveys & Tutorials 23, 1622‚Äì1658.
[192] Nguyen, J., Malik, K., Zhan, H., Yousefpour, A., Rabbat, M., Malek, M., Huba, D., 2022. Federated learning with buffered asynchronous
aggregation, in: Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, PMLR. pp. 3581‚Äì3607. URL:
https://proceedings.mlr.press/v151/nguyen22b.html.
[193] Nguyen, T., Mdhaffar, S., Tomashenko, N., Bonastre, J.F., Est√®ve, Y., 2023.
Federated learning for asr based on wav2vec 2.0.
arXiv:2302.10790.
[194] Nguyen, T.D., Nguyen, T., Le Nguyen, P., Pham, H.H., Doan, K.D., Wong, K.S., 2024. Backdoor attacks and defenses in federated learning:
Survey, challenges and future research directions. Engineering Applications of Artificial Intelligence 127, 107166.
[195] Ni, J., Muhlstein, L., McAuley, J., 2019. Modeling heart rate and activity data for personalized fitness recommendation, in: The World
Wide Web Conference, Association for Computing Machinery, New York, NY, USA. p. 1343‚Äì1353. URL: https://doi.org/10.1145/
3308558.3313643, doi:10.1145/3308558.3313643.
[196] Niknam, S., Dhillon, H.S., Reed, J.H., 2020. Federated learning for wireless communications: Motivation, opportunities, and challenges.
IEEE Communications Magazine 58, 46‚Äì51. doi:10.1109/MCOM.001.1900461.
[197] Oh, J., Kim, S., Yun, S.Y., 2021.
Fedbabu: Towards enhanced representation for federated image classification.
arXiv preprint
arXiv:2106.06042 .
[198] Ongaro, D., Ousterhout, J., 2014. In search of an understandable consensus algorithm, in: Proceedings of the 2014 USENIX Conference on
USENIX Annual Technical Conference, USENIX Association, USA. p. 305‚Äì320.
[199] P2PFL, 2022. p2pfl. https://github.com/pguijas/p2pfl.
[200] PaddlePaddle, 2019. Paddlefl. https://github.com/PaddlePaddle/PaddleFL.
[201] PAGE, E.S., 1954. "continuous inspection schemes". Biometrika 41, 100‚Äì115. URL: https://doi.org/10.1093/biomet/41.1-2.100,
doi:10.1093/biomet/41.1-2.100, arXiv:https://academic.oup.com/biomet/article-pdf/41/1-2/100/1243987/41-1-2-100.pdf.
[202] Panayotov, V., Chen, G., Povey, D., Khudanpur, S., 2015. Librispeech: An asr corpus based on public domain audio books, in: 2015 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5206‚Äì5210. doi:10.1109/ICASSP.2015.7178964.
[203] Park, S., Suh, Y., Lee, J., 2021. Fedpso: Federated learning using particle swarm optimization to reduce communication costs. Sensors 21,
600.
[204] Park, W., Kim, D., Lu, Y., Cho, M., 2019. Relational knowledge distillation, in: Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR).
[205] Pathak, R., Wainwright, M.J., 2020. Fedsplit: An algorithmic framework for fast federated optimization. Advances in neural information
processing systems 33, 7057‚Äì7066.
[206] Pfeiffer, J., Ruder, S., Vuliƒá, I., Ponti, E.M., 2023. Modular deep learning. arXiv preprint arXiv:2302.11529 .
[207] Pinto Neto, E.C., Sadeghi, S., Zhang, X., Dadkhah, S., 2023. Federated reinforcement learning in iot: Applications, opportunities and open
challenges. Applied Sciences 13. URL: https://www.mdpi.com/2076-3417/13/11/6497, doi:10.3390/app13116497.
[208] Pourahmadi, V., Alameddine, H.A., Salahuddin, M.A., Boutaba, R., 2022. Spotting anomalies at the edge: Outlier exposure-based cross-silo
federated learning for ddos detection. IEEE Transactions on Dependable and Secure Computing 20, 4002‚Äì4015.
[209] Prasad, K., Ghosh, S., Cormode, G., Mironov, I., Yousefpour, A., Stock, P., 2022. Reconciling security and communication efficiency in
federated learning. arXiv preprint arXiv:2207.12779 .
[210] Prasad, V.K., Bhattacharya, P., Maru, D., Tanwar, S., Verma, A., Singh, A., Tiwari, A.K., Sharma, R., Alkhayyat, A., T, urcanu, F.E., Raboaca,
M.S., 2023. Federated learning for the internet-of-medical-things: A survey. Mathematics 11. URL: https://www.mdpi.com/2227-7390/
11/1/151, doi:10.3390/math11010151.
[211] Qi, J., Zhou, Q., Lei, L., Zheng, K., 2021. Federated reinforcement learning: Techniques, applications, and open challenges. arXiv preprint
arXiv:2108.11887 .
[212] Qi, P., Chiaro, D., Guzzo, A., Ianni, M., Fortino, G., Piccialli, F., 2024. Model aggregation techniques in federated learning: A comprehensive
survey. Future Generation Computer Systems 150, 272‚Äì293.
[213] Qu, G., Cui, N., Wu, H., Li, R., Ding, Y., 2022. Chainfl: A simulation platform for joint federated learning and blockchain in edge/cloud
computing environments. IEEE Transactions on Industrial Informatics 18, 3572‚Äì3581. doi:10.1109/TII.2021.3117481.
[214] Rafi, T.H., Noor, F.A., Hussain, T., Chae, D.K., 2024. Fairness and privacy preserving in federated learning: A survey. Information Fusion
105, 102198.
[215] Rahulamathavan, Y., Herath, C., Liu, X., Lambotharan, S., Maple, C., 2023. Fhefl: Fully homomorphic encryption friendly privacy-preserving
federated learning with byzantine users. arXiv preprint arXiv:2306.05112 .
Frederico Vicente et al.
Page 65 of 70
Modular Federated Learning: A Meta-Framework Perspective
[216] Ram,
S.S.,
Nediƒá,
A.,
Veeravalli,
V.V.,
2009.
Incremental
stochastic
subgradient
algorithms
for
convex
optimization.
SIAM
Journal
on
Optimization
20,
691‚Äì717.
URL:
https://doi.org/10.1137/080726380,
doi:10.1137/080726380,
arXiv:https://doi.org/10.1137/080726380.
[217] Rathee, M., Shen, C., Wagh, S., Popa, R.A., 2023. Elsa: Secure aggregation for federated learning with malicious actors, in: 2023 IEEE
Symposium on Security and Privacy (SP), pp. 1961‚Äì1979. doi:10.1109/SP46215.2023.10179468.
[218] Reddi, V.J., 2024. Machine learning systems with tinyml. https://harvard-edge.github.io/cs249r_book/. Accessed: 2024-01-24.
[219] Riad, K., Huang, T., Ke, L., 2020. A dynamic and hierarchical access control for iot in multi-authority cloud storage. Journal of Network
and Computer Applications 160, 102633. URL: https://www.sciencedirect.com/science/article/pii/S1084804520301077,
doi:https://doi.org/10.1016/j.jnca.2020.102633.
[220] Rizk, E., Vlaski, S., Sayed, A.H., 2020. Dynamic federated learning, in: 2020 IEEE 21st International Workshop on Signal Processing
Advances in Wireless Communications (SPAWC), pp. 1‚Äì5. doi:10.1109/SPAWC48557.2020.9154327.
[221] Ro, J.H., Suresh, A.T., Wu, K., 2021. Fedjax: Federated learning simulation with jax. arXiv preprint arXiv:2108.02117 .
[222] Romanini, D., Hall, A.J., Papadopoulos, P., Titcombe, T., Ismail, A., Cebere, T., Sandmann, R., Roehm, R., Hoeh, M.A., 2021. Pyvertical:
A vertical federated learning framework for multi-headed splitnn. arXiv preprint arXiv:2104.00489 .
[223] van Rooyen, B., Menon, A., Williamson, R.C., 2015. Learning with symmetric label noise: The importance of being unhinged, in: Cortes, C.,
Lawrence, N., Lee, D., Sugiyama, M., Garnett, R. (Eds.), Advances in Neural Information Processing Systems, Curran Associates, Inc. URL:
https://proceedings.neurips.cc/paper_files/paper/2015/file/45c48cce2e2d7fbdea1afc51c7c6ad26-Paper.pdf.
[224] Roth, H.R., Cheng, Y., Wen, Y., Yang, I., Xu, Z., Hsieh, Y.T., Kersten, K., Harouni, A., Zhao, C., Lu, K., et al., 2022. Nvidia flare: Federated
learning from simulation to real-world. arXiv preprint arXiv:2210.13291 .
[225] Roy, A.G., Siddiqui, S., P√∂lsterl, S., Navab, N., Wachinger, C., 2019. Braintorrent: A peer-to-peer environment for decentralized federated
learning. arXiv preprint arXiv:1905.06731 .
[226] Roy Chowdhury, A., Guo, C., Jha, S., van der Maaten, L., 2022. Eiffel: Ensuring integrity for federated learning, in: Proceedings of the 2022
ACM SIGSAC Conference on Computer and Communications Security, Association for Computing Machinery, New York, NY, USA. p.
2535‚Äì2549. URL: https://doi.org/10.1145/3548606.3560611, doi:10.1145/3548606.3560611.
[227] Rush, A.M., Collins, M., 2012. A tutorial on dual decomposition and lagrangian relaxation for inference in natural language processing.
Journal of Artificial Intelligence Research 45, 305‚Äì362.
[228] Rush, K., Charles, Z., Garrett, Z., 2023. Federated automatic differentiation. arXiv preprint arXiv:2301.07806 .
[229] Rush, K., Charles, Z., Garrett, Z., 2024. Fax: Scalable and differentiable federated primitives in jax. arXiv:2403.07128.
[230] Ryffel, T., Trask, A., Dahl, M., Wagner, B., Mancuso, J., Rueckert, D., Passerat-Palmbach, J., 2018. A generic framework for privacy
preserving deep learning. arXiv preprint arXiv:1811.04017 .
[231] Saad, W., Han, Z., Poor, H.V., Basar, T., 2012. Game-theoretic methods for the smart grid: An overview of microgrid systems, demand-side
management, and smart grid communications. IEEE Signal Processing Magazine 29, 86‚Äì105. doi:10.1109/MSP.2012.2186410.
[232] S√°nchez, P.M.S., Celdr√°n, A.H., Schenk, T., Iten, A.L.B., Bovet, G., P√©rez, G.M., Stiller, B., 2022. Studying the robustness of anti-adversarial
federated learning models detecting cyberattacks in iot spectrum sensors. IEEE Transactions on Dependable and Secure Computing 21,
573‚Äì584.
[233] Sattarov, T., Schreyer, M., Borth, D., 2024. Fedtabdiff: Federated learning of diffusion probabilistic models for synthetic mixed-type tabular
data generation.
[234] Sattler, F., M√ºller, K.R., Samek, W., 2021. Clustered federated learning: Model-agnostic distributed multitask optimization under privacy
constraints. IEEE Transactions on Neural Networks and Learning Systems 32, 3710‚Äì3722. doi:10.1109/TNNLS.2020.3015958.
[235] Schmidt, M., Le Roux, N., Bach, F., 2017. Minimizing finite sums with the stochastic average gradient. Mathematical Programming 162,
83‚Äì112.
[236] Schmidt, V., Goyal, K., Joshi, A., Feld, B., Conell, L., Laskaris, N., Blank, D., Wilson, J., Friedler, S., Luccioni, S., 2021. CodeCarbon:
Estimate and Track Carbon Emissions from Machine Learning Computing doi:10.5281/zenodo.4658424.
[237] Seide, F., Fu, H., Droppo, J., Li, G., Yu, D., 2014. 1-bit stochastic gradient descent and its application to data-parallel distributed training of
speech DNNs, in: Proc. Interspeech 2014, pp. 1058‚Äì1062. doi:10.21437/Interspeech.2014-274.
[238] Shalev-Shwartz, S., Zhang, T., 2013. Stochastic dual coordinate ascent methods for regularized loss minimization. Journal of Machine
Learning Research 14.
[239] Shamir, A., 1979.
How to share a secret.
Commun. ACM 22, 612‚Äì613.
URL: https://doi.org/10.1145/359168.359176,
doi:10.1145/359168.359176.
[240] Shamir, O., Srebro, N., Zhang, T., 2014. Communication-efficient distributed optimization using an approximate newton-type method,
in: Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32, JMLR.org. p.
II‚Äì1000‚ÄìII‚Äì1008.
[241] Sharma, A., Marchang, N., 2024. Probabilistic sign flipping attack in federated learning, in: 2024 15th International Conference on Computing
Communication and Networking Technologies (ICCCNT), IEEE. pp. 1‚Äì6.
[242] Sharma, R., Ramakrishna, A., MacLaughlin, A., Rumshisky, A., Majmudar, J., Chung, C., Avestimehr, S., Gupta, R., 2022.
Federated learning with noisy user feedback, in: NAACL 2022.
URL: https://www.amazon.science/publications/
federated-learning-with-noisy-user-feedback.
[243] Shi, W., Ling, Q., Wu, G., Yin, W., 2015. Extra: An exact first-order algorithm for decentralized consensus optimization. SIAM Journal on
Optimization 25, 944‚Äì966.
[244] Shi, W., Ling, Q., Yuan, K., Wu, G., Yin, W., 2014. On the linear convergence of the admm in decentralized consensus optimization. IEEE
Transactions on Signal Processing 62, 1750‚Äì1761. doi:10.1109/TSP.2014.2304432.
[245] Shi, Y., Liang, J., Zhang, W., Tan, V.Y., Bai, S., 2022. Towards understanding and mitigating dimensional collapse in heterogeneous federated
learning. arXiv preprint arXiv:2210.00226 .
Frederico Vicente et al.
Page 66 of 70
Modular Federated Learning: A Meta-Framework Perspective
[246] Shoeybi, M., Patwary, M., Puri, R., LeGresley, P., Casper, J., Catanzaro, B., 2019. Megatron-lm: Training multi-billion parameter language
models using model parallelism. arXiv preprint arXiv:1909.08053 .
[247] Silva, I.O.e., Soares, C., Sousa, I., Ghani, R., 2024. Systematic analysis of the impact of label noise correction on ml fairness, in: Liu, T.,
Webb, G., Yue, L., Wang, D. (Eds.), AI 2023: Advances in Artificial Intelligence, Springer Nature Singapore, Singapore. pp. 173‚Äì184.
[248] So, J., G√ºler, B., Avestimehr, A.S., 2020. Byzantine-resilient secure federated learning. IEEE Journal on Selected Areas in Communications
39, 2168‚Äì2181.
[249] So, J., He, C., Yang, C.S., Li, S., Yu, Q., E. Ali, R., Guler, B., Avestimehr, S., 2022.
Lightsecagg: a lightweight and
versatile design for secure aggregation in federated learning, in: Marculescu, D., Chi, Y., Wu, C. (Eds.), Proceedings of
Machine Learning and Systems, pp. 694‚Äì720.
URL: https://proceedings.mlsys.org/paper_files/paper/2022/file/
6c44dc73014d66ba49b28d483a8f8b0d-Paper.pdf.
[250] Stripelis, D., Anastasiou, C., Toral, P., Asghar, A., Ambite, J.L., 2023. Metisfl: An embarrassingly parallelized controller for scalable &
efficient federated learning workflows, in: Proceedings of the 4th International Workshop on Distributed Machine Learning, Association for
Computing Machinery, New York, NY, USA. p. 11‚Äì19. URL: https://doi.org/10.1145/3630048.3630186, doi:10.1145/3630048.
3630186.
[251] Stripelis, D., Thompson, P.M., Ambite, J.L., 2022.
Semi-synchronous federated learning for energy-efficient training and accelerated
convergence in cross-silo settings. ACM Trans. Intell. Syst. Technol. 13. URL: https://doi.org/10.1145/3524885, doi:10.1145/
3524885.
[252] Su, Y., Wang, Z., Cao, M., Jia, M., Liu, F., 2022.
Convergence analysis of dual decomposition algorithm in distributed optimization:
Asynchrony and inexactness. IEEE Transactions on Automatic Control .
[253] Sun, J., Chen, T., Giannakis, G.B., Yang, Q., Yang, Z., 2022. Lazily aggregated quantized gradient innovation for communication-efficient
federated learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 2031‚Äì2044. doi:10.1109/TPAMI.2020.3033286.
[254] Sun, L., Qian, J., Chen, X., 2021. Ldp-fl: Practical private aggregation in federated learning with local differential privacy, in: Zhou, Z.H. (Ed.),
Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, International Joint Conferences on Artificial
Intelligence Organization. pp. 1571‚Äì1578. URL: https://doi.org/10.24963/ijcai.2021/217, doi:10.24963/ijcai.2021/217.
main Track.
[255] T. Dinh, C., Tran, N., Nguyen, J., 2020. Personalized federated learning with moreau envelopes, in: Larochelle, H., Ranzato, M., Hadsell,
R., Balcan, M., Lin, H. (Eds.), Advances in Neural Information Processing Systems, Curran Associates, Inc.. pp. 21394‚Äì21405. URL:
https://proceedings.neurips.cc/paper_files/paper/2020/file/f4f1f13c8289ac1b1ee0ff176b56fc60-Paper.pdf.
[256] Tan, A.Z., Yu, H., Cui, L., Yang, Q., 2022. Towards personalized federated learning. IEEE transactions on neural networks and learning
systems 34, 9587‚Äì9603.
[257] Tang, J., Ding, X., Hu, D., Guo, B., Shen, Y., Ma, P., Jiang, Y., 2023. Fedrad: Heterogeneous federated learning via relational adaptive
distillation. Sensors 23. URL: https://www.mdpi.com/1424-8220/23/14/6518, doi:10.3390/s23146518.
[258] Tang, X., Yu, H., 2023. Competitive-cooperative multi-agent reinforcement learning for auction-based federated learning, in: Elkind, E.
(Ed.), Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI-23, International Joint Conferences
on Artificial Intelligence Organization. pp. 4262‚Äì4270. URL: https://doi.org/10.24963/ijcai.2023/474, doi:10.24963/ijcai.
2023/474. main Track.
[259] Teerapittayanon, S., McDanel, B., Kung, H.T., 2016. Branchynet: Fast inference via early exiting from deep neural networks, in: 2016 23rd
international conference on pattern recognition (ICPR), IEEE. pp. 2464‚Äì2469.
[260] Tekgul, B.G., Xia, Y., Marchal, S., Asokan, N., 2021. Waffle: Watermarking in federated learning, in: 2021 40th International Symposium
on Reliable Distributed Systems (SRDS), IEEE. pp. 310‚Äì320.
[261] Ogier du Terrail, J., Leopold, A., Joly, C., B√©guier, C., Andreux, M., Maussion, C., Schmauch, B., Tramel, E.W., Bendjebbar, E., Zaslavskiy,
M., Wainrib, G., Milder, M., Gervasoni, J., Guerin, J., Durand, T., Livartowski, A., Moutet, K., Gautier, C., Djafar, I., Moisson, A.L., Marini,
C., Galtier, M., Balazard, F., Dubois, R., Moreira, J., Simon, A., Drubay, D., Lacroix-Triki, M., Franchet, C., Bataillon, G., Heudel, P.E.,
2023. Federated learning for predicting histological response to neoadjuvant chemotherapy in triple-negative breast cancer. Nature Medicine
29, 135‚Äì146. URL: https://doi.org/10.1038/s41591-022-02155-w, doi:10.1038/s41591-022-02155-w.
[262] Thapa, C., Mahawaga Arachchige, P.C., Camtepe, S., Sun, L., 2022. Splitfed: When federated learning meets split learning. Proceedings of the
AAAI Conference on Artificial Intelligence 36, 8485‚Äì8493. URL: https://ojs.aaai.org/index.php/AAAI/article/view/20825,
doi:10.1609/aaai.v36i8.20825.
[263] Thwal, C.M., Tun, Y.L., Kim, K., Park, S.B., Hong, C.S., 2023. Transformers with attentive federated aggregation for time series stock
forecasting, in: 2023 International Conference on Information Networking (ICOIN), IEEE. pp. 499‚Äì504.
[264] Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al., 2023.
Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 .
[265] Truex, S., Baracaldo, N., Anwar, A., Steinke, T., Ludwig, H., Zhang, R., Zhou, Y., 2019. A hybrid approach to privacy-preserving federated
learning, in: Proceedings of the 12th ACM workshop on artificial intelligence and security, pp. 1‚Äì11.
[266] Tsitsiklis, J., Bertsekas, D., Athans, M., 1986. Distributed asynchronous deterministic and stochastic gradient optimization algorithms. IEEE
Transactions on Automatic Control 31, 803‚Äì812. doi:10.1109/TAC.1986.1104412.
[267] Tsitsiklis, J.N., 1984. Problems in decentralized decision making and computation. Ph.D. thesis. Massachusetts Institute of Technology.
[268] Tsitsiklis, J.N., et al., 1989.
Decentralized detection, Massachusetts Institute of Technology, Laboratory for Information and Decision
Systems.
[269] Vaizman, Y., Ellis, K., Lanckriet, G., 2017. Recognizing detailed human context in the wild from smartphones and smartwatches. IEEE
Pervasive Computing 16, 62‚Äì74. doi:10.1109/MPRV.2017.3971131.
[270] Valdeira, P., Chi, Y., Soares, C., Xavier, J., 2023. A multi-token coordinate descent method for semi-decentralized vertical federated learning.
arXiv preprint arXiv:2309.09977 .
Frederico Vicente et al.
Page 67 of 70
Modular Federated Learning: A Meta-Framework Perspective
[271] Valdeira, P., Xavier, J., Soares, C., Chi, Y., 2024. Communication-efficient vertical federated learning via compressed error feedback. arXiv
preprint arXiv:2406.14420 .
[272] Vepakomma, P., Gupta, O., Swedish, T., Raskar, R., 2018. Split learning for health: Distributed deep learning without sharing raw patient
data. arXiv preprint arXiv:1812.00564 .
[273] Vogels, T., Hendrikx, H., Jaggi, M., 2023. Beyond spectral gap: The role of the topology in decentralized learning. Journal of Machine
Learning Research 24, 1‚Äì31. URL: http://jmlr.org/papers/v24/22-1471.html.
[274] Voita, E., Talbot, D., Moiseev, F., Sennrich, R., Titov, I., 2019.
Analyzing multi-head self-attention: Specialized heads do the heavy
lifting, the rest can be pruned, in: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association
for Computational Linguistics, Florence, Italy. pp. 5797‚Äì5808.
URL: https://aclanthology.org/P19-1580, doi:10.18653/v1/
P19-1580.
[275] Wang, J., Tantia, V., Ballas, N., Rabbat, M., 2019a. Slowmo: Improving communication-efficient distributed sgd with slow momentum.
arXiv preprint arXiv:1910.00643 .
[276] Wang, Q., Xu, M., Jin, C., Dong, X., Yuan, J., Jin, X., Huang, G., Liu, Y., Liu, X., 2022. Melon: breaking the memory wall for resource-efficient
on-device machine learning, in: Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services,
Association for Computing Machinery, New York, NY, USA. p. 450‚Äì463.
URL: https://doi.org/10.1145/3498361.3538928,
doi:10.1145/3498361.3538928.
[277] Wang, Q., Yang, K., 2024. Privacy-preserving data fusion for traffic state estimation: A vertical federated learning approach. arXiv preprint
arXiv:2401.11836 .
[278] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020. Minilm: Deep self-attention distillation for task-agnostic compression
of pre-trained transformers, in: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H. (Eds.), Advances in Neural Information
Processing Systems, Curran Associates, Inc.. pp. 5776‚Äì5788. URL: https://proceedings.neurips.cc/paper_files/paper/2020/
file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.
[279] Wang, X., Chen, W., Xia, J., Wen, Z., Zhu, R., Schreck, T., 2023a. Hetvis: A visual analysis approach for identifying data heterogeneity
in horizontal federated learning. IEEE Transactions on Visualization and Computer Graphics 29, 310‚Äì319. doi:10.1109/TVCG.2022.
3209347.
[280] Wang, X., Wang, Y., Javaheri, Z., Almutairi, L., Moghadamnejad, N., Younes, O.S., 2023b. Federated deep learning for anomaly detection
in the internet of things. Computers and Electrical Engineering 108, 108651.
[281] Wang, Y., Ma, X., Chen, Z., Luo, Y., Yi, J., Bailey, J., 2019b. Symmetric cross entropy for robust learning with noisy labels, in: 2019
IEEE/CVF International Conference on Computer Vision (ICCV), pp. 322‚Äì330. doi:10.1109/ICCV.2019.00041.
[282] Wang, Z., Dong, N., Sun, J., Knottenbelt, W., Guo, Y., 2024. zkfl: Zero-knowledge proof-based gradient aggregation for federated learning.
IEEE Transactions on Big Data .
[283] Wang, Z., Fan, X., Qi, J., Wen, C., Wang, C., Yu, R., 2021. Federated learning with fair averaging, in: Zhou, Z. (Ed.), Proceedings of
the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event / Montreal, Canada, 19-27 August 2021,
ijcai.org. pp. 1615‚Äì1623. URL: https://doi.org/10.24963/ijcai.2021/223, doi:10.24963/IJCAI.2021/223.
[284] Wei, J., Zhu, Z., Cheng, H., Liu, T., Niu, G., Liu, Y., 2021. Learning with noisy labels revisited: A study using real-world human annotations.
arXiv preprint arXiv:2110.12088 .
[285] Wei, K., Li, J., Ma, C., Ding, M., Shu, F., Zhao, H., Chen, W., Zhu, H., 2024. Gradient sparsification for efficient wireless federated learning
with differential privacy. Science China Information Sciences 67, 142303.
[286] Wei, X., Shen, C., 2022. Federated learning over noisy channels: Convergence analysis and design examples. IEEE Transactions on Cognitive
Communications and Networking 8, 1253‚Äì1268.
[287] Wilson, A.G., Hu, Z., Salakhutdinov, R., Xing, E.P., 2016. Deep kernel learning, in: Gretton, A., Robert, C.C. (Eds.), Proceedings of the
19th International Conference on Artificial Intelligence and Statistics, PMLR, Cadiz, Spain. pp. 370‚Äì378. URL: https://proceedings.
mlr.press/v51/wilson16.html.
[288] Woisetschl√§ger, H., Erben, A., Mayer, R., Wang, S., Jacobsen, H.A., 2023. Fledge: Benchmarking federated machine learning applications
in edge computing systems. arXiv preprint arXiv:2306.05172 .
[289] Wortsman, M., Ilharco, G., Gadre, S.Y., Roelofs, R., Gontijo-Lopes, R., Morcos, A.S., Namkoong, H., Farhadi, A., Carmon, Y., Kornblith, S.,
Schmidt, L., 2022. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time, in:
Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., Sabato, S. (Eds.), Proceedings of the 39th International Conference on Machine
Learning, PMLR. pp. 23965‚Äì23998. URL: https://proceedings.mlr.press/v162/wortsman22a.html.
[290] Wu, C., Li, Z., Wang, F., Wu, C., 2023a.
Learning cautiously in federated learning with noisy and heterogeneous clients, in: 2023
IEEE International Conference on Multimedia and Expo (ICME), IEEE Computer Society, Los Alamitos, CA, USA. pp. 660‚Äì665. URL:
https://doi.ieeecomputersociety.org/10.1109/ICME55011.2023.00119, doi:10.1109/ICME55011.2023.00119.
[291] Wu, C.J., Raghavendra, R., Gupta, U., Acun, B., Ardalani, N., Maeng, K., Chang, G., Aga, F., Huang, J., Bai, C., Gschwind, M., Gupta, A.,
Ott, M., Melnikov, A., Candido, S., Brooks, D., Chauhan, G., Lee, B., Lee, H.H., Akyildiz, B., Balandat, M., Spisak, J., Jain, R., Rabbat, M.,
Hazelwood, K., 2022a. Sustainable ai: Environmental implications, challenges and opportunities, in: Marculescu, D., Chi, Y., Wu, C. (Eds.),
Proceedings of Machine Learning and Systems, pp. 795‚Äì813. URL: https://proceedings.mlsys.org/paper_files/paper/2022/
file/462211f67c7d858f663355eff93b745e-Paper.pdf.
[292] Wu, D., Deng, Y., Li, M., 2022b. Fl-mgvn: Federated learning for anomaly detection using mixed gaussian variational self-encoding network.
Information processing & management 59, 102839.
[293] Wu, R., Mitra, S., Chen, X., Rao, A., 2023b. Decentralized personalized online federated learning, in: 2023 IEEE International Conference
on Big Data (BigData), pp. 1873‚Äì1882. doi:10.1109/BigData59044.2023.10386159.
[294] Wu, X., Yu, H., 2022.
Mars-fl: Enabling competitors to collaborate in federated learning.
IEEE Transactions on Big Data , 1‚Äì
11doi:10.1109/TBDATA.2022.3186991.
Frederico Vicente et al.
Page 68 of 70
Modular Federated Learning: A Meta-Framework Perspective
[295] XGBoost, 2022. Federated xgboost. https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/federated.
py.
[296] Xiao, H., Rasul, K., Vollgraf, R., 2017. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint
arXiv:1708.07747 .
[297] Xiao, L., Yu, A.W., Lin, Q., Chen, W., 2019. Dscovr: Randomized primal-dual block coordinate algorithms for asynchronous distributed
optimization. Journal of Machine Learning Research 20, 1‚Äì58.
[298] Xiao, T., Xia, T., Yang, Y., Huang, C., Wang, X., 2015. Learning from massive noisy labeled data for image classification, in: 2015 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2691‚Äì2699. doi:10.1109/CVPR.2015.7298885.
[299] Xie, C., Koyejo, O., Gupta, I., 2020. Fall of empires: Breaking byzantine-tolerant sgd by inner product manipulation, in: Uncertainty in
Artificial Intelligence, PMLR. pp. 261‚Äì270.
[300] Xie, C., Koyejo, S., Gupta, I., 2019. Zeno: Distributed stochastic gradient descent with suspicion-based fault-tolerance, in: Chaudhuri,
K., Salakhutdinov, R. (Eds.), Proceedings of the 36th International Conference on Machine Learning, PMLR. pp. 6893‚Äì6901.
URL:
https://proceedings.mlr.press/v97/xie19b.html.
[301] Xu, J., Chen, Z., Quek, T.Q., Chong, K.F.E., 2022. Fedcorr: Multi-stage federated learning for label noise correction, in: Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10184‚Äì10193.
[302] Xu, J., Tong, X., Huang, S.L., 2023a. Personalized federated learning with feature alignment and classifier collaboration. arXiv preprint
arXiv:2306.11867 .
[303] Xu, J., Wang, S., Wang, L., Yao, A.C.C., 2021. Fedcm: Federated learning with client-level momentum. arXiv preprint arXiv:2106.10874 .
[304] Xu, Z., Zhang, Y., Andrew, G., Choquette-Choo, C.A., Kairouz, P., McMahan, H.B., Rosenstock, J., Zhang, Y., 2023b. Federated learning
of gboard language models with differential privacy. arXiv preprint arXiv:2305.18465 .
[305] Yaacoub, J.P.A., Noura, H.N., Salman, O., 2023.
Security of federated learning with iot systems: Issues, limitations, challenges, and
solutions. Internet of Things and Cyber-Physical Systems 3, 155‚Äì179. URL: https://www.sciencedirect.com/science/article/
pii/S2667345223000226, doi:https://doi.org/10.1016/j.iotcps.2023.04.001.
[306] Yadav, C., Chowdhury, A.R., Boneh, D., Chaudhuri, K., 2024. Fairproof: Confidential and certifiable fairness for neural networks. arXiv
preprint arXiv:2402.12572 .
[307] Yadav, P., Tam, D., Choshen, L., Raffel, C.A., Bansal, M., 2023.
Ties-merging: Resolving interference when merging models,
in: Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., Levine, S. (Eds.), Advances in Neural Information Processing
Systems, Curran Associates, Inc.. pp. 7093‚Äì7115.
URL: https://proceedings.neurips.cc/paper_files/paper/2023/file/
1644c9af28ab7916874f6fd6228a9bcf-Paper-Conference.pdf.
[308] Yadav, R., Aiken, A., Kjolstad, F., 2022. Distal: the distributed tensor algebra compiler, in: Proceedings of the 43rd ACM SIGPLAN
International Conference on Programming Language Design and Implementation, Association for Computing Machinery, New York, NY,
USA. p. 286‚Äì300. URL: https://doi.org/10.1145/3519939.3523437, doi:10.1145/3519939.3523437.
[309] Yang, H.H., Chen, Z., Quek, T.Q., Poor, H.V., 2021. Revisiting analog over-the-air machine learning: The blessing and curse of interference.
IEEE Journal of Selected Topics in Signal Processing 16, 406‚Äì419.
[310] Yang, S., Park, H., Byun, J., Kim, C., 2022a.
Robust federated learning with noisy labels.
IEEE Intelligent Systems 37, 35‚Äì43.
doi:10.1109/MIS.2022.3151466.
[311] Yang, Y., Guan, X., Jia, Q.S., Yu, L., Xu, B., Spanos, C.J., 2022b. A survey of admm variants for distributed optimization: Problems,
algorithms and features. arXiv preprint arXiv:2208.03700 .
[312] Ye, R., Ge, R., Zhu, X., Chai, J., Du, Y., Liu, Y., Wang, Y., Chen, S., 2024. Fedllm-bench: Realistic benchmarks for federated learning of
large language models. arXiv preprint arXiv:2406.04845 .
[313] Yemini, M., Saha, R., Ozfatura, E., G√ºnd√ºz, D., Goldsmith, A.J., 2022. Semi-decentralized federated learning with collaborative relaying,
in: 2022 IEEE International Symposium on Information Theory (ISIT), pp. 1471‚Äì1476. doi:10.1109/ISIT50566.2022.9834707.
[314] Yin, H., Mallya, A., Vahdat, A., Alvarez, J.M., Kautz, J., Molchanov, P., 2021. See through gradients: Image batch recovery via gradinversion,
in: 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), IEEE Computer Society, Los Alamitos, CA, USA.
pp. 16332‚Äì16341. URL: https://doi.ieeecomputersociety.org/10.1109/CVPR46437.2021.01607, doi:10.1109/CVPR46437.
2021.01607.
[315] Younis, O., Fahmy, S., 2004. Heed: a hybrid, energy-efficient, distributed clustering approach for ad hoc sensor networks. IEEE Transactions
on Mobile Computing 3, 366‚Äì379. doi:10.1109/TMC.2004.41.
[316] Yousefpour, A., Guo, S., Shenoy, A., Ghosh, S., Stock, P., Maeng, K., Kr√ºger, S.W., Rabbat, M., Wu, C.J., Mironov, I., 2023. Green federated
learning. arXiv preprint arXiv:2303.14604 .
[317] Yousefpour, A., Shilov, I., Sablayrolles, A., Testuggine, D., Prasad, K., Malek, M., Nguyen, J., Ghosh, S., Bharadwaj, A., Zhao, J., Cormode,
G., Mironov, I., 2021. Opacus: User-friendly differential privacy library in PyTorch. arXiv preprint arXiv:2109.12298 .
[318] Yu, F., Zhang, W., Qin, Z., Xu, Z., Wang, D., Liu, C., Tian, Z., Chen, X., 2021. Fed2: Feature-aligned federated learning, in: Proceedings
of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, Association for Computing Machinery, New York, NY,
USA. p. 2066‚Äì2074. URL: https://doi.org/10.1145/3447548.3467309, doi:10.1145/3447548.3467309.
[319] Yu, L., Yu, B., Yu, H., Huang, F., Li, Y., 2023. Language models are super mario: Absorbing abilities from homologous models as a free
lunch. arXiv preprint arXiv:2311.03099 .
[320] Yuan, H., Ma, T., 2020. Federated accelerated stochastic gradient descent. Advances in Neural Information Processing Systems 33, 5332‚Äì
5344.
[321] Yuan, J., Xu, M., Zhao, Y., Bian, K., Huang, G., Liu, X., Wang, S., 2020.
Federated neural architecture search.
arXiv preprint
arXiv:2002.06352 .
[322] Yurochkin, M., Agarwal, M., Ghosh, S., Greenewald, K., Hoang, N., Khazaeni, Y., 2019. Bayesian nonparametric federated learning of neural
networks, in: Chaudhuri, K., Salakhutdinov, R. (Eds.), Proceedings of the 36th International Conference on Machine Learning, PMLR. pp.
Frederico Vicente et al.
Page 69 of 70
Modular Federated Learning: A Meta-Framework Perspective
7252‚Äì7261. URL: https://proceedings.mlr.press/v97/yurochkin19a.html.
[323] Zama, 2022. Concrete: TFHE Compiler that converts python programs into FHE equivalent. https://github.com/zama-ai/concrete.
[324] Zeng, D., Hu, X., Liu, S., Yu, Y., Wang, Q., Xu, Z., 2023a. Stochastic clustered federated learning. arXiv preprint arXiv:2303.00897 .
[325] Zeng, D., Liang, S., Hu, X., Wang, H., Xu, Z., 2023b. Fedlab: A flexible federated learning framework. Journal of Machine Learning
Research 24, 1‚Äì7. URL: http://jmlr.org/papers/v24/22-0440.html.
[326] Zetas, M., Spantideas, S., Giannopoulos, A., Nomikos, N., Trakadas, P., 2024. Empowering 6g maritime communications with distributed
intelligence and over-the-air model sharing. Frontiers in Communications and Networks 4. URL: https://www.frontiersin.org/
articles/10.3389/frcmn.2023.1280602, doi:10.3389/frcmn.2023.1280602.
[327] Zhang, F., Kuang, K., Chen, L., You, Z., Shen, T., Xiao, J., Zhang, Y., Wu, C., Wu, F., Zhuang, Y., Li, X., 2023a. Federated unsupervised
representation learning. Frontiers of Information Technology & Electronic Engineering 24, 1181‚Äì1193. URL: https://doi.org/10.
1631/FITEE.2200268, doi:10.1631/FITEE.2200268.
[328] Zhang, J., Zeng, S., Zhang, M., Wang, R., Wang, F., Zhou, Y., Liang, P.P., Qu, L., 2024. Flhetbench: Benchmarking device and state
heterogeneity in federated learning, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12098‚Äì
12108.
[329] Zhang, X., Chen, X., Hong, M., Wu, Z.S., Yi, J., 2022a.
Understanding clipping for federated learning: Convergence and client-level
differential privacy, in: International Conference on Machine Learning, ICML 2022.
[330] Zhang, X., Li, Y., Li, W., Guo, K., Shao, Y., 2022b. Personalized federated learning via variational Bayesian inference, in: Chaudhuri, K.,
Jegelka, S., Song, L., Szepesvari, C., Niu, G., Sabato, S. (Eds.), Proceedings of the 39th International Conference on Machine Learning,
PMLR. pp. 26293‚Äì26310. URL: https://proceedings.mlr.press/v162/zhang22o.html.
[331] Zhang, X., Lin, S., Chen, C., Chen, X., 2023b. Moda: model ownership deprivation attack in asynchronous federated learning. IEEE
Transactions on Dependable and Secure Computing .
[332] Zhang, Y., Yu, H., 2024.
Lr-xfl: Logical reasoning-based explainable federated learning.
Proceedings of the AAAI Conference on
Artificial Intelligence 38, 21788‚Äì21796.
URL: https://ojs.aaai.org/index.php/AAAI/article/view/30179, doi:10.1609/
aaai.v38i19.30179.
[333] Zhang, Y., Zeng, D., Luo, J., Xu, Z., King, I., 2023c. A survey of trustworthy federated learning with perspectives on security, robustness
and privacy, in: Companion Proceedings of the ACM Web Conference 2023, Association for Computing Machinery, New York, NY, USA.
p. 1167‚Äì1176. URL: https://doi.org/10.1145/3543873.3587681, doi:10.1145/3543873.3587681.
[334] Zhang, Z., Hu, X., Zhang, J., Zhang, Y., Wang, H., Qu, L., Xu, Z., 2023d. Fedlegal: The first real-world federated learning benchmark for legal
nlp, in: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 3492‚Äì3507.
[335] Zhao, X., Sayed, A.H., 2012. Clustering via diffusion adaptation over networks, in: 2012 3rd International Workshop on Cognitive Information
Processing (CIP), pp. 1‚Äì6. doi:10.1109/CIP.2012.6232902.
[336] Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V., 2018a. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582 .
[337] Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V., 2018b. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582 .
[338] Zhou, H., Lan, T., Venkataramani, G.P., Ding, W., 2023a. Every parameter matters: Ensuring the convergence of federated learning with
dynamic heterogeneous models reduction, in: Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., Levine, S. (Eds.), Advances in
Neural Information Processing Systems, Curran Associates, Inc.. pp. 25991‚Äì26002. URL: https://proceedings.neurips.cc/paper_
files/paper/2023/file/526356453b7301c9b29aa0533f62bdef-Paper-Conference.pdf.
[339] Zhou, S., Li, G.Y., 2023. Federated learning via inexact admm. IEEE Transactions on Pattern Analysis and Machine Intelligence 45,
9699‚Äì9708. doi:10.1109/TPAMI.2023.3243080.
[340] Zhou, X., Wang, P., Zhou, L., Xun, P., Lu, K., 2023b.
A survey of the security analysis of embedded devices.
Sensors 23.
URL:
https://www.mdpi.com/1424-8220/23/22/9221, doi:10.3390/s23229221.
[341] Zhu, H., Jin, Y., 2021. Real-time federated evolutionary neural architecture search. IEEE Transactions on Evolutionary Computation 26,
364‚Äì378.
[342] Zhu, H., Zhang, H., Jin, Y., 2021. From federated learning to federated neural architecture search: a survey. Complex & Intelligent Systems
7, 639‚Äì657.
[343] Zhu, L., Liu, Z., Han, S., 2019. Deep leakage from gradients. Curran Associates Inc., Red Hook, NY, USA.
[344] Zhuo, H.H., Feng, W., Lin, Y., Xu, Q., Yang, Q., 2019. Federated deep reinforcement learning. arXiv preprint arXiv:1901.08277 .
[345] Zoph, B., 2016. Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578 .
Frederico Vicente et al.
Page 70 of 70
